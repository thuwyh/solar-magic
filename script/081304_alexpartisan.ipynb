{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import math\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mask_two = [-i for i in range(1,2)]+[i for i in range(1,2)]\n",
    "rolling_mask_four = [-i for i in range(1,3)]+[i for i in range(1,3)]\n",
    "rolling_mask_six = [-i for i in range(1,4)]+[i for i in range(1,4)]\n",
    "rolling_mask_eight = [-i for i in range(1,5)]+[i for i in range(1,5)]\n",
    "rolling_mask_ten = [-i for i in range(1,6)]+[i for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/public_raw.train.csv')\n",
    "\n",
    "test = pd.read_csv('../data/public_raw.test.csv')\n",
    "\n",
    "train['is_train']=1\n",
    "test['is_train']=0\n",
    "\n",
    "df = pd.concat([train, test],sort=False)\n",
    "\n",
    "rep_cols = {'ID':'ID', \n",
    " '板温':'board_t', \n",
    " '现场温度':'env_t', \n",
    " '光照强度':'light_strength', \n",
    " '转换效率':'efficiency', \n",
    " '转换效率A':'efficiency_A', \n",
    " '转换效率B':'efficiency_B', \n",
    " '转换效率C':'efficiency_C', \n",
    " '电压A':'V_A',\n",
    " '电压B':'V_B', \n",
    " '电压C':'V_C', \n",
    " '电流A':'I_A', \n",
    " '电流B':'I_B', \n",
    " '电流C':'I_C', \n",
    " '功率A':'P_A', \n",
    " '功率B':'P_B', \n",
    " '功率C':'P_C', \n",
    " '平均功率':'P_avg', \n",
    " '风速':'wind_speed',\n",
    " '风向':'wind_direction', \n",
    " '发电量':'y'\n",
    "}\n",
    "\n",
    "df.rename(index=str, columns=rep_cols, inplace=True)\n",
    "\n",
    "df.sort_values(by=['ID'],ascending=True, inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#修正\n",
    "#计算偏差率的辅助列\n",
    "for c in ['I_A','I_B','I_C','V_A','V_B','V_C']:\n",
    "    df[c+'_avg_sequence'] = np.nanmean([df[c].shift(i) for i in rolling_mask_eight],axis=0)\n",
    "    df[c+'_exception_ratio'] = np.abs(df[c]-df[c+'_avg_sequence'])/df[c+'_avg_sequence']\n",
    "    \n",
    "    \n",
    "#标记包含异常值的记录\n",
    "df['is_abnormal']=0\n",
    "\n",
    "for c in ['I_A','I_B','I_C','V_A','V_B','V_C']:\n",
    "    df.loc[df[c+'_exception_ratio'] > 1.6 , 'is_abnormal'] = 1\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练集中异常记录30条\n",
    "df[df['is_train']==1][df['is_abnormal']==1][['ID','board_t','light_strength','I_A','I_B','I_C','V_A','V_B','V_C','P_avg','y']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练集中异常记录34条\n",
    "df[df['is_train']==0][df['is_abnormal']==1][['ID','board_t','light_strength','I_A','I_B','I_C','V_A','V_B','V_C','P_avg','y']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645.39 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.85625\n",
      "2\n",
      "65382.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 722.25\n",
      "3\n",
      "65498.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 677.125\n",
      "4\n",
      "6.78 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.56\n",
      "5\n",
      "6.68 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.22125\n",
      "6\n",
      "640.77 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 241.31999999999994\n",
      "7\n",
      "65402.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 24870.625\n",
      "8\n",
      "640.77 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 241.33249999999998\n",
      "9\n",
      "65402.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 24871.75\n",
      "10\n",
      "6.68 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.2449999999999997\n",
      "11\n",
      "640.85 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 241.33249999999998\n",
      "12\n",
      "65403.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 24871.75\n",
      "13\n",
      "640.85 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 241.3425\n",
      "14\n",
      "65403.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 24870.875\n",
      "15\n",
      "6.77 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.25375\n",
      "16\n",
      "65406.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 341.25\n",
      "17\n",
      "6.53 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.3125\n",
      "18\n",
      "6.45 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.31875\n",
      "19\n",
      "6.52 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.32375\n",
      "20\n",
      "65514.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 641.125\n",
      "21\n",
      "6.87 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.515\n",
      "22\n",
      "638.94 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.2875\n",
      "23\n",
      "2.37 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.7137500000000001\n",
      "24\n",
      "65394.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 605.625\n",
      "25\n",
      "653.71 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 5.369999999999999\n",
      "26\n",
      "65477.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 696.5\n",
      "27\n",
      "649.75 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 5.754999999999999\n",
      "28\n",
      "65408.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 688.375\n",
      "29\n",
      "649.96 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 4.890000000000001\n",
      "30\n",
      "65406.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 534.25\n",
      "31\n",
      "65438.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 713.75\n",
      "32\n",
      "652.02 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 5.364999999999999\n",
      "33\n",
      "65386.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 702.375\n",
      "34\n",
      "65454.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 681.875\n",
      "35\n",
      "7.04 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.9174999999999999\n",
      "36\n",
      "7.1 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.42875\n",
      "37\n",
      "639.04 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.9687500000000001\n",
      "38\n",
      "65387.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 712.25\n",
      "39\n",
      "653.23 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 5.3374999999999995\n",
      "40\n",
      "65420.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 696.125\n",
      "41\n",
      "65460.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 684.875\n",
      "42\n",
      "6.81 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.41500000000000004\n",
      "43\n",
      "6.83 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.44499999999999995\n",
      "44\n",
      "6.82 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.45749999999999996\n",
      "45\n",
      "65396.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 685.625\n",
      "46\n",
      "7.1 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.73\n",
      "47\n",
      "7.13 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.38250000000000006\n",
      "48\n",
      "635.6 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.79625\n",
      "49\n",
      "65350.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 710.875\n",
      "50\n",
      "652.04 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 5.72125\n",
      "51\n",
      "65428.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 695.625\n",
      "52\n",
      "649.69 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.96625\n",
      "53\n",
      "65446.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 706.125\n",
      "54\n",
      "7.22 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.14375\n",
      "55\n",
      "7.28 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.37124999999999997\n",
      "56\n",
      "639.06 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.2412500000000002\n",
      "57\n",
      "65353.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 721.25\n",
      "58\n",
      "65470.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 700.625\n",
      "59\n",
      "65481.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 682.0\n",
      "60\n",
      "65438.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 685.875\n",
      "61\n",
      "65512.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 685.875\n",
      "62\n",
      "65455.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 683.125\n",
      "63\n",
      "65508.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 677.0\n",
      "64\n",
      "65515.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 690.625\n",
      "65\n",
      "6.64 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.3637500000000001\n",
      "66\n",
      "6.65 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.39250000000000007\n",
      "67\n",
      "6.52 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.40125000000000005\n",
      "68\n",
      "65470.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 654.625\n",
      "69\n",
      "65475.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 700.375\n",
      "70\n",
      "6.56 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.2574999999999998\n",
      "71\n",
      "6.62 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.92\n",
      "72\n",
      "65463.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 8679.125\n",
      "73\n",
      "6.62 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.9087499999999997\n",
      "74\n",
      "65463.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 8677.375\n",
      "75\n",
      "6.5 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.2424999999999997\n",
      "76\n",
      "6.56 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.90625\n",
      "77\n",
      "647.62 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.9049999999999998\n",
      "78\n",
      "65463.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 505.75\n",
      "79\n",
      "6.93 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.14125\n",
      "80\n",
      "643.45 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 80.73375000000003\n",
      "81\n",
      "2.7 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.6925\n",
      "82\n",
      "65419.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 8789.0\n",
      "83\n",
      "6.97 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.98\n",
      "84\n",
      "643.58 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 161.15124999999998\n",
      "85\n",
      "3.35 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.97\n",
      "86\n",
      "65419.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 16880.625\n",
      "87\n",
      "693.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 221.875\n",
      "88\n",
      "693.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 222.375\n",
      "89\n",
      "643.75 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 241.63125000000002\n",
      "90\n",
      "3.16 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.1525\n",
      "91\n",
      "65420.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 24970.125\n",
      "92\n",
      "7.01 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.00625\n",
      "93\n",
      "643.83 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 161.21625\n",
      "94\n",
      "3.36 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.7537500000000001\n",
      "95\n",
      "65420.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 16880.125\n",
      "96\n",
      "643.94 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 162.2425\n",
      "97\n",
      "65420.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 16797.5\n",
      "98\n",
      "704.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 124.0\n",
      "99\n",
      "704.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 200.875\n",
      "100\n",
      "6.94 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.0275\n",
      "101\n",
      "644.15 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 161.3275\n",
      "102\n",
      "65423.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 16798.5\n",
      "103\n",
      "644.15 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 161.27624999999998\n",
      "104\n",
      "65423.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 16799.625\n",
      "105\n",
      "7.13 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.1675\n",
      "106\n",
      "7.05 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.3962499999999998\n",
      "107\n",
      "644.16 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 161.32124999999996\n",
      "108\n",
      "65422.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 16886.875\n",
      "109\n",
      "7.21 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.3425000000000001\n",
      "110\n",
      "7.06 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.3425\n",
      "111\n",
      "7.08 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.385\n",
      "112\n",
      "65440.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 701.5\n",
      "113\n",
      "1.77 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.41624999999999995\n",
      "114\n",
      "3.31 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.4399999999999999\n",
      "115\n",
      "0.78 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.2275\n",
      "116\n",
      "0.78 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.22125\n",
      "117\n",
      "0.7 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.225\n",
      "118\n",
      "715.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 257.5\n",
      "119\n",
      "696.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 259.25\n",
      "120\n",
      "728.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 258.625\n",
      "121\n",
      "1.02 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.19624999999999998\n",
      "122\n",
      "0.97 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.2\n",
      "123\n",
      "0.87 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.2025\n",
      "124\n",
      "692.0 is abnormal as value of V_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 264.25\n",
      "125\n",
      "708.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 259.5\n",
      "126\n",
      "724.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 264.875\n",
      "127\n",
      "1.66 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.35624999999999996\n",
      "128\n",
      "6.72 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.38625\n",
      "129\n",
      "641.85 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.39625\n",
      "130\n",
      "65410.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 679.375\n",
      "131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65505.0 is abnormal as value of V_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 664.875\n",
      "132\n",
      "65491.0 is abnormal as value of V_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 643.875\n",
      "133\n",
      "1.38 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.35125\n",
      "134\n",
      "0.74 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 0.28125000000000006\n",
      "135\n",
      "32.91 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 7.88625\n",
      "136\n",
      "8.86 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 3.3025\n",
      "137\n",
      "8.39 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 3.185\n",
      "138\n",
      "7.99 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.12625\n",
      "139\n",
      "7.49 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.6087500000000001\n",
      "140\n",
      "8.05 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.85875\n",
      "141\n",
      "5.44 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 1.8137500000000002\n",
      "142\n",
      "6.87 is abnormal as value of I_A\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.06\n",
      "143\n",
      "6.72 is abnormal as value of I_C\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 2.4499999999999997\n",
      "144\n",
      "8.14 is abnormal as value of I_B\n",
      "Mark for abnormal records: 1.0\n",
      "Has been replaced by 3.07625\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "#异常值由滚动平均值替代（前后各4个点的平均值）\n",
    "static=1\n",
    "for idx, line in df.iterrows():\n",
    "    for c in ['I_A','I_B','I_C','V_A','V_B','V_C']:\n",
    "        if line[c+'_exception_ratio']>1.6:\n",
    "            print(str(line[c]) + ' is abnormal as value of ' + c)\n",
    "            print('Mark for abnormal records: ' + str(line['is_abnormal']))\n",
    "            line.loc[c] = line[c+'_avg_sequence']\n",
    "            print('Has been replaced by '+str(line[c+'_avg_sequence'])) \n",
    "            static += 1\n",
    "            print(static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前二后二\n",
    "next_one = []\n",
    "prev_one = []\n",
    "next_id = []\n",
    "prev_id = []\n",
    "\n",
    "second_next_one = []\n",
    "second_prev_one = []\n",
    "\n",
    "df_len = df.shape[0]\n",
    "\n",
    "i_y =df.columns.get_loc(\"y\")\n",
    "\n",
    "def get_prev_nn_index(cur_i):\n",
    "    prev_i = cur_i-1\n",
    "    while(prev_i>=0 and pd.isnull(df.iat[prev_i,i_y])):\n",
    "        prev_i-=1\n",
    "    return prev_i\n",
    "\n",
    "def get_next_nn_index(cur_i):\n",
    "    prev_i = cur_i+1\n",
    "    while(prev_i<df_len and pd.isnull(df.iat[prev_i,i_y])):\n",
    "        prev_i+=1\n",
    "    return prev_i\n",
    "\n",
    "for i in range(df_len):\n",
    "    f_pre_i=get_prev_nn_index(i)\n",
    "    if(f_pre_i)<0:\n",
    "        prev_one.append(np.nan)\n",
    "        prev_id.append(0)\n",
    "    else:\n",
    "        prev_one.append(df.iat[f_pre_i,i_y])\n",
    "        prev_id.append(f_pre_i)\n",
    "        \n",
    "    s_pre_i=get_prev_nn_index(f_pre_i)\n",
    "    if (s_pre_i)<0:\n",
    "        second_prev_one.append(np.nan)\n",
    "    else:\n",
    "        second_prev_one.append(df.iat[s_pre_i,i_y])\n",
    "    \n",
    "    f_next_i=get_next_nn_index(i)\n",
    "    if(f_next_i<df_len):\n",
    "        next_one.append(df.iat[f_next_i,i_y])\n",
    "        next_id.append(f_next_i)\n",
    "    else:\n",
    "        next_one.append(np.nan)\n",
    "        next_id.append(df_len)\n",
    "    \n",
    "    s_next_i=get_next_nn_index(f_next_i)\n",
    "    if(s_next_i<df_len):\n",
    "        second_next_one.append(df.iat[s_next_i,i_y])\n",
    "    else:\n",
    "        second_next_one.append(np.nan)\n",
    "        \n",
    "\n",
    "df['next_value'] = next_one\n",
    "df['prev_value'] = prev_one\n",
    "df['avg_value'] = np.nanmean([df['next_value'], df['prev_value']],axis=0)\n",
    "\n",
    "df.drop(['next_value','prev_value'],1,inplace=True)\n",
    "\n",
    "# df.drop(['P_A','P_B','P_C','P_avg'],1,inplace=True)\n",
    "df['P_A_cor']=df['I_A']*df['V_A']\n",
    "df['P_B_cor']=df['I_B']*df['V_B']\n",
    "df['P_C_cor']=df['I_C']*df['V_C']\n",
    "df['P_avg_cor']=1/3*(df['P_A_cor']+df['P_B_cor']+df['P_C_cor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 8409)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#拆分数据\n",
    "\n",
    "train_data = df[df['is_train']==1]\n",
    "test_data = df[df['is_train']==0]\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#准备Test集结果\n",
    "df_result = pd.DataFrame()\n",
    "df_result['ID'] = list(test_data['ID'])\n",
    "special_missing_ID = test_data[test_data[(test_data == 0) | (test_data == 0.)].count(axis=1) > 13]['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>board_t</th>\n",
       "      <th>env_t</th>\n",
       "      <th>light_strength</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>efficiency_A</th>\n",
       "      <th>efficiency_B</th>\n",
       "      <th>efficiency_C</th>\n",
       "      <th>V_A</th>\n",
       "      <th>V_B</th>\n",
       "      <th>...</th>\n",
       "      <th>V_B_avg_sequence</th>\n",
       "      <th>V_B_exception_ratio</th>\n",
       "      <th>V_C_avg_sequence</th>\n",
       "      <th>V_C_exception_ratio</th>\n",
       "      <th>is_abnormal</th>\n",
       "      <th>avg_value</th>\n",
       "      <th>P_A_cor</th>\n",
       "      <th>P_B_cor</th>\n",
       "      <th>P_C_cor</th>\n",
       "      <th>P_avg_cor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>-19.14</td>\n",
       "      <td>-17.4</td>\n",
       "      <td>34</td>\n",
       "      <td>80.55</td>\n",
       "      <td>106.32</td>\n",
       "      <td>16.98</td>\n",
       "      <td>118.36</td>\n",
       "      <td>729</td>\n",
       "      <td>709</td>\n",
       "      <td>...</td>\n",
       "      <td>597.666667</td>\n",
       "      <td>0.186280</td>\n",
       "      <td>603.666667</td>\n",
       "      <td>0.200994</td>\n",
       "      <td>0</td>\n",
       "      <td>1.692575</td>\n",
       "      <td>976.86</td>\n",
       "      <td>155.98</td>\n",
       "      <td>1087.50</td>\n",
       "      <td>740.113333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>-18.73</td>\n",
       "      <td>-17.3</td>\n",
       "      <td>30</td>\n",
       "      <td>99.90</td>\n",
       "      <td>139.00</td>\n",
       "      <td>21.20</td>\n",
       "      <td>139.51</td>\n",
       "      <td>728</td>\n",
       "      <td>717</td>\n",
       "      <td>...</td>\n",
       "      <td>615.285714</td>\n",
       "      <td>0.165312</td>\n",
       "      <td>621.285714</td>\n",
       "      <td>0.168544</td>\n",
       "      <td>0</td>\n",
       "      <td>1.706770</td>\n",
       "      <td>1128.40</td>\n",
       "      <td>172.08</td>\n",
       "      <td>1132.56</td>\n",
       "      <td>811.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>-17.54</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>41</td>\n",
       "      <td>82.48</td>\n",
       "      <td>114.86</td>\n",
       "      <td>14.91</td>\n",
       "      <td>117.66</td>\n",
       "      <td>731</td>\n",
       "      <td>722</td>\n",
       "      <td>...</td>\n",
       "      <td>628.750000</td>\n",
       "      <td>0.148310</td>\n",
       "      <td>634.875000</td>\n",
       "      <td>0.134082</td>\n",
       "      <td>0</td>\n",
       "      <td>2.031615</td>\n",
       "      <td>1279.25</td>\n",
       "      <td>166.06</td>\n",
       "      <td>1310.40</td>\n",
       "      <td>918.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>-15.43</td>\n",
       "      <td>-16.6</td>\n",
       "      <td>53</td>\n",
       "      <td>73.98</td>\n",
       "      <td>101.72</td>\n",
       "      <td>15.55</td>\n",
       "      <td>104.67</td>\n",
       "      <td>730</td>\n",
       "      <td>727</td>\n",
       "      <td>...</td>\n",
       "      <td>721.500000</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>725.375000</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0</td>\n",
       "      <td>2.253939</td>\n",
       "      <td>1474.60</td>\n",
       "      <td>225.37</td>\n",
       "      <td>1517.34</td>\n",
       "      <td>1072.436667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>-14.60</td>\n",
       "      <td>-16.3</td>\n",
       "      <td>65</td>\n",
       "      <td>64.62</td>\n",
       "      <td>86.86</td>\n",
       "      <td>13.09</td>\n",
       "      <td>93.92</td>\n",
       "      <td>727</td>\n",
       "      <td>729</td>\n",
       "      <td>...</td>\n",
       "      <td>723.375000</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>725.125000</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>0</td>\n",
       "      <td>2.575187</td>\n",
       "      <td>1548.51</td>\n",
       "      <td>233.28</td>\n",
       "      <td>1674.40</td>\n",
       "      <td>1152.063333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  board_t  env_t  light_strength  efficiency  efficiency_A  efficiency_B  \\\n",
       "2  10   -19.14  -17.4              34       80.55        106.32         16.98   \n",
       "3  11   -18.73  -17.3              30       99.90        139.00         21.20   \n",
       "4  12   -17.54  -17.0              41       82.48        114.86         14.91   \n",
       "6  14   -15.43  -16.6              53       73.98        101.72         15.55   \n",
       "7  15   -14.60  -16.3              65       64.62         86.86         13.09   \n",
       "\n",
       "   efficiency_C  V_A  V_B     ...       V_B_avg_sequence  V_B_exception_ratio  \\\n",
       "2        118.36  729  709     ...             597.666667             0.186280   \n",
       "3        139.51  728  717     ...             615.285714             0.165312   \n",
       "4        117.66  731  722     ...             628.750000             0.148310   \n",
       "6        104.67  730  727     ...             721.500000             0.007623   \n",
       "7         93.92  727  729     ...             723.375000             0.007776   \n",
       "\n",
       "   V_C_avg_sequence  V_C_exception_ratio  is_abnormal  avg_value  P_A_cor  \\\n",
       "2        603.666667             0.200994            0   1.692575   976.86   \n",
       "3        621.285714             0.168544            0   1.706770  1128.40   \n",
       "4        634.875000             0.134082            0   2.031615  1279.25   \n",
       "6        725.375000             0.000862            0   2.253939  1474.60   \n",
       "7        725.125000             0.003965            0   2.575187  1548.51   \n",
       "\n",
       "   P_B_cor  P_C_cor    P_avg_cor  \n",
       "2   155.98  1087.50   740.113333  \n",
       "3   172.08  1132.56   811.013333  \n",
       "4   166.06  1310.40   918.570000  \n",
       "6   225.37  1517.34  1072.436667  \n",
       "7   233.28  1674.40  1152.063333  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 40)\n",
      "(8918, 40)\n"
     ]
    }
   ],
   "source": [
    "#Train集去重\n",
    "print(train_data.shape)\n",
    "train_data = train_data.drop_duplicates(train_data.columns.drop(['ID','avg_value','P_A_cor','P_B_cor','P_C_cor','P_avg_cor','V_B_avg_sequence','V_B_exception_ratio','V_A_avg_sequence','V_A_exception_ratio','V_C_avg_sequence','V_C_exception_ratio','I_B_avg_sequence','I_B_exception_ratio','I_A_avg_sequence','I_A_exception_ratio','I_C_avg_sequence','I_C_exception_ratio',]), keep='first')\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据\n",
    "def generate_train_data(train_data, test_data, poly=False, select=False):\n",
    "    y = train_data['y']\n",
    "    X = train_data.drop(['y','ID','is_train'], axis=1)\n",
    "    sub_data = test_data.drop(['y','ID','is_train'], axis=1)\n",
    "    \n",
    "    polynm = None\n",
    "    if poly:\n",
    "        from sklearn.preprocessing import PolynomialFeatures\n",
    "        polynm = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "        X = polynm.fit_transform(X)\n",
    "        sub_data = polynm.transform(sub_data)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "    \n",
    "    sm = None\n",
    "    if select:\n",
    "        from sklearn.feature_selection import SelectFromModel\n",
    "        sm = SelectFromModel(GradientBoostingRegressor(random_state=2))\n",
    "        X_train = sm.fit_transform(X_train, y_train)\n",
    "        X_test = sm.transform(X_test)\n",
    "        sub_data = sm.transform(sub_data)\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test, sub_data, sm, polynm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, sub_data, sm, polynm = generate_train_data(train_data, test_data, poly=False, select=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X_train = np.concatenate([X_train, X_test])\n",
    "all_y_train = np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据\n",
    "# def generate_train_data(train_data, test_data, poly=False, select=False):\n",
    "#     y = train_data['y']\n",
    "#     X = train_data.drop(['y','ID','is_train'], axis=1)\n",
    "#     sub_data = test_data.drop(['y','ID','is_train'], axis=1)\n",
    "    \n",
    "#     polynm = None\n",
    "#     if poly:\n",
    "#         from sklearn.preprocessing import PolynomialFeatures\n",
    "#         polynm = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "#         X = polynm.fit_transform(X)\n",
    "#         sub_data = polynm.transform(sub_data)\n",
    "        \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "    \n",
    "#     sm = None\n",
    "#     if select:\n",
    "#         from sklearn.feature_selection import SelectFromModel\n",
    "#         sm = SelectFromModel(GradientBoostingRegressor(random_state=2))\n",
    "#         X_train = sm.fit_transform(X_train, y_train)\n",
    "#         X_test = sm.transform(X_test)\n",
    "#         sub_data = sm.transform(sub_data)\n",
    "        \n",
    "#     return X_train, X_test, y_train, y_test, sub_data, sm, polynm\n",
    "\n",
    "def cal_score(mse):\n",
    "    if isinstance(mse, float):\n",
    "        return 1 / (1 + math.sqrt(mse))\n",
    "    else:\n",
    "        return np.divide(1, 1 + np.sqrt(mse))\n",
    "#  定义交叉验证函数  \n",
    "def cross_validation_test(models, train_X_data, train_y_data, cv=5):\n",
    "    model_name, mse_avg, score_avg = [], [], []\n",
    "    for i, model in enumerate(models):\n",
    "        print(i + 1,'- Model:', str(model).split('(')[0])\n",
    "        model_name.append(str(i + 1) + '.' + str(model).split('(')[0])\n",
    "        nmse = cross_val_score(model, train_X_data[i], train_y_data[i], cv=cv, scoring='neg_mean_squared_error')\n",
    "        avg_mse = np.average(-nmse)\n",
    "        scores = cal_score(-nmse)\n",
    "        avg_score = np.average(scores)\n",
    "        mse_avg.append(avg_mse)\n",
    "        score_avg.append(avg_score)\n",
    "        print('MSE:', -nmse)\n",
    "        print('Score:', scores)\n",
    "        print('Average XGB - MSE:', avg_mse, ' - Score:', avg_score, '\\n')\n",
    "    res = pd.DataFrame()\n",
    "    res['Model'] = model_name\n",
    "    res['Avg MSE'] = mse_avg\n",
    "    res['Avg Score'] = score_avg\n",
    "    return res\n",
    "\n",
    "# def add_newid(df):\n",
    "#     ID = df[\"ID\"]\n",
    "#     df[\"new_id\"]=(np.mod(ID,205))\n",
    "#     return df\n",
    "# def add_avg(df):\n",
    "#     array = np.array(df[\"P_avg\"])\n",
    "#     newarray=[]\n",
    "#     num = 0\n",
    "#     for i in np.arange(len(array)):\n",
    "#         for j in np.arange(10):\n",
    "#             if i<10:\n",
    "#                 num = (array[j-1]+array[j-2]+array[j-3])/3\n",
    "#             if i>=10:\n",
    "#                 num = (array[i-1]+array[i-2]+array[i-3]+array[i-5]+array[i-6]+array[i-7]+array[i-8]+array[i-9])/9\n",
    "#         newarray.append(num)\n",
    "#     df[\"old_SoCalledSF_P_avg\"] = newarray\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbt1 = xgb.XGBRegressor(n_estimators=950, max_depth=3, max_features='sqrt', random_state=321, n_jobs=8)\n",
    "xgbt2 = xgb.XGBRegressor(n_estimators=1000, max_depth=3, max_features='sqrt', random_state=456, n_jobs=8)\n",
    "xgbt3 = xgb.XGBRegressor(n_estimators=1100, max_depth=3, max_features='sqrt', random_state=789, n_jobs=8)\n",
    "# n_estimators=1000  max_depth=5  'sqrt'  GradientBoostingRegressor 最佳参数 ,learning_rate=0.08\n",
    "gbdt1 = GradientBoostingRegressor(n_estimators=800, max_depth=4, max_features='log2', random_state=123,learning_rate=0.08)\n",
    "gbdt2 = GradientBoostingRegressor(n_estimators=900, max_depth=4, max_features='log2', random_state=456,learning_rate=0.08)\n",
    "gbdt3 = GradientBoostingRegressor(n_estimators=1000, max_depth=5, max_features='log2', random_state=789,learning_rate=0.08)\n",
    "# n_estimators=700, max_features='auto', random_state=2, n_jobs=8,max_depth=10\n",
    "forest1 = RandomForestRegressor(n_estimators=800, max_features='sqrt', random_state=7, n_jobs=8)\n",
    "forest2 = RandomForestRegressor(n_estimators=900, max_features='log2', random_state=9, n_jobs=8)\n",
    "forest3 = RandomForestRegressor(n_estimators=900, max_features='sqrt', random_state=11, n_jobs=8) \n",
    "\n",
    "lgb1 = LGBMRegressor(n_estimators=900, max_depth=5, random_state=5, n_jobs=8) \n",
    "lgb2 = LGBMRegressor(n_estimators=850, max_depth=4, random_state=7, n_jobs=8)\n",
    "lgb3 = LGBMRegressor(n_estimators=720, max_depth=4, random_state=9, n_jobs=8)\n",
    "\n",
    "# xgbt1 = xgb.XGBRegressor(n_estimators=950, max_depth=3, max_features='sqrt', random_state=2, n_jobs=8)\n",
    "# xgbt2 = xgb.XGBRegressor(n_estimators=1000, max_depth=3, max_features='sqrt', random_state=3, n_jobs=8)\n",
    "# xgbt3 = xgb.XGBRegressor(n_estimators=1100, max_depth=3, max_features='sqrt', random_state=4, n_jobs=8)\n",
    "\n",
    "# gbdt1 = GradientBoostingRegressor(n_estimators=500, max_depth=3, max_features='sqrt', random_state=2)\n",
    "# gbdt2 = GradientBoostingRegressor(n_estimators=400, max_depth=3, max_features='sqrt', random_state=3)\n",
    "# gbdt3 = GradientBoostingRegressor(n_estimators=500, max_depth=4, max_features='log2', random_state=4)\n",
    "\n",
    "# forest1 = RandomForestRegressor(n_estimators=300, max_features='sqrt', random_state=2, n_jobs=8)\n",
    "# forest2 = RandomForestRegressor(n_estimators=300, max_features='log2', random_state=3, n_jobs=8)\n",
    "# forest3 = RandomForestRegressor(n_estimators=600, max_features='sqrt', random_state=4, n_jobs=8) \n",
    "\n",
    "# lgb1 = LGBMRegressor(n_estimators=900, max_depth=5, random_state=2, n_jobs=8) \n",
    "# lgb2 = LGBMRegressor(n_estimators=850, max_depth=4, random_state=3, n_jobs=8)\n",
    "# lgb3 = LGBMRegressor(n_estimators=720, max_depth=4, random_state=4, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - Model: XGBRegressor\n",
      "MSE: [0.01362767 0.03184425 0.01639666 0.08434111 0.01868022]\n",
      "Score: [0.89546551 0.84857258 0.88648597 0.77494425 0.87975847]\n",
      "Average XGB - MSE: 0.03297798205217808  - Score: 0.8570453566872016 \n",
      "\n",
      "2 - Model: XGBRegressor\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-bcd67be43f97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_y_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     ]\n\u001b[0;32m     20\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-17-132778a4d749>\u001b[0m in \u001b[0;36mcross_validation_test\u001b[1;34m(models, train_X_data, train_y_data, cv)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'- Model:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'('\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mmodel_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'('\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mnmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_X_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mavg_mse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcal_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mnmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m   1579\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1580\u001b[0m                                               fit_params)\n\u001b[1;32m-> 1581\u001b[1;33m                       for train, test in cv)\n\u001b[0m\u001b[0;32m   1582\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[0;32m   1673\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1675\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1677\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[0;32m    322\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                               verbose_eval=verbose, xgb_model=xgb_model)\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python36\\lib\\site-packages\\xgboost-0.72-py3.6.egg\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m-> 1021\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1022\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "\n",
    "cross_validation_test(\n",
    "    models=[    \n",
    "        xgbt1, xgbt2, xgbt3,\n",
    "        gbdt1, gbdt2, gbdt3,\n",
    "        forest1, forest2, forest3,\n",
    "        lgb1, lgb2, lgb3\n",
    "    ],\n",
    "    train_X_data=[\n",
    "        all_X_train, all_X_train, all_X_train, all_X_train,\n",
    "        all_X_train, all_X_train, all_X_train, all_X_train,\n",
    "        all_X_train, all_X_train, all_X_train, all_X_train\n",
    "    ],\n",
    "    train_y_data=[\n",
    "        all_y_train, all_y_train, all_y_train, all_y_train,\n",
    "        all_y_train, all_y_train, all_y_train, all_y_train,\n",
    "        all_y_train, all_y_train, all_y_train, all_y_train\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrs = [\n",
    "    xgbt1, gbdt1, forest1, lgb1,\n",
    "    xgbt2, gbdt2, forest2, lgb2,\n",
    "    xgbt3, gbdt3, forest3, lgb3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stacker(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "    \n",
    "    # X: 原始训练集, y: 原始训练集真实值, predict_data: 原始待预测数据\n",
    "    def fit_predict(self, X, y, predict_data):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(predict_data)\n",
    "\n",
    "        folds = list(KFold(n_splits=self.n_splits, shuffle=False, random_state=2018).split(X, y))\n",
    "        \n",
    "        # 以基学习器预测结果为特征的 stacker的训练数据 与 stacker预测数据\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_predict = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, regr in enumerate(self.base_models):\n",
    "            print(i + 1, 'Base model:', str(regr).split('(')[0])\n",
    "            S_predict_i = np.zeros((T.shape[0], self.n_splits))\n",
    "            \n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                # 将X分为训练集与测试集\n",
    "                X_train, y_train, X_test, y_test = X[train_idx], y[train_idx], X[test_idx], y[test_idx]\n",
    "                print ('Fit fold', (j+1), '...')\n",
    "                regr.fit(X_train, y_train)\n",
    "                    y_pred = regr.predict(X_test)                \n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_predict_i[:, j] = regr.predict(T)\n",
    "            \n",
    "            S_predict[:, i] = S_predict_i.mean(axis=1)\n",
    "\n",
    "        nmse_score = cross_val_score(self.stacker, S_train, y, cv=5, scoring='neg_mean_squared_error')\n",
    "        print('CV MSE:', -nmse_score)\n",
    "        print('Stacker AVG MSE:', -nmse_score.mean(), 'Stacker AVG Score:', np.mean(np.divide(1, 1 + np.sqrt(-nmse_score))))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        res = self.stacker.predict(S_predict)\n",
    "        return res, S_train, S_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "2 Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "3 Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "4 Base model: LGBMRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "5 Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "6 Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "7 Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "8 Base model: LGBMRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "9 Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "10 Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "11 Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "12 Base model: LGBMRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "CV MSE: [0.01110849 0.0193132  0.01149076 0.0770924  0.01408286]\n",
      "Stacker AVG MSE: 0.026617539555857533 Stacker AVG Score: 0.8724844144895535\n"
     ]
    }
   ],
   "source": [
    "stacking_model = SVR(C=100, gamma=0.01, epsilon=0.01)\n",
    "stacker = Stacker(5, stacking_model, regrs)\n",
    "pred_stack, S_train_data, S_predict_data = stacker.fit_predict(all_X_train, all_y_train, sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['score'] = pred_stack\n",
    "\n",
    "index = df_result[df_result['ID'].isin(special_missing_ID)].index\n",
    "df_result.loc[index, 'score'] = 0.379993053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8409.000000\n",
       "mean        5.696030\n",
       "std         3.460621\n",
       "min        -0.454089\n",
       "25%         2.515640\n",
       "50%         5.704791\n",
       "75%         8.890597\n",
       "max        12.150429\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('../result/081303_08724.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
