{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_cols = {'ID':'ID', \n",
    " '板温':'board_t', \n",
    " '现场温度':'env_t', \n",
    " '光照强度':'light_strength', \n",
    " '转换效率':'efficiency', \n",
    " '转换效率A':'efficiency_A', \n",
    " '转换效率B':'efficiency_B', \n",
    " '转换效率C':'efficiency_C', \n",
    " '电压A':'V_A',\n",
    " '电压B':'V_B', \n",
    " '电压C':'V_C', \n",
    " '电流A':'I_A', \n",
    " '电流B':'I_B', \n",
    " '电流C':'I_C', \n",
    " '功率A':'P_A', \n",
    " '功率B':'P_B', \n",
    " '功率C':'P_C', \n",
    " '平均功率':'P_avg', \n",
    " '风速':'wind_speed',\n",
    " '风向':'wind_direction', \n",
    " '发电量':'y'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_val(preds, train_data):\n",
    "    label = train_data.get_label()\n",
    "    return 'score', 1/(1+np.sqrt(mean_squared_error(preds, label))), True\n",
    "def my_obj(preds, train_data):\n",
    "    labels = train_deata.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/public_raw.train.csv')\n",
    "test = pd.read_csv('../data/public_raw.test.csv')\n",
    "\n",
    "train_len = train.shape[0]\n",
    "\n",
    "train['is_train']=1\n",
    "test['is_train']=0\n",
    "\n",
    "df = pd.concat([train, test],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index=str, columns=rep_cols, inplace=True)\n",
    "\n",
    "df.sort_values(by=['ID'],ascending=True, inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前二后二\n",
    "next_one = []\n",
    "prev_one = []\n",
    "next_id = []\n",
    "prev_id = []\n",
    "\n",
    "second_next_one = []\n",
    "second_prev_one = []\n",
    "\n",
    "df_len = df.shape[0]\n",
    "\n",
    "i_y =df.columns.get_loc(\"y\")\n",
    "\n",
    "def get_prev_nn_index(cur_i):\n",
    "    prev_i = cur_i-1\n",
    "    while(prev_i>=0 and pd.isnull(df.iat[prev_i,i_y])):\n",
    "        prev_i-=1\n",
    "    return prev_i\n",
    "\n",
    "def get_next_nn_index(cur_i):\n",
    "    prev_i = cur_i+1\n",
    "    while(prev_i<df_len and pd.isnull(df.iat[prev_i,i_y])):\n",
    "        prev_i+=1\n",
    "    return prev_i\n",
    "\n",
    "for i in range(df_len):\n",
    "    f_pre_i=get_prev_nn_index(i)\n",
    "    if(f_pre_i)<0:\n",
    "        prev_one.append(np.nan)\n",
    "        prev_id.append(0)\n",
    "    else:\n",
    "        prev_one.append(df.iat[f_pre_i,i_y])\n",
    "        prev_id.append(f_pre_i)\n",
    "        \n",
    "    s_pre_i=get_prev_nn_index(f_pre_i)\n",
    "    if (s_pre_i)<0:\n",
    "        second_prev_one.append(np.nan)\n",
    "    else:\n",
    "        second_prev_one.append(df.iat[s_pre_i,i_y])\n",
    "    \n",
    "    f_next_i=get_next_nn_index(i)\n",
    "    if(f_next_i<df_len):\n",
    "        next_one.append(df.iat[f_next_i,i_y])\n",
    "        next_id.append(f_next_i)\n",
    "    else:\n",
    "        next_one.append(np.nan)\n",
    "        next_id.append(df_len)\n",
    "    \n",
    "    s_next_i=get_next_nn_index(f_next_i)\n",
    "    if(s_next_i<df_len):\n",
    "        second_next_one.append(df.iat[s_next_i,i_y])\n",
    "    else:\n",
    "        second_next_one.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "df['next_value'] = next_one\n",
    "df['prev_value'] = prev_one\n",
    "df['avg_value'] = np.nanmean([df['next_value'], df['prev_value']],axis=0)\n",
    "df['next_ID'] = next_id\n",
    "df['prev_ID'] = prev_id\n",
    "# df['interpolation_ID'] = df['prev_value']+(df['ID']-df['prev_ID'])/(df['next_ID']-df['prev_ID'])*(df['next_value']-df['prev_value'])\n",
    "# df['interpolation_ls'] = df['prev_value']+(df['light_strength']-df['prev_ls'])/(1+df['next_ls']-df['prev_ls'])*(df['next_value']-df['prev_value'])\n",
    "\n",
    "df['second_prev_value'] = second_prev_one\n",
    "df['second_next_value'] = second_next_one\n",
    "# df['avg_value_four'] = np.nanmean([df['second_next_value'],df['next_value'], df['prev_value'],df['second_prev_value']],axis=0)\n",
    "\n",
    "\n",
    "# df['rolling_seven'] = df['y'].rolling(7,center=True,min_periods=0).apply(lambda x: np.nanmean(x[[0,1,2,4,5,6]]))\n",
    "rolling_mask_four = [-i for i in range(1,2)]+[i for i in range(1,2)]\n",
    "rolling_mask_six = [-i for i in range(1,3)]+[i for i in range(1,3)]\n",
    "rolling_mask_eight = [-i for i in range(1,4)]+[i for i in range(1,4)]\n",
    "rolling_mask_ten = [-i for i in range(1,5)]+[i for i in range(1,5)]\n",
    "# df['rolling_four_y'] = np.nanmean([df['y'].shift(i) for i in rolling_mask_four],axis=0)\n",
    "# df['rolling_six_y'] = np.nanmean([df['y'].shift(i) for i in rolling_mask_six],axis=0)\n",
    "df['rolling_eight_y'] = np.nanmean([df['y'].shift(i) for i in rolling_mask_eight],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['magic_feature'] = df['ID']%190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['is_train']==1]\n",
    "test = df[df['is_train']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 50,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = lgb.Dataset(df_train, y_train, silent=True) \n",
    "cv_results = lgb.cv(params, data_train, num_boost_round=1000, nfold=5, stratified=False, shuffle=True, metrics='rmse', early_stopping_rounds=50, verbose_eval=50, show_stdv=True, seed=0) \n",
    "print('best n_estimators:', len(cv_results['rmse-mean'])) \n",
    "print('best cv score:', cv_results['rmse-mean'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0583624\tvalid's score: 0.805423\n",
      "Early stopping, best iteration is:\n",
      "[856]\tvalid's l2: 0.0579284\tvalid's score: 0.806008\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0186443\tvalid's score: 0.87986\n",
      "Early stopping, best iteration is:\n",
      "[708]\tvalid's l2: 0.0181785\tvalid's score: 0.881191\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid's l2: 0.0125331\tvalid's score: 0.89932\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0391504\tvalid's score: 0.834819\n",
      "[1000]\tvalid's l2: 0.0373976\tvalid's score: 0.837953\n",
      "[1500]\tvalid's l2: 0.0371253\tvalid's score: 0.838448\n",
      "Early stopping, best iteration is:\n",
      "[1550]\tvalid's l2: 0.0371023\tvalid's score: 0.83849\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid's l2: 0.015838\tvalid's score: 0.888218\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0594399\tvalid's score: 0.803986\n",
      "[1000]\tvalid's l2: 0.0582135\tvalid's score: 0.805623\n",
      "Early stopping, best iteration is:\n",
      "[1076]\tvalid's l2: 0.0581556\tvalid's score: 0.805701\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0154092\tvalid's score: 0.889574\n",
      "Early stopping, best iteration is:\n",
      "[722]\tvalid's l2: 0.0152858\tvalid's score: 0.889968\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid's l2: 0.0227367\tvalid's score: 0.86897\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0317394\tvalid's score: 0.848784\n",
      "Early stopping, best iteration is:\n",
      "[717]\tvalid's l2: 0.0313675\tvalid's score: 0.849539\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0147992\tvalid's score: 0.891542\n",
      "[1000]\tvalid's l2: 0.0144441\tvalid's score: 0.892711\n",
      "Early stopping, best iteration is:\n",
      "[976]\tvalid's l2: 0.0144167\tvalid's score: 0.892802\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.032042\tvalid's score: 0.848174\n",
      "[1000]\tvalid's l2: 0.0315131\tvalid's score: 0.849243\n",
      "Early stopping, best iteration is:\n",
      "[945]\tvalid's l2: 0.031385\tvalid's score: 0.849504\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0531114\tvalid's score: 0.812705\n",
      "[1000]\tvalid's l2: 0.0525034\tvalid's score: 0.813579\n",
      "Early stopping, best iteration is:\n",
      "[1118]\tvalid's l2: 0.0523983\tvalid's score: 0.813731\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0134224\tvalid's score: 0.896174\n",
      "Early stopping, best iteration is:\n",
      "[413]\tvalid's l2: 0.0133647\tvalid's score: 0.896374\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid's l2: 0.0126233\tvalid's score: 0.898995\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0291377\tvalid's score: 0.854191\n",
      "[1000]\tvalid's l2: 0.0284637\tvalid's score: 0.855643\n",
      "Early stopping, best iteration is:\n",
      "[1252]\tvalid's l2: 0.0282824\tvalid's score: 0.856037\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[298]\tvalid's l2: 0.0178332\tvalid's score: 0.882191\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[323]\tvalid's l2: 0.0515646\tvalid's score: 0.814944\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0352023\tvalid's score: 0.842018\n",
      "Early stopping, best iteration is:\n",
      "[616]\tvalid's l2: 0.0349751\tvalid's score: 0.842448\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0288982\tvalid's score: 0.854705\n",
      "Early stopping, best iteration is:\n",
      "[830]\tvalid's l2: 0.0279417\tvalid's score: 0.856782\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0206337\tvalid's score: 0.874398\n",
      "Early stopping, best iteration is:\n",
      "[723]\tvalid's l2: 0.0204622\tvalid's score: 0.874855\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0150914\tvalid's score: 0.890593\n",
      "[1000]\tvalid's l2: 0.0146853\tvalid's score: 0.891915\n",
      "Early stopping, best iteration is:\n",
      "[1078]\tvalid's l2: 0.0146452\tvalid's score: 0.892047\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0867386\tvalid's score: 0.772491\n",
      "[1000]\tvalid's l2: 0.0807346\tvalid's score: 0.778732\n",
      "[1500]\tvalid's l2: 0.0783273\tvalid's score: 0.781329\n",
      "[2000]\tvalid's l2: 0.0772434\tvalid's score: 0.782517\n",
      "[2500]\tvalid's l2: 0.0767628\tvalid's score: 0.783048\n",
      "Early stopping, best iteration is:\n",
      "[2843]\tvalid's l2: 0.0766594\tvalid's score: 0.783162\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid's l2: 0.0166803\tvalid's score: 0.88562\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[347]\tvalid's l2: 0.0209566\tvalid's score: 0.873543\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid's l2: 0.0220385\tvalid's score: 0.870736\n",
      "local cv: 0.8599033635854586\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'mse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 0\n",
    "}\n",
    "# 同样的条件下，此参数设置达到local cv: 0.8575832021441638\n",
    "\n",
    "\n",
    "test_predicts = []\n",
    "val_preds = []\n",
    "\n",
    "# log_test_predicts = []\n",
    "# log_val_predicts = []\n",
    "for idx, seed in enumerate([1,2,3,4,5]):\n",
    "    kf = KFold(5, shuffle=True, random_state=seed)\n",
    "    \n",
    "    val_preds.append(np.zeros(train.shape[0]))\n",
    "    for n_fold, (tra_idx, val_idx) in enumerate(kf.split(train)):\n",
    "        tra = train.iloc[tra_idx]\n",
    "        val = train.iloc[val_idx]\n",
    "        tst = test.copy()\n",
    "\n",
    "#         grouper = ['bin_ls','bin_env_t','bin_board_t']\n",
    "#         x = tra.groupby(grouper)['y'].agg({'target_encoding_mean':'mean',\n",
    "#                                            'target_encoding_max':'max',\n",
    "#                                            'target_encoding_min':'min',\n",
    "#                                            'target_encoding_median':'median',\n",
    "#                                            'target_encoding_var':'var',\n",
    "#                                            'target_encoding_count':'count'}).reset_index()\n",
    "#         tra = tra.merge(x, on=grouper, how='left')\n",
    "#         val = val.merge(x, on= grouper , how ='left')\n",
    "#         tst = tst.merge(x, on=grouper, how='left')\n",
    "        predictor = [c for c in tra.columns.tolist() if c not in['y','is_train','I_B','I_C']]\n",
    "\n",
    "        train_set = lightgbm.Dataset(\n",
    "            tra[predictor],\n",
    "            tra['y']\n",
    "        )\n",
    "\n",
    "        validation_set = lightgbm.Dataset(\n",
    "            val[predictor],\n",
    "            val['y']\n",
    "        )\n",
    "\n",
    "        model = lightgbm.train(params, train_set, num_boost_round=5000,\n",
    "                              valid_sets= [validation_set],\n",
    "                              valid_names=['valid'],\n",
    "                              early_stopping_rounds=100,\n",
    "                               feval=my_val,\n",
    "                              verbose_eval=500)\n",
    "\n",
    "        val_preds[idx][val_idx] = model.predict(val[predictor])\n",
    "        test_predicts.append(model.predict(tst[predictor]))\n",
    "\n",
    "print('local cv:',1/(1+np.sqrt(mean_squared_error(train['y'],np.mean(val_preds,axis=0)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [c for c in tra.columns.tolist() if c not in ['y','is_train','I_B','I_C']]\n",
    "param_test1 = {'num_iterations':range(100,160,10)}\n",
    "gsearch1 = GridSearchCV(\n",
    "estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(train[predictors],train[target])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
