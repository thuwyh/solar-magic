{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_cols = {'ID':'ID', \n",
    " '板温':'board_t', \n",
    " '现场温度':'env_t', \n",
    " '光照强度':'light_strength', \n",
    " '转换效率':'efficiency', \n",
    " '转换效率A':'efficiency_A', \n",
    " '转换效率B':'efficiency_B', \n",
    " '转换效率C':'efficiency_C', \n",
    " '电压A':'V_A',\n",
    " '电压B':'V_B', \n",
    " '电压C':'V_C', \n",
    " '电流A':'I_A', \n",
    " '电流B':'I_B', \n",
    " '电流C':'I_C', \n",
    " '功率A':'P_A', \n",
    " '功率B':'P_B', \n",
    " '功率C':'P_C', \n",
    " '平均功率':'P_avg', \n",
    " '风速':'wind_speed',\n",
    " '风向':'wind_direction', \n",
    " '发电量':'y'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_val(preds, train_data):\n",
    "    label = train_data.get_label()\n",
    "    return 'score', 1/(1+np.sqrt(mean_squared_error(preds, label))), True\n",
    "\n",
    "def my_obj(preds, train_data):\n",
    "    labels = train_deata.get_label()\n",
    "    \n",
    "\n",
    "train = pd.read_csv('../data/public_raw.train.csv')\n",
    "test = pd.read_csv('../data/public_raw.test.csv')\n",
    "\n",
    "train_len = train.shape[0]\n",
    "\n",
    "train['is_train']=1\n",
    "test['is_train']=0\n",
    "\n",
    "df = pd.concat([train, test],sort=False)\n",
    "\n",
    "df.rename(index=str, columns=rep_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#异常值处理\n",
    "# 改用均值\n",
    "correct_dict = {\n",
    "    'V_A':(600,700),\n",
    "    'V_B':(600,700),\n",
    "    'V_C':(600,700),\n",
    "    'P_A':(0,10000),\n",
    "    'P_B':(0,10000),\n",
    "    'P_C':(0,10000),\n",
    "    'P_avg':(0,10000)\n",
    "}\n",
    "cols = [c for c in df.columns.tolist() if c!='y' and c!='ID']\n",
    "for c in correct_dict.keys():\n",
    "    df[c+'_is_out_of_upper'] = (df[c]>correct_dict[c][1]).astype(np.int32)\n",
    "    df[c+'_is_out_of_lower'] = (df[c]<correct_dict[c][0]).astype(np.int32)\n",
    "#     df.loc[(df[c]>df[c].quantile(0.99))|(df[c]<df[c].quantile(0.01)),c]=np.nan\n",
    "#     df[c].fillna(df[c].mean(),inplace=True)\n",
    "#     df[c] = np.clip(df[c],df[c].quantile(.01),df[c].quantile(0.99))\n",
    "#     df[c] = np.clip(df[c], correct_dict[c][0], correct_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>board_t</th>\n",
       "      <th>env_t</th>\n",
       "      <th>light_strength</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>efficiency_A</th>\n",
       "      <th>efficiency_B</th>\n",
       "      <th>efficiency_C</th>\n",
       "      <th>V_A</th>\n",
       "      <th>V_B</th>\n",
       "      <th>...</th>\n",
       "      <th>V_C_is_out_of_upper</th>\n",
       "      <th>V_C_is_out_of_lower</th>\n",
       "      <th>P_A_is_out_of_upper</th>\n",
       "      <th>P_A_is_out_of_lower</th>\n",
       "      <th>P_B_is_out_of_upper</th>\n",
       "      <th>P_B_is_out_of_lower</th>\n",
       "      <th>P_C_is_out_of_upper</th>\n",
       "      <th>P_C_is_out_of_lower</th>\n",
       "      <th>P_avg_is_out_of_upper</th>\n",
       "      <th>P_avg_is_out_of_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>-19.14</td>\n",
       "      <td>-17.4</td>\n",
       "      <td>34</td>\n",
       "      <td>80.55</td>\n",
       "      <td>106.32</td>\n",
       "      <td>16.98</td>\n",
       "      <td>118.36</td>\n",
       "      <td>729</td>\n",
       "      <td>709</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>-18.73</td>\n",
       "      <td>-17.3</td>\n",
       "      <td>30</td>\n",
       "      <td>99.90</td>\n",
       "      <td>139.00</td>\n",
       "      <td>21.20</td>\n",
       "      <td>139.51</td>\n",
       "      <td>728</td>\n",
       "      <td>717</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>-17.54</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>41</td>\n",
       "      <td>82.48</td>\n",
       "      <td>114.86</td>\n",
       "      <td>14.91</td>\n",
       "      <td>117.66</td>\n",
       "      <td>731</td>\n",
       "      <td>722</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>-15.43</td>\n",
       "      <td>-16.6</td>\n",
       "      <td>53</td>\n",
       "      <td>73.98</td>\n",
       "      <td>101.72</td>\n",
       "      <td>15.55</td>\n",
       "      <td>104.67</td>\n",
       "      <td>730</td>\n",
       "      <td>727</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>-14.60</td>\n",
       "      <td>-16.3</td>\n",
       "      <td>65</td>\n",
       "      <td>64.62</td>\n",
       "      <td>86.86</td>\n",
       "      <td>13.09</td>\n",
       "      <td>93.92</td>\n",
       "      <td>727</td>\n",
       "      <td>729</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  board_t  env_t  light_strength  efficiency  efficiency_A  efficiency_B  \\\n",
       "0  10   -19.14  -17.4              34       80.55        106.32         16.98   \n",
       "1  11   -18.73  -17.3              30       99.90        139.00         21.20   \n",
       "2  12   -17.54  -17.0              41       82.48        114.86         14.91   \n",
       "3  14   -15.43  -16.6              53       73.98        101.72         15.55   \n",
       "4  15   -14.60  -16.3              65       64.62         86.86         13.09   \n",
       "\n",
       "   efficiency_C  V_A  V_B          ...            V_C_is_out_of_upper  \\\n",
       "0        118.36  729  709          ...                              1   \n",
       "1        139.51  728  717          ...                              1   \n",
       "2        117.66  731  722          ...                              1   \n",
       "3        104.67  730  727          ...                              1   \n",
       "4         93.92  727  729          ...                              1   \n",
       "\n",
       "   V_C_is_out_of_lower  P_A_is_out_of_upper  P_A_is_out_of_lower  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   P_B_is_out_of_upper  P_B_is_out_of_lower  P_C_is_out_of_upper  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   P_C_is_out_of_lower  P_avg_is_out_of_upper  P_avg_is_out_of_lower  \n",
       "0                    0                      0                      0  \n",
       "1                    0                      0                      0  \n",
       "2                    0                      0                      0  \n",
       "3                    0                      0                      0  \n",
       "4                    0                      0                      0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['ID'],ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_one = []\n",
    "prev_one = []\n",
    "next_id = []\n",
    "prev_id = []\n",
    "next_b_t = []\n",
    "prev_b_t = []\n",
    "next_t = []\n",
    "prev_t = []\n",
    "next_ls = []\n",
    "prev_ls = []\n",
    "\n",
    "df_len = df.shape[0]\n",
    "\n",
    "i_y =df.columns.get_loc(\"y\")\n",
    "i_ls = df.columns.get_loc(\"light_strength\")\n",
    "\n",
    "for i in range(df_len):\n",
    "    prev = i-1\n",
    "    while(prev>=0 and df.iat[prev,i_y]<0):\n",
    "        prev-=1\n",
    "    if prev>=0:\n",
    "        prev_one.append(df.iat[prev,i_y])\n",
    "        prev_id.append(prev)\n",
    "        prev_ls.append(df.iat[prev,i_ls])\n",
    "    else:\n",
    "        prev_one.append(np.nan)\n",
    "        prev_id.append(0)\n",
    "        prev_ls.append(0)\n",
    "        \n",
    "    next = i+1\n",
    "    while(next<df_len and df.iat[next,i_y]<0):\n",
    "        next+=1\n",
    "    if next<df_len:\n",
    "        next_one.append(df.iat[next,i_y])\n",
    "        next_id.append(next)\n",
    "        next_ls.append(df.iat[next,i_ls])\n",
    "    else:\n",
    "        next_one.append(np.nan)\n",
    "        next_id.append(df_len)\n",
    "        next_ls.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['next_value'] = next_one\n",
    "df['prev_value'] = prev_one\n",
    "df['avg_value'] = np.nanmean([df['next_value'], df['prev_value']],axis=0)\n",
    "df['next_ID'] = next_id\n",
    "df['prev_ID'] = prev_id\n",
    "df['next_ls'] = next_ls\n",
    "df['prev_ls'] = prev_ls\n",
    "df['interpolation_ID'] = df['prev_value']+(df['ID']-df['prev_ID'])/(df['next_ID']-df['prev_ID'])*(df['next_value']-df['prev_value'])\n",
    "df['interpolation_ls'] = df['prev_value']+(df['light_strength']-df['prev_ls'])/(1.5+df['next_ls']-df['prev_ls'])*(df['next_value']-df['prev_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['P_A','P_avg','I_A','P_C','I_C','P_B','I_B']\n",
    "target_plus = [c+'_is_out_of_upper' for c in target]+[c+'_is_out_of_lower' for c in target]+target\n",
    "for c in target:\n",
    "    df['log_'+c] = np.log1p(df[c])\n",
    "\n",
    "# 估算功率\n",
    "df['predict_p_1'] = df['P_A']+df['P_B']+df['P_C']\n",
    "df['predict_p_2'] = (df['P_A']*df['efficiency_A'] \\\n",
    "                   +df['P_B']*df['efficiency_B'] \\\n",
    "                   +df['P_C']*df['efficiency_C'])/36000\n",
    "\n",
    "# 第一阶，用其他值预测某些特征\n",
    "\n",
    "params_layer1 = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'mae',\n",
    "    'num_leaves': 48,\n",
    "    'learning_rate': 0.2,\n",
    "#     'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 0\n",
    "}\n",
    "kf_layer1 = KFold(3, shuffle=True, random_state=1991)\n",
    "\n",
    "layer1_result = df[['ID']]\n",
    "\n",
    "for t in target:\n",
    "    print('Now, we are processing',t)\n",
    "    # 特征中去掉t\n",
    "    predictor_t = [c for c in target_plus if c not in['ID','y',t,t+'_is_out_of_upper',t+'_is_out_of_lower']]\n",
    "    \n",
    "    # 初始化结果\n",
    "    val_preds = np.zeros(df.shape[0])\n",
    "    \n",
    "    for n_fold, (tra_idx, val_idx) in enumerate(kf_layer1.split(df)):\n",
    "        tra = df.iloc[tra_idx]\n",
    "        # 删掉有问题的数据\n",
    "        tra.drop(tra[(tra[t+'_is_out_of_upper']==1)|(tra[t+'_is_out_of_lower']==1)].index, inplace=True)\n",
    "        \n",
    "        val = df.iloc[val_idx]\n",
    "        # 删掉有问题的数据\n",
    "        val_c = val.drop(val[(val[t+'_is_out_of_upper']==1)|(val[t+'_is_out_of_lower']==1)].index)\n",
    "\n",
    "        train_set = lightgbm.Dataset(\n",
    "            tra[predictor_t],\n",
    "            tra[t]\n",
    "        )\n",
    "\n",
    "        validation_set = lightgbm.Dataset(\n",
    "            val_c[predictor_t],\n",
    "            val_c[t]\n",
    "        )\n",
    "\n",
    "        model = lightgbm.train(params_layer1, train_set, \n",
    "                               num_boost_round=8000,\n",
    "                              valid_sets= [validation_set],\n",
    "                              valid_names=['valid'],\n",
    "                              early_stopping_rounds=20,\n",
    "                              verbose_eval=1000)\n",
    "\n",
    "        val_preds[val_idx] = model.predict(val[predictor_t])\n",
    "        \n",
    "    # 将结果保存起来\n",
    "    layer1_result['predicted_'+t] = val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1_result.to_pickle('../feature/predicted_value-2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1_result = pd.read_pickle('../feature/predicted_value.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(layer1_result, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in target:\n",
    "    df['diff_'+t] = df[t]-df['predicted_'+t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['magic_feature'] = df['ID']%190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = df.iloc[0:train_len]\n",
    "# test = df.iloc[train_len:]\n",
    "train = df[df['is_train']==1]\n",
    "test = df[df['is_train']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'mse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "predictor = [c for c in train.columns.tolist() if c not in['y','is_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0562015\tvalid's score: 0.808363\n",
      "Early stopping, best iteration is:\n",
      "[562]\tvalid's l2: 0.0561299\tvalid's score: 0.808461\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0193845\tvalid's score: 0.877787\n",
      "Early stopping, best iteration is:\n",
      "[510]\tvalid's l2: 0.0192942\tvalid's score: 0.878037\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid's l2: 0.0136733\tvalid's score: 0.895309\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0390349\tvalid's score: 0.835022\n",
      "[1000]\tvalid's l2: 0.0374865\tvalid's score: 0.837792\n",
      "Early stopping, best iteration is:\n",
      "[1171]\tvalid's l2: 0.0373576\tvalid's score: 0.838025\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[372]\tvalid's l2: 0.016334\tvalid's score: 0.886678\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0609405\tvalid's score: 0.802014\n",
      "[1000]\tvalid's l2: 0.059828\tvalid's score: 0.803473\n",
      "[1500]\tvalid's l2: 0.0594981\tvalid's score: 0.803909\n",
      "Early stopping, best iteration is:\n",
      "[1501]\tvalid's l2: 0.0594978\tvalid's score: 0.803909\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0160669\tvalid's score: 0.887504\n",
      "Early stopping, best iteration is:\n",
      "[423]\tvalid's l2: 0.0158263\tvalid's score: 0.888255\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid's l2: 0.0238014\tvalid's score: 0.866343\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0266065\tvalid's score: 0.85976\n",
      "[1000]\tvalid's l2: 0.0260473\tvalid's score: 0.861036\n",
      "Early stopping, best iteration is:\n",
      "[1023]\tvalid's l2: 0.0260136\tvalid's score: 0.861113\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0139366\tvalid's score: 0.894412\n",
      "Early stopping, best iteration is:\n",
      "[552]\tvalid's l2: 0.0138343\tvalid's score: 0.894759\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[362]\tvalid's l2: 0.0324599\tvalid's score: 0.847338\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0547808\tvalid's score: 0.810338\n",
      "Early stopping, best iteration is:\n",
      "[813]\tvalid's l2: 0.0543575\tvalid's score: 0.810933\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid's l2: 0.0170094\tvalid's score: 0.884627\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0135819\tvalid's score: 0.895623\n",
      "Early stopping, best iteration is:\n",
      "[618]\tvalid's l2: 0.0133772\tvalid's score: 0.896331\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0289279\tvalid's score: 0.854641\n",
      "Early stopping, best iteration is:\n",
      "[698]\tvalid's l2: 0.0286143\tvalid's score: 0.855317\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[382]\tvalid's l2: 0.0182348\tvalid's score: 0.881029\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.052529\tvalid's score: 0.813543\n",
      "Early stopping, best iteration is:\n",
      "[607]\tvalid's l2: 0.0524794\tvalid's score: 0.813614\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0290484\tvalid's score: 0.854383\n",
      "Early stopping, best iteration is:\n",
      "[581]\tvalid's l2: 0.0289323\tvalid's score: 0.854631\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0298456\tvalid's score: 0.85269\n",
      "[1000]\tvalid's l2: 0.0290326\tvalid's score: 0.854416\n",
      "[1500]\tvalid's l2: 0.0288835\tvalid's score: 0.854736\n",
      "Early stopping, best iteration is:\n",
      "[1430]\tvalid's l2: 0.0288659\tvalid's score: 0.854774\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid's l2: 0.0235306\tvalid's score: 0.867004\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[379]\tvalid's l2: 0.0149786\tvalid's score: 0.890958\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0848653\tvalid's score: 0.774403\n",
      "[1000]\tvalid's l2: 0.0779557\tvalid's score: 0.781735\n",
      "[1500]\tvalid's l2: 0.075807\tvalid's score: 0.78411\n",
      "[2000]\tvalid's l2: 0.0748829\tvalid's score: 0.785147\n",
      "[2500]\tvalid's l2: 0.0746073\tvalid's score: 0.785458\n",
      "Early stopping, best iteration is:\n",
      "[2729]\tvalid's l2: 0.0745643\tvalid's score: 0.785506\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid's l2: 0.016393\tvalid's score: 0.886497\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid's l2: 0.0207597\tvalid's score: 0.874063\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid's l2: 0.0222316\tvalid's score: 0.870244\n",
      "local cv: 0.8595713780248281\n"
     ]
    }
   ],
   "source": [
    "test_predicts = []\n",
    "val_preds = []\n",
    "\n",
    "# log_test_predicts = []\n",
    "# log_val_predicts = []\n",
    "for idx, seed in enumerate([1,2,3,4,5]):\n",
    "    kf = KFold(5, shuffle=True, random_state=seed)\n",
    "    \n",
    "    val_preds.append(np.zeros(train.shape[0]))\n",
    "    for n_fold, (tra_idx, val_idx) in enumerate(kf.split(train)):\n",
    "        tra = train.iloc[tra_idx]\n",
    "        val = train.iloc[val_idx]\n",
    "\n",
    "        train_set = lightgbm.Dataset(\n",
    "            tra[predictor],\n",
    "            tra['y']\n",
    "        )\n",
    "\n",
    "        validation_set = lightgbm.Dataset(\n",
    "            val[predictor],\n",
    "            val['y']\n",
    "        )\n",
    "\n",
    "        model = lightgbm.train(params, train_set, num_boost_round=5000,\n",
    "                              valid_sets= [validation_set],\n",
    "                              valid_names=['valid'],\n",
    "                              early_stopping_rounds=100,\n",
    "                               feval=my_val,\n",
    "                              verbose_eval=500)\n",
    "\n",
    "        val_preds[idx][val_idx] = model.predict(val[predictor])\n",
    "        test_predicts.append(model.predict(test[predictor]))\n",
    "        \n",
    "#         train_set = lightgbm.Dataset(\n",
    "#             tra[predictor],\n",
    "#             np.log1p(tra['y'])\n",
    "#         )\n",
    "\n",
    "#         validation_set = lightgbm.Dataset(\n",
    "#             val[predictor],\n",
    "#             np.log1p(val['y'])\n",
    "#         )\n",
    "\n",
    "#         model = lightgbm.train(params, train_set, num_boost_round=5000,\n",
    "#                               valid_sets= [validation_set],\n",
    "#                               valid_names=['valid'],\n",
    "#                               early_stopping_rounds=100,\n",
    "#                                feval=my_val,\n",
    "#                               verbose_eval=500)\n",
    "\n",
    "#         val_preds[idx][val_idx] = np.expm1(model.predict(val[predictor]))\n",
    "#         test_predicts.append(np.expm1(model.predict(test[predictor])))\n",
    "\n",
    "\n",
    "print('local cv:',1/(1+np.sqrt(mean_squared_error(train['y'],np.mean(val_preds,axis=0)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local cv: 0.8590894080898801\n"
     ]
    }
   ],
   "source": [
    "print('local cv:',1/(1+np.sqrt(mean_squared_error(train['y'],np.mean(val_preds,axis=0)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>board_t</th>\n",
       "      <th>env_t</th>\n",
       "      <th>light_strength</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>efficiency_A</th>\n",
       "      <th>efficiency_B</th>\n",
       "      <th>efficiency_C</th>\n",
       "      <th>V_A</th>\n",
       "      <th>V_B</th>\n",
       "      <th>...</th>\n",
       "      <th>next_value</th>\n",
       "      <th>prev_value</th>\n",
       "      <th>avg_value</th>\n",
       "      <th>next_ID</th>\n",
       "      <th>prev_ID</th>\n",
       "      <th>next_ls</th>\n",
       "      <th>prev_ls</th>\n",
       "      <th>interpolation_ID</th>\n",
       "      <th>interpolation_ls</th>\n",
       "      <th>magic_feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>-19.14</td>\n",
       "      <td>-17.4</td>\n",
       "      <td>34</td>\n",
       "      <td>80.55</td>\n",
       "      <td>106.32</td>\n",
       "      <td>16.98</td>\n",
       "      <td>118.36</td>\n",
       "      <td>729</td>\n",
       "      <td>709</td>\n",
       "      <td>...</td>\n",
       "      <td>1.692575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.692575</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>-18.73</td>\n",
       "      <td>-17.3</td>\n",
       "      <td>30</td>\n",
       "      <td>99.90</td>\n",
       "      <td>139.00</td>\n",
       "      <td>21.20</td>\n",
       "      <td>139.51</td>\n",
       "      <td>728</td>\n",
       "      <td>717</td>\n",
       "      <td>...</td>\n",
       "      <td>1.975787</td>\n",
       "      <td>1.437752</td>\n",
       "      <td>1.706770</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>3.858913</td>\n",
       "      <td>1.184558</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>-17.54</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>41</td>\n",
       "      <td>82.48</td>\n",
       "      <td>114.86</td>\n",
       "      <td>14.91</td>\n",
       "      <td>117.66</td>\n",
       "      <td>731</td>\n",
       "      <td>722</td>\n",
       "      <td>...</td>\n",
       "      <td>2.370656</td>\n",
       "      <td>1.692575</td>\n",
       "      <td>2.031615</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>3.726817</td>\n",
       "      <td>1.997019</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>-15.43</td>\n",
       "      <td>-16.6</td>\n",
       "      <td>53</td>\n",
       "      <td>73.98</td>\n",
       "      <td>101.72</td>\n",
       "      <td>15.55</td>\n",
       "      <td>104.67</td>\n",
       "      <td>730</td>\n",
       "      <td>727</td>\n",
       "      <td>...</td>\n",
       "      <td>2.532091</td>\n",
       "      <td>1.975787</td>\n",
       "      <td>2.253939</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>41</td>\n",
       "      <td>3.830134</td>\n",
       "      <td>2.237578</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>-14.60</td>\n",
       "      <td>-16.3</td>\n",
       "      <td>65</td>\n",
       "      <td>64.62</td>\n",
       "      <td>86.86</td>\n",
       "      <td>13.09</td>\n",
       "      <td>93.92</td>\n",
       "      <td>727</td>\n",
       "      <td>729</td>\n",
       "      <td>...</td>\n",
       "      <td>2.779719</td>\n",
       "      <td>2.370656</td>\n",
       "      <td>2.575187</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>4.211441</td>\n",
       "      <td>2.571013</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>-14.10</td>\n",
       "      <td>-16.2</td>\n",
       "      <td>76</td>\n",
       "      <td>61.97</td>\n",
       "      <td>77.59</td>\n",
       "      <td>25.80</td>\n",
       "      <td>82.53</td>\n",
       "      <td>733</td>\n",
       "      <td>728</td>\n",
       "      <td>...</td>\n",
       "      <td>3.832378</td>\n",
       "      <td>2.532091</td>\n",
       "      <td>3.182235</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>5.457736</td>\n",
       "      <td>2.972188</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>-11.25</td>\n",
       "      <td>-15.9</td>\n",
       "      <td>96</td>\n",
       "      <td>71.51</td>\n",
       "      <td>70.09</td>\n",
       "      <td>70.09</td>\n",
       "      <td>74.35</td>\n",
       "      <td>726</td>\n",
       "      <td>726</td>\n",
       "      <td>...</td>\n",
       "      <td>3.956692</td>\n",
       "      <td>2.779719</td>\n",
       "      <td>3.368205</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>76</td>\n",
       "      <td>6.016394</td>\n",
       "      <td>3.702835</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>-10.77</td>\n",
       "      <td>-15.8</td>\n",
       "      <td>100</td>\n",
       "      <td>70.04</td>\n",
       "      <td>69.27</td>\n",
       "      <td>68.43</td>\n",
       "      <td>72.42</td>\n",
       "      <td>726</td>\n",
       "      <td>720</td>\n",
       "      <td>...</td>\n",
       "      <td>5.440741</td>\n",
       "      <td>3.832378</td>\n",
       "      <td>4.636559</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>96</td>\n",
       "      <td>8.657466</td>\n",
       "      <td>5.002096</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>-10.77</td>\n",
       "      <td>-15.8</td>\n",
       "      <td>100</td>\n",
       "      <td>5699.37</td>\n",
       "      <td>16924.86</td>\n",
       "      <td>162.65</td>\n",
       "      <td>10.59</td>\n",
       "      <td>65382</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4.501339</td>\n",
       "      <td>3.956692</td>\n",
       "      <td>4.229016</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>122</td>\n",
       "      <td>100</td>\n",
       "      <td>5.318310</td>\n",
       "      <td>3.956692</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>-8.33</td>\n",
       "      <td>-14.7</td>\n",
       "      <td>122</td>\n",
       "      <td>63.99</td>\n",
       "      <td>62.47</td>\n",
       "      <td>62.96</td>\n",
       "      <td>66.53</td>\n",
       "      <td>721</td>\n",
       "      <td>717</td>\n",
       "      <td>...</td>\n",
       "      <td>5.135805</td>\n",
       "      <td>5.440741</td>\n",
       "      <td>5.288273</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>142</td>\n",
       "      <td>100</td>\n",
       "      <td>4.830870</td>\n",
       "      <td>5.286520</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  board_t  env_t  light_strength  efficiency  efficiency_A  \\\n",
       "2   10   -19.14  -17.4              34       80.55        106.32   \n",
       "3   11   -18.73  -17.3              30       99.90        139.00   \n",
       "4   12   -17.54  -17.0              41       82.48        114.86   \n",
       "6   14   -15.43  -16.6              53       73.98        101.72   \n",
       "7   15   -14.60  -16.3              65       64.62         86.86   \n",
       "8   16   -14.10  -16.2              76       61.97         77.59   \n",
       "11  19   -11.25  -15.9              96       71.51         70.09   \n",
       "12  20   -10.77  -15.8             100       70.04         69.27   \n",
       "14  22   -10.77  -15.8             100     5699.37      16924.86   \n",
       "16  24    -8.33  -14.7             122       63.99         62.47   \n",
       "\n",
       "    efficiency_B  efficiency_C    V_A  V_B      ...        next_value  \\\n",
       "2          16.98        118.36    729  709      ...          1.692575   \n",
       "3          21.20        139.51    728  717      ...          1.975787   \n",
       "4          14.91        117.66    731  722      ...          2.370656   \n",
       "6          15.55        104.67    730  727      ...          2.532091   \n",
       "7          13.09         93.92    727  729      ...          2.779719   \n",
       "8          25.80         82.53    733  728      ...          3.832378   \n",
       "11         70.09         74.35    726  726      ...          3.956692   \n",
       "12         68.43         72.42    726  720      ...          5.440741   \n",
       "14        162.65         10.59  65382    7      ...          4.501339   \n",
       "16         62.96         66.53    721  717      ...          5.135805   \n",
       "\n",
       "    prev_value  avg_value  next_ID  prev_ID  next_ls  prev_ls  \\\n",
       "2          NaN   1.692575        3        0       30        0   \n",
       "3     1.437752   1.706770        4        2       41       34   \n",
       "4     1.692575   2.031615        6        3       53       30   \n",
       "6     1.975787   2.253939        7        4       65       41   \n",
       "7     2.370656   2.575187        8        6       76       53   \n",
       "8     2.532091   3.182235       11        7       96       65   \n",
       "11    2.779719   3.368205       12        8      100       76   \n",
       "12    3.832378   4.636559       14       11      100       96   \n",
       "14    3.956692   4.229016       16       12      122      100   \n",
       "16    5.440741   5.288273       19       14      142      100   \n",
       "\n",
       "    interpolation_ID  interpolation_ls  magic_feature  \n",
       "2                NaN               NaN             10  \n",
       "3           3.858913          1.184558             11  \n",
       "4           3.726817          1.997019             12  \n",
       "6           3.830134          2.237578             14  \n",
       "7           4.211441          2.571013             15  \n",
       "8           5.457736          2.972188             16  \n",
       "11          6.016394          3.702835             19  \n",
       "12          8.657466          5.002096             20  \n",
       "14          5.318310          3.956692             22  \n",
       "16          4.830870          5.286520             24  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_A                 213281.614781\n",
       "I_A                  78626.754818\n",
       "I_C                  55108.540367\n",
       "P_avg                42837.628159\n",
       "avg_value            19909.648506\n",
       "P_C                  17879.467202\n",
       "P_B                  11791.316512\n",
       "I_B                   7289.793923\n",
       "prev_value            1451.447198\n",
       "interpolation_ls       735.324104\n",
       "light_strength         246.287412\n",
       "next_value             160.978217\n",
       "efficiency_C           121.560562\n",
       "prev_ls                107.647241\n",
       "board_t                107.057531\n",
       "V_B                    106.715245\n",
       "efficiency              97.737557\n",
       "wind_direction          97.379456\n",
       "V_A                     85.196419\n",
       "wind_speed              59.659514\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.feature_importance(importance_type='gain'),\n",
    "          index=model.feature_name()).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8959.000000\n",
       "mean             NaN\n",
       "std              NaN\n",
       "min             -inf\n",
       "25%         2.416154\n",
       "50%         5.698367\n",
       "75%         8.928873\n",
       "max              inf\n",
       "Name: interpolation_ls, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.interpolation_ls.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_A               177424.003579\n",
       "log_P_A           123218.987586\n",
       "P_avg              38730.925607\n",
       "I_A                37315.842299\n",
       "predict_p_1        21958.906647\n",
       "P_C                21726.018202\n",
       "log_P_C             6591.719350\n",
       "prev_value          5255.104082\n",
       "I_C                 4302.151605\n",
       "log_I_A             3888.771484\n",
       "P_B                 2939.793071\n",
       "log_P_avg           2678.844737\n",
       "I_B                 1023.088723\n",
       "avg_value            885.473413\n",
       "log_I_C              449.592948\n",
       "light_strength       360.835061\n",
       "next_value           260.763310\n",
       "log_P_B              213.739565\n",
       "board_t              185.747500\n",
       "V_C                  143.911206\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.feature_importance(importance_type='gain'),\n",
    "          index=model.feature_name()).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_predicts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-5cb16a0752eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ans'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predicts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_predicts' is not defined"
     ]
    }
   ],
   "source": [
    "test['ans'] = np.mean(test_predicts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['ID','ans']].to_csv('../result/080103-magic.csv',header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1131ea080>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1131eaac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['ans'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8409.000000\n",
       "mean        5.696277\n",
       "std         3.457993\n",
       "min        -0.276554\n",
       "25%         2.523626\n",
       "50%         5.720650\n",
       "75%         8.889917\n",
       "max        12.215004\n",
       "Name: ans, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['ans'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x107abb908>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nApLUsP8PdtTXiw0lxJEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107e19470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['y'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9000.000000\n",
       "mean        5.695245\n",
       "std         3.463744\n",
       "min        -0.125144\n",
       "25%         2.512812\n",
       "50%         5.769032\n",
       "75%         8.896220\n",
       "max        12.288756\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
