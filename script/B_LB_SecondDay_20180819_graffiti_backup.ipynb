{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.问题分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.问题类别"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "一元回归问题.\n",
    "训练集样本9000条(包括82条重复样本)\n",
    "测试集样本8409条\n",
    "原始特征19个\n",
    "\n",
    "预测量为样本对应的发电量\n",
    "score = 1/(1+RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.特征分析 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "时间戳\n",
    "ID：当前记录条数； \n",
    "\n",
    "测量物理量(连续)\n",
    "板温：光伏电池板背测温度；\n",
    "现场温度：光伏电站现场温度；\n",
    "转换效率：为计算得到的平均转换效率；\n",
    "电压A：为数据采集点A处汇流箱电压值；\n",
    "电压B：为数据采集点B处汇流箱电压值；\n",
    "电压C：为数据采集点C处汇流箱电压值；\n",
    "电流A：为采集点A处汇流箱电流值；\n",
    "电流B：为采集点B处汇流箱电流值；\n",
    "电流C：为采集点C处汇流箱电流值；\n",
    "风速：为光伏电厂现场风速测量值；\n",
    "风向：为光伏电厂现场风的来向；\n",
    "\n",
    "计算物理量\n",
    "转换效率A：数据采集点A处的光伏板转换效率；\n",
    "转换效率B：数据采集点B处的光伏板转换效率；\n",
    "转换效率C：数据采集点C处的光伏板转换效率；\n",
    "功率A：为采集点A处的功率Pa，P=UI；\n",
    "功率B：为采集点B处的功率Pb，P=UI；\n",
    "功率C：为采集点C处的功率Pc，P=UI；\n",
    "平均功率：为A、B、C三点功率的平均值：(Pa+Pb+Pc)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.数据挖掘"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "详见 0803_数据挖掘.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.准备工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.准备工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import math\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.原始数据准备(不进行任何清洗)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('../data/public_raw.train.csv')\n",
    "test_raw = pd.read_csv('../data/public_raw.test.csv')\n",
    "\n",
    "train_raw['is_train']=1\n",
    "test_raw['is_train']=0\n",
    "\n",
    "df = pd.concat([train_raw, test_raw],sort=False)\n",
    "\n",
    "rep_cols = {'ID':'ID', \n",
    " '板温':'board_t', \n",
    " '现场温度':'env_t', \n",
    " '光照强度':'light_strength', \n",
    " '转换效率':'efficiency', \n",
    " '转换效率A':'efficiency_A', \n",
    " '转换效率B':'efficiency_B', \n",
    " '转换效率C':'efficiency_C', \n",
    " '电压A':'V_A',\n",
    " '电压B':'V_B', \n",
    " '电压C':'V_C', \n",
    " '电流A':'I_A', \n",
    " '电流B':'I_B', \n",
    " '电流C':'I_C', \n",
    " '功率A':'P_A', \n",
    " '功率B':'P_B', \n",
    " '功率C':'P_C', \n",
    " '平均功率':'P_avg', \n",
    " '风速':'wind_speed',\n",
    " '风向':'wind_direction', \n",
    " '发电量':'y'\n",
    "}\n",
    "\n",
    "df.rename(index=str, columns=rep_cols, inplace=True)\n",
    "\n",
    "df.sort_values(by=['ID'],ascending=True, inplace=True)\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #原始路线\n",
    "# all_data = df.copy()\n",
    "# bad_feature = ['env_t', 'V_A', 'V_B', 'V_C', 'I_B', 'I_C', 'efficiency', 'efficiency_A', 'efficiency_B', 'efficiency_C']\n",
    "# bad_index1 = all_data[bad_feature][\n",
    "#     (all_data[bad_feature] > all_data[bad_feature].mean() + 2 * all_data[bad_feature].std()) | \n",
    "#     (all_data[bad_feature] < all_data[bad_feature].mean() - 2 * all_data[bad_feature].std())\n",
    "# ].dropna(how='all').index\n",
    "# bad_index2 = all_data[\n",
    "#     ((all_data['V_A']<500)&(all_data['V_A']!=0))|\n",
    "#     ((all_data['V_B']<500)&(all_data['V_B']!=0))|\n",
    "#     ((all_data['V_C']<500)&(all_data['V_C']!=0))].index\n",
    "# bad_index = pd.Int64Index(list(bad_index1)+list(bad_index2))\n",
    "\n",
    "# # bad_index = all_data[bad_feature][\n",
    "# #     (all_data[bad_feature] > all_data[bad_feature].mean() + 2 * all_data[bad_feature].std()) | \n",
    "# #     (all_data[bad_feature] < all_data[bad_feature].mean() - 2 * all_data[bad_feature].std())\n",
    "# # ].dropna(how='all').index\n",
    "\n",
    "\n",
    "\n",
    "# bad_data = all_data.loc[bad_index].sort_values(by='ID', ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 上下记录均值替代异常值\n",
    "# for idx, line in bad_data.iterrows():\n",
    "#     ID = line['ID']\n",
    "#     col_index = line[bad_feature][ \n",
    "#         (line[bad_feature] > all_data[bad_feature].mean() + 3 * all_data[bad_feature].std())| \n",
    "#         (line[bad_feature] < all_data[bad_feature].mean() - 3 * all_data[bad_feature].std())\n",
    "#     ].index\n",
    "#     index = all_data[all_data['ID'] == ID].index\n",
    "    \n",
    "#     # idx - before_offset, CV  0.8684\n",
    "#     before_offset = 1\n",
    "#     while (idx + before_offset)in bad_index:\n",
    "#         before_offset += 1\n",
    "\n",
    "#     after_offset = 1\n",
    "#     while (idx + after_offset) in bad_index:\n",
    "#         after_offset += 1\n",
    "    \n",
    "#     replace_value = (all_data.loc[index - before_offset, col_index].values + all_data.loc[index + after_offset, col_index].values) / 2\n",
    "#     all_data.loc[index, col_index] = replace_value[0]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mask_two = [-i for i in range(1,2)]+[i for i in range(1,2)]\n",
    "rolling_mask_four = [-i for i in range(1,3)]+[i for i in range(1,3)]\n",
    "rolling_mask_six = [-i for i in range(1,4)]+[i for i in range(1,4)]\n",
    "rolling_mask_eight = [-i for i in range(1,5)]+[i for i in range(1,5)]\n",
    "rolling_mask_ten = [-i for i in range(1,6)]+[i for i in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "Int64Index([], dtype='int64')\n",
      "Empty DataFrame\n",
      "Columns: [ID, V_A, V_B, V_C, I_A, I_B, I_C, y]\n",
      "Index: []\n",
      "Int64Index([14, 859, 981, 1065, 1237, 1419, 3303, 3305, 3309, 3311, 3313], dtype='int64')\n",
      "Int64Index([3303, 1065, 3305, 1419, 3309, 14, 3311, 3313, 1237, 981, 859], dtype='int64')\n",
      "        ID    V_A  V_B  V_C   I_A     I_B   I_C         y\n",
      "14      22  65382    7  107  7.19  645.39  2.75  5.440741\n",
      "859    948  65394    4   14  6.87  638.94  2.37       NaN\n",
      "981   1070  65477   41  692  2.62  653.71  3.15       NaN\n",
      "1065  1173  65408   22  250  7.04  649.75  2.75  7.753474\n",
      "1237  1362  65386   23  244  7.00  652.02  2.79  7.806384\n",
      "1419  1565  65420    8  260  6.93  653.23  0.83       NaN\n",
      "3303  3597  65419   10   63  6.93  643.45  2.70       NaN\n",
      "3305  3599  65419    5   64  6.97  643.58  3.35  0.268685\n",
      "3309  3603  65420    3   67  7.01  643.75  3.16  0.286363\n",
      "3311  3605  65420   11   67  7.01  643.83  3.36  0.278587\n",
      "3313  3607  65420   15   68  7.09  643.94  0.03  0.286621\n",
      "ID :22.0\n",
      "645.39 is abnormal as value of  I_B\n",
      "Has been replaced by 2.84\n",
      "ID :948.0\n",
      "638.94 is abnormal as value of  I_B\n",
      "Has been replaced by 0.3\n",
      "ID :1070.0\n",
      "653.71 is abnormal as value of  I_B\n",
      "Has been replaced by 5.32\n",
      "ID :1173.0\n",
      "649.75 is abnormal as value of  I_B\n",
      "Has been replaced by 6.275\n",
      "ID :1362.0\n",
      "652.02 is abnormal as value of  I_B\n",
      "Has been replaced by 5.35\n",
      "ID :1565.0\n",
      "653.23 is abnormal as value of  I_B\n",
      "Has been replaced by 5.12\n",
      "ID :3597.0\n",
      "643.45 is abnormal as value of  I_B\n",
      "Has been replaced by 0.335\n",
      "ID :3599.0\n",
      "643.58 is abnormal as value of  I_B\n",
      "Has been replaced by 0.34\n",
      "ID :3603.0\n",
      "643.75 is abnormal as value of  I_B\n",
      "Has been replaced by 0.34\n",
      "ID :3605.0\n",
      "643.83 is abnormal as value of  I_B\n",
      "Has been replaced by 0.34\n",
      "ID :3607.0\n",
      "643.94 is abnormal as value of  I_B\n",
      "Has been replaced by 0.34\n",
      "Int64Index([  527,   528,   529,   530,  1067,  1373,  1722,  1950,  2036,\n",
      "             2071,  3255,  3316,  3317,  3318,  5083, 15971],\n",
      "           dtype='int64')\n",
      "Int64Index([15971,  1067,   527,   528,   529,   530,  2036,  3316,  3317,\n",
      "             2071,  3318,  3255,  1722,  5083,  1373,  1950],\n",
      "           dtype='int64')\n",
      "          ID  V_A    V_B  V_C   I_A   I_B     I_C         y\n",
      "527      591   36  65402    0  6.68  6.72  640.77       NaN\n",
      "528      592   36  65402    0  1.56  6.72  640.77  0.426489\n",
      "529      593   37  65403    3  6.68  6.72  640.85       NaN\n",
      "530      594   37  65403    3  1.56  6.72  640.85       NaN\n",
      "1067    1175  553  65406   27  7.07  7.07  649.96       NaN\n",
      "1373    1519   77  65387   14  7.04  7.10  639.04  0.839478\n",
      "1722    1894   74  65350   22  7.10  7.13  635.60  0.780917\n",
      "1950    2137  563  65428   30  6.95  6.97  652.04       NaN\n",
      "2036    2223  297  65446   18  7.06  7.06  649.69       NaN\n",
      "2071    2271  114  65353   14  7.22  7.28  639.06       NaN\n",
      "3255    3540   36  65463   18  6.50  6.56  647.62  0.209395\n",
      "3316    3610   36  65423    7  6.94  7.06  644.15       NaN\n",
      "3317    3611  710  65423    7  0.33  1.94  644.15       NaN\n",
      "3318    3612   37  65422    5  7.13  7.05  644.16  0.192079\n",
      "5083    5521   36  65410    0  1.66  6.72  641.85  0.426272\n",
      "15971  16437  599    146   26  7.96  8.47   32.91       NaN\n",
      "ID :591.0\n",
      "640.77 is abnormal as value of  I_C\n",
      "Has been replaced by 3.56\n",
      "ID :592.0\n",
      "640.77 is abnormal as value of  I_C\n",
      "Has been replaced by 3.56\n",
      "ID :593.0\n",
      "640.85 is abnormal as value of  I_C\n",
      "Has been replaced by 3.56\n",
      "ID :594.0\n",
      "640.85 is abnormal as value of  I_C\n",
      "Has been replaced by 3.56\n",
      "ID :1175.0\n",
      "649.96 is abnormal as value of  I_C\n",
      "Has been replaced by 4.21\n",
      "ID :1519.0\n",
      "639.04 is abnormal as value of  I_C\n",
      "Has been replaced by 0.745\n",
      "ID :1894.0\n",
      "635.6 is abnormal as value of  I_C\n",
      "Has been replaced by 0.7949999999999999\n",
      "ID :2137.0\n",
      "652.04 is abnormal as value of  I_C\n",
      "Has been replaced by 5.66\n",
      "ID :2223.0\n",
      "649.69 is abnormal as value of  I_C\n",
      "Has been replaced by 3.01\n",
      "ID :2271.0\n",
      "639.06 is abnormal as value of  I_C\n",
      "Has been replaced by 1.12\n",
      "ID :3540.0\n",
      "647.62 is abnormal as value of  I_C\n",
      "Has been replaced by 3.4699999999999998\n",
      "ID :3610.0\n",
      "644.15 is abnormal as value of  I_C\n",
      "Has been replaced by 0.37\n",
      "ID :3611.0\n",
      "644.15 is abnormal as value of  I_C\n",
      "Has been replaced by 0.37\n",
      "ID :3612.0\n",
      "644.16 is abnormal as value of  I_C\n",
      "Has been replaced by 0.37\n",
      "ID :5521.0\n",
      "641.85 is abnormal as value of  I_C\n",
      "Has been replaced by 0.36\n",
      "ID :16437.0\n",
      "32.91 is abnormal as value of  I_C\n",
      "Has been replaced by 7.82\n",
      "Int64Index([  14,  174,  175,  176,  498,  499,  527,  528,  529,  530,  531,\n",
      "             673,  859,  981, 1065, 1178, 1237, 1373, 1419, 1520, 1561, 1722,\n",
      "            2036, 2071, 2214, 2567, 2740, 2890, 3108, 3136, 3253, 3254, 3255,\n",
      "            3303, 3305, 3309, 3311, 3313, 3316, 3318, 3429, 5083, 6976],\n",
      "           dtype='int64')\n",
      "Int64Index([2567, 1419,   14,  527,  528,  529,  530,  531, 2071, 1561, 1178,\n",
      "             673, 3108, 2214, 1065,  174,  175,  176, 2740, 3253, 3254, 3255,\n",
      "            1722, 3136, 6976, 2890,  981, 1237,  859, 5083, 1373, 3429, 3303,\n",
      "            3305, 3309, 3311, 1520, 3313,  498,  499, 2036, 3316, 3318],\n",
      "           dtype='int64')\n",
      "        ID    V_A    V_B    V_C   I_A    I_B    I_C         y\n",
      "14      22  65382      7    107  7.19  2.840  2.750  5.440741\n",
      "174    198    493    664    669  0.42  0.250  0.340       NaN\n",
      "175    199    486    673    681  0.75  0.260  1.130  0.564661\n",
      "176    200    480    678    703  1.15  0.280  1.640       NaN\n",
      "498    542    264    681    679  2.62  0.490  3.090  1.777304\n",
      "499    543    290    293     15  6.81  6.780  6.800       NaN\n",
      "527    591     36  65402      0  6.68  6.720  3.560       NaN\n",
      "528    592     36  65402      0  1.56  6.720  3.560  0.426489\n",
      "529    593     37  65403      3  6.68  6.720  3.560       NaN\n",
      "530    594     37  65403      3  1.56  6.720  3.560       NaN\n",
      "531    595     37     39  65406  6.77  6.780  6.780       NaN\n",
      "673    737     37     37  65514  6.53  6.450  6.520       NaN\n",
      "859    948  65394      4     14  6.87  0.300  2.370       NaN\n",
      "981   1070  65477     41    692  2.62  5.320  3.150       NaN\n",
      "1065  1173  65408     22    250  7.04  6.275  2.750  7.753474\n",
      "1178  1286    310    307  65438  7.18  7.160  7.180  4.694385\n",
      "1237  1362  65386     23    244  7.00  5.350  2.790  7.806384\n",
      "1373  1519     77  65387     14  7.04  7.100  0.745  0.839478\n",
      "1419  1565  65420      8    260  6.93  5.120  0.830       NaN\n",
      "1520  1666    293    255  65460  6.87  6.800  6.810  4.521973\n",
      "1561  1717     36     40  65396  6.81  6.830  6.820       NaN\n",
      "1722  1894     74  65350     22  7.10  7.130  0.795  0.780917\n",
      "2036  2223    297  65446     18  7.06  7.060  3.010       NaN\n",
      "2071  2271    114  65353     14  7.22  7.280  1.120       NaN\n",
      "2214  2414    292    296  65470  7.02  7.000  6.990  4.299538\n",
      "2567  2797    305  65512     17  6.86  6.860  3.600  4.221675\n",
      "2740  2986  65515      0     89  6.89  1.660  0.210  4.196051\n",
      "2890  3152      3     33    260  6.67  7.580  2.780  7.650842\n",
      "3108  3393     34     38  65470  6.64  6.650  6.520       NaN\n",
      "3136  3421    290    300  65475  6.98  6.990  7.000       NaN\n",
      "3253  3538     36     37  65463  6.56  6.620  6.600  0.344703\n",
      "3254  3539     36     37  65463  1.44  6.620  6.600  0.209395\n",
      "3255  3540     36  65463     18  6.50  6.560  3.470  0.209395\n",
      "3303  3597  65419     10     63  6.93  0.335  2.700       NaN\n",
      "3305  3599  65419      5     64  6.97  0.340  3.350  0.268685\n",
      "3309  3603  65420      3     67  7.01  0.340  3.160  0.286363\n",
      "3311  3605  65420     11     67  7.01  0.340  3.360  0.278587\n",
      "3313  3607  65420     15     68  7.09  0.340  0.030  0.286621\n",
      "3316  3610     36  65423      7  6.94  7.060  0.370       NaN\n",
      "3318  3612     37  65422      5  7.13  7.050  0.370  0.192079\n",
      "3429  3723     39     42  65440  7.21  7.060  7.080  0.460215\n",
      "5083  5521     36  65410      0  1.66  6.720  0.360  0.426272\n",
      "6976  7437    807    831  65491  9.00  6.400  6.370       NaN\n",
      "ID :22.0\n",
      "65382.0 is abnormal as value of  V_A\n",
      "Has been replaced by 725.0\n",
      "ID :198.0\n",
      "493.0 is abnormal as value of  V_A\n",
      "Has been replaced by 512.0\n",
      "ID :199.0\n",
      "486.0 is abnormal as value of  V_A\n",
      "Has been replaced by 512.0\n",
      "ID :200.0\n",
      "480.0 is abnormal as value of  V_A\n",
      "Has been replaced by 512.0\n",
      "ID :542.0\n",
      "264.0 is abnormal as value of  V_A\n",
      "Has been replaced by 678.5\n",
      "ID :543.0\n",
      "290.0 is abnormal as value of  V_A\n",
      "Has been replaced by 678.5\n",
      "ID :591.0\n",
      "36.0 is abnormal as value of  V_A\n",
      "Has been replaced by 687.0\n",
      "ID :592.0\n",
      "36.0 is abnormal as value of  V_A\n",
      "Has been replaced by 687.0\n",
      "ID :593.0\n",
      "37.0 is abnormal as value of  V_A\n",
      "Has been replaced by 687.0\n",
      "ID :594.0\n",
      "37.0 is abnormal as value of  V_A\n",
      "Has been replaced by 687.0\n",
      "ID :595.0\n",
      "37.0 is abnormal as value of  V_A\n",
      "Has been replaced by 687.0\n",
      "ID :737.0\n",
      "37.0 is abnormal as value of  V_A\n",
      "Has been replaced by 650.0\n",
      "ID :948.0\n",
      "65394.0 is abnormal as value of  V_A\n",
      "Has been replaced by 687.5\n",
      "ID :1070.0\n",
      "65477.0 is abnormal as value of  V_A\n",
      "Has been replaced by 697.5\n",
      "ID :1173.0\n",
      "65408.0 is abnormal as value of  V_A\n",
      "Has been replaced by 707.0\n",
      "ID :1286.0\n",
      "310.0 is abnormal as value of  V_A\n",
      "Has been replaced by 715.5\n",
      "ID :1362.0\n",
      "65386.0 is abnormal as value of  V_A\n",
      "Has been replaced by 702.0\n",
      "ID :1519.0\n",
      "77.0 is abnormal as value of  V_A\n",
      "Has been replaced by 711.0\n",
      "ID :1565.0\n",
      "65420.0 is abnormal as value of  V_A\n",
      "Has been replaced by 697.5\n",
      "ID :1666.0\n",
      "293.0 is abnormal as value of  V_A\n",
      "Has been replaced by 681.5\n",
      "ID :1717.0\n",
      "36.0 is abnormal as value of  V_A\n",
      "Has been replaced by 687.5\n",
      "ID :1894.0\n",
      "74.0 is abnormal as value of  V_A\n",
      "Has been replaced by 729.5\n",
      "ID :2223.0\n",
      "297.0 is abnormal as value of  V_A\n",
      "Has been replaced by 709.0\n",
      "ID :2271.0\n",
      "114.0 is abnormal as value of  V_A\n",
      "Has been replaced by 729.0\n",
      "ID :2414.0\n",
      "292.0 is abnormal as value of  V_A\n",
      "Has been replaced by 703.5\n",
      "ID :2797.0\n",
      "305.0 is abnormal as value of  V_A\n",
      "Has been replaced by 688.5\n",
      "ID :2986.0\n",
      "65515.0 is abnormal as value of  V_A\n",
      "Has been replaced by 691.5\n",
      "ID :3152.0\n",
      "3.0 is abnormal as value of  V_A\n",
      "Has been replaced by 673.0\n",
      "ID :3393.0\n",
      "34.0 is abnormal as value of  V_A\n",
      "Has been replaced by 659.0\n",
      "ID :3421.0\n",
      "290.0 is abnormal as value of  V_A\n",
      "Has been replaced by 700.5\n",
      "ID :3538.0\n",
      "36.0 is abnormal as value of  V_A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has been replaced by 658.0\n",
      "ID :3539.0\n",
      "36.0 is abnormal as value of  V_A\n",
      "Has been replaced by 658.0\n",
      "ID :3540.0\n",
      "36.0 is abnormal as value of  V_A\n",
      "Has been replaced by 658.0\n",
      "ID :3597.0\n",
      "65419.0 is abnormal as value of  V_A\n",
      "Has been replaced by 700.0\n",
      "ID :3599.0\n",
      "65419.0 is abnormal as value of  V_A\n",
      "Has been replaced by 698.5\n",
      "ID :3603.0\n",
      "65420.0 is abnormal as value of  V_A\n",
      "Has been replaced by 696.0\n",
      "ID :3605.0\n",
      "65420.0 is abnormal as value of  V_A\n",
      "Has been replaced by 694.0\n",
      "ID :3607.0\n",
      "65420.0 is abnormal as value of  V_A\n",
      "Has been replaced by 695.0\n",
      "ID :3610.0\n",
      "36.0 is abnormal as value of  V_A\n",
      "Has been replaced by 708.5\n",
      "ID :3612.0\n",
      "37.0 is abnormal as value of  V_A\n",
      "Has been replaced by 704.0\n",
      "ID :3723.0\n",
      "39.0 is abnormal as value of  V_A\n",
      "Has been replaced by 718.5\n",
      "ID :5521.0\n",
      "36.0 is abnormal as value of  V_A\n",
      "Has been replaced by 689.5\n",
      "ID :7437.0\n",
      "807.0 is abnormal as value of  V_A\n",
      "Has been replaced by 646.5\n",
      "Int64Index([   14,   499,   527,   528,   529,   530,   531,   673,   859,\n",
      "              981,  1065,  1066,  1067,  1178,  1237,  1326,  1373,  1419,\n",
      "             1520,  1561,  1722,  1950,  2036,  2071,  2214,  2364,  2454,\n",
      "             2567,  2629,  2670,  2890,  3108,  3136,  3253,  3254,  3255,\n",
      "             3303,  3305,  3309,  3311,  3313,  3316,  3317,  3318,  3429,\n",
      "             4068,  5083,  5488,  5565,  6976,  7281, 14216, 15833, 15971],\n",
      "           dtype='int64')\n",
      "Int64Index([ 2567, 14216,  1419,    14,   527,   528,   529,   530,   531,\n",
      "             2454,  2071,  1561,  1178,  1950,   673,  3108,  2214,  1065,\n",
      "             1066,  1067,  1326,  3253,  3254,  3255,  1722,  2364,  5565,\n",
      "             3136,  6976,  2629,  2890,   981,  1237, 15833,   859,  5083,\n",
      "             1373, 15971,  4068,  3429,  3303,  3305,  3309,  2670,  3311,\n",
      "             1520,  3313,  5488,   499,  2036,  3316,  3317,  3318,  7281],\n",
      "           dtype='int64')\n",
      "          ID    V_A    V_B    V_C   I_A    I_B    I_C         y\n",
      "14        22  725.0      7    107  7.19  2.840  2.750  5.440741\n",
      "499      543  678.5    293     15  6.81  6.780  6.800       NaN\n",
      "527      591  687.0  65402      0  6.68  6.720  3.560       NaN\n",
      "528      592  687.0  65402      0  1.56  6.720  3.560  0.426489\n",
      "529      593  687.0  65403      3  6.68  6.720  3.560       NaN\n",
      "530      594  687.0  65403      3  1.56  6.720  3.560       NaN\n",
      "531      595  687.0     39  65406  6.77  6.780  6.780       NaN\n",
      "673      737  650.0     37  65514  6.53  6.450  6.520       NaN\n",
      "859      948  687.5      4     14  6.87  0.300  2.370       NaN\n",
      "981     1070  697.5     41    692  2.62  5.320  3.150       NaN\n",
      "1065    1173  707.0     22    250  7.04  6.275  2.750  7.753474\n",
      "1066    1174  708.0     22    250  5.42  7.190  2.750       NaN\n",
      "1067    1175  553.0  65406     27  7.07  7.070  4.210       NaN\n",
      "1178    1286  715.5    307  65438  7.18  7.160  7.180  4.694385\n",
      "1237    1362  702.0     23    244  7.00  5.350  2.790  7.806384\n",
      "1326    1451  560.0  65454     27  6.84  6.820  3.120  7.996870\n",
      "1373    1519  711.0  65387     14  7.04  7.100  0.745  0.839478\n",
      "1419    1565  697.5      8    260  6.93  5.120  0.830       NaN\n",
      "1520    1666  681.5    255  65460  6.87  6.800  6.810  4.521973\n",
      "1561    1717  687.5     40  65396  6.81  6.830  6.820       NaN\n",
      "1722    1894  729.5  65350     22  7.10  7.130  0.795  0.780917\n",
      "1950    2137  563.0  65428     30  6.95  6.970  5.660       NaN\n",
      "2036    2223  709.0  65446     18  7.06  7.060  3.010       NaN\n",
      "2071    2271  729.0  65353     14  7.22  7.280  1.120       NaN\n",
      "2214    2414  703.5    296  65470  7.02  7.000  6.990  4.299538\n",
      "2364    2579  560.0  65481     39  6.82  6.800  1.850       NaN\n",
      "2454    2684  564.0  65438     26  6.86  6.860  0.700       NaN\n",
      "2567    2797  688.5  65512     17  6.86  6.860  3.600  4.221675\n",
      "2629    2875  555.0  65455     23  6.83  6.820  1.990  7.794517\n",
      "2670    2916  604.0  65508     30  6.73  6.720  4.970       NaN\n",
      "2890    3152  673.0     33    260  6.67  7.580  2.780  7.650842\n",
      "3108    3393  659.0     38  65470  6.64  6.650  6.520       NaN\n",
      "3136    3421  700.5    300  65475  6.98  6.990  7.000       NaN\n",
      "3253    3538  658.0     37  65463  6.56  6.620  6.600  0.344703\n",
      "3254    3539  658.0     37  65463  1.44  6.620  6.600  0.209395\n",
      "3255    3540  658.0  65463     18  6.50  6.560  3.470  0.209395\n",
      "3303    3597  700.0     10     63  6.93  0.335  2.700       NaN\n",
      "3305    3599  698.5      5     64  6.97  0.340  3.350  0.268685\n",
      "3309    3603  696.0      3     67  7.01  0.340  3.160  0.286363\n",
      "3311    3605  694.0     11     67  7.01  0.340  3.360  0.278587\n",
      "3313    3607  695.0     15     68  7.09  0.340  0.030  0.286621\n",
      "3316    3610  708.5  65423      7  6.94  7.060  0.370       NaN\n",
      "3317    3611  710.0  65423      7  0.33  1.940  0.370       NaN\n",
      "3318    3612  704.0  65422      5  7.13  7.050  0.370  0.192079\n",
      "3429    3723  718.5     42  65440  7.21  7.060  7.080  0.460215\n",
      "4068    4401  667.0      9     99  0.37  1.770  3.310  0.323052\n",
      "5083    5521  689.5  65410      0  1.66  6.720  0.360  0.426272\n",
      "5488    5939  715.0     15    137  2.89  3.540  2.690  2.858739\n",
      "5565    6016  667.0  65505     23  7.96  9.210  4.750       NaN\n",
      "6976    7437  646.5    831  65491  9.00  6.400  6.370       NaN\n",
      "7281    7742  689.0     32     30  0.34  1.380  0.490       NaN\n",
      "14216  14682  661.0     36    316  2.85  4.650  2.020       NaN\n",
      "15833  16299  638.0     18    589  5.49  6.610  3.190       NaN\n",
      "15971  16437  599.0    146     26  7.96  8.470  7.820       NaN\n",
      "ID :22.0\n",
      "7.0 is abnormal as value of  V_B\n",
      "Has been replaced by 724.5\n",
      "ID :543.0\n",
      "293.0 is abnormal as value of  V_B\n",
      "Has been replaced by 681.0\n",
      "ID :591.0\n",
      "65402.0 is abnormal as value of  V_B\n",
      "Has been replaced by 682.0\n",
      "ID :592.0\n",
      "65402.0 is abnormal as value of  V_B\n",
      "Has been replaced by 682.0\n",
      "ID :593.0\n",
      "65403.0 is abnormal as value of  V_B\n",
      "Has been replaced by 682.0\n",
      "ID :594.0\n",
      "65403.0 is abnormal as value of  V_B\n",
      "Has been replaced by 682.0\n",
      "ID :595.0\n",
      "39.0 is abnormal as value of  V_B\n",
      "Has been replaced by 682.0\n",
      "ID :737.0\n",
      "37.0 is abnormal as value of  V_B\n",
      "Has been replaced by 649.0\n",
      "ID :948.0\n",
      "4.0 is abnormal as value of  V_B\n",
      "Has been replaced by 687.0\n",
      "ID :1070.0\n",
      "41.0 is abnormal as value of  V_B\n",
      "Has been replaced by 694.0\n",
      "ID :1173.0\n",
      "22.0 is abnormal as value of  V_B\n",
      "Has been replaced by 703.5\n",
      "ID :1174.0\n",
      "22.0 is abnormal as value of  V_B\n",
      "Has been replaced by 703.5\n",
      "ID :1175.0\n",
      "65406.0 is abnormal as value of  V_B\n",
      "Has been replaced by 703.5\n",
      "ID :1286.0\n",
      "307.0 is abnormal as value of  V_B\n",
      "Has been replaced by 716.5\n",
      "ID :1362.0\n",
      "23.0 is abnormal as value of  V_B\n",
      "Has been replaced by 698.5\n",
      "ID :1451.0\n",
      "65454.0 is abnormal as value of  V_B\n",
      "Has been replaced by 682.5\n",
      "ID :1519.0\n",
      "65387.0 is abnormal as value of  V_B\n",
      "Has been replaced by 712.5\n",
      "ID :1565.0\n",
      "8.0 is abnormal as value of  V_B\n",
      "Has been replaced by 692.5\n",
      "ID :1666.0\n",
      "255.0 is abnormal as value of  V_B\n",
      "Has been replaced by 684.5\n",
      "ID :1717.0\n",
      "40.0 is abnormal as value of  V_B\n",
      "Has been replaced by 683.0\n",
      "ID :1894.0\n",
      "65350.0 is abnormal as value of  V_B\n",
      "Has been replaced by 713.5\n",
      "ID :2137.0\n",
      "65428.0 is abnormal as value of  V_B\n",
      "Has been replaced by 694.5\n",
      "ID :2223.0\n",
      "65446.0 is abnormal as value of  V_B\n",
      "Has been replaced by 707.0\n",
      "ID :2271.0\n",
      "65353.0 is abnormal as value of  V_B\n",
      "Has been replaced by 719.0\n",
      "ID :2414.0\n",
      "296.0 is abnormal as value of  V_B\n",
      "Has been replaced by 701.5\n",
      "ID :2579.0\n",
      "65481.0 is abnormal as value of  V_B\n",
      "Has been replaced by 682.0\n",
      "ID :2684.0\n",
      "65438.0 is abnormal as value of  V_B\n",
      "Has been replaced by 687.0\n",
      "ID :2797.0\n",
      "65512.0 is abnormal as value of  V_B\n",
      "Has been replaced by 687.0\n",
      "ID :2875.0\n",
      "65455.0 is abnormal as value of  V_B\n",
      "Has been replaced by 684.5\n",
      "ID :2916.0\n",
      "65508.0 is abnormal as value of  V_B\n",
      "Has been replaced by 675.0\n",
      "ID :3152.0\n",
      "33.0 is abnormal as value of  V_B\n",
      "Has been replaced by 668.5\n",
      "ID :3393.0\n",
      "38.0 is abnormal as value of  V_B\n",
      "Has been replaced by 664.5\n",
      "ID :3421.0\n",
      "300.0 is abnormal as value of  V_B\n",
      "Has been replaced by 699.0\n",
      "ID :3538.0\n",
      "37.0 is abnormal as value of  V_B\n",
      "Has been replaced by 661.5\n",
      "ID :3539.0\n",
      "37.0 is abnormal as value of  V_B\n",
      "Has been replaced by 661.5\n",
      "ID :3540.0\n",
      "65463.0 is abnormal as value of  V_B\n",
      "Has been replaced by 661.5\n",
      "ID :3597.0\n",
      "10.0 is abnormal as value of  V_B\n",
      "Has been replaced by 704.0\n",
      "ID :3599.0\n",
      "5.0 is abnormal as value of  V_B\n",
      "Has been replaced by 699.0\n",
      "ID :3603.0\n",
      "3.0 is abnormal as value of  V_B\n",
      "Has been replaced by 701.0\n",
      "ID :3605.0\n",
      "11.0 is abnormal as value of  V_B\n",
      "Has been replaced by 698.0\n",
      "ID :3607.0\n",
      "15.0 is abnormal as value of  V_B\n",
      "Has been replaced by 705.0\n",
      "ID :3610.0\n",
      "65423.0 is abnormal as value of  V_B\n",
      "Has been replaced by 703.0\n",
      "ID :3611.0\n",
      "65423.0 is abnormal as value of  V_B\n",
      "Has been replaced by 703.0\n",
      "ID :3612.0\n",
      "65422.0 is abnormal as value of  V_B\n",
      "Has been replaced by 703.0\n",
      "ID :3723.0\n",
      "42.0 is abnormal as value of  V_B\n",
      "Has been replaced by 698.0\n",
      "ID :4401.0\n",
      "9.0 is abnormal as value of  V_B\n",
      "Has been replaced by 668.0\n",
      "ID :5521.0\n",
      "65410.0 is abnormal as value of  V_B\n",
      "Has been replaced by 682.5\n",
      "ID :5939.0\n",
      "15.0 is abnormal as value of  V_B\n",
      "Has been replaced by 715.5\n",
      "ID :6016.0\n",
      "65505.0 is abnormal as value of  V_B\n",
      "Has been replaced by 666.0\n",
      "ID :7437.0\n",
      "831.0 is abnormal as value of  V_B\n",
      "Has been replaced by 645.5\n",
      "ID :7742.0\n",
      "32.0 is abnormal as value of  V_B\n",
      "Has been replaced by 681.0\n",
      "ID :14682.0\n",
      "36.0 is abnormal as value of  V_B\n",
      "Has been replaced by 657.0\n",
      "ID :16299.0\n",
      "18.0 is abnormal as value of  V_B\n",
      "Has been replaced by 633.5\n",
      "ID :16437.0\n",
      "146.0 is abnormal as value of  V_B\n",
      "Has been replaced by 597.5\n",
      "Int64Index([   14,   127,   468,   499,   529,   530,   531,   673,   859,\n",
      "             1065,  1066,  1067,  1178,  1237,  1326,  1373,  1419,  1520,\n",
      "             1561,  1722,  1950,  2036,  2071,  2214,  2364,  2454,  2567,\n",
      "             2629,  2670,  2740,  2887,  2890,  3108,  3136,  3253,  3254,\n",
      "             3255,  3303,  3304,  3305,  3309,  3310,  3311,  3312,  3313,\n",
      "             3316,  3317,  3318,  3429,  3967,  4068,  4301,  4857,  5488,\n",
      "             5565,  6976,  7281, 10456, 10457, 11366, 12348, 12723, 14216,\n",
      "            15971],\n",
      "           dtype='int64')\n",
      "Int64Index([ 2567, 14216,  1419,    14,   529,   530,   531,  2454,  2071,\n",
      "             1561,  1178,  1950,   673,  3108,  2214,  1065,  1066,  1067,\n",
      "             1326, 12723,  2740,  3253,  3254,  3255,  1722,  2364,  5565,\n",
      "            12348,  3136,  6976,  2629,  2887,  2890,  4301,   468,  1237,\n",
      "             3967, 10456, 10457,   859,  5488,  1373, 15971,  4068,  3429,\n",
      "            11366,  3303,  3304,  3305,  3309,  2670,  3310,  1520,  3311,\n",
      "             3312,   499,  2036,  3313,  3316,  3317,  3318,  4857,  7281,\n",
      "              127],\n",
      "           dtype='int64')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID    V_A    V_B    V_C   I_A    I_B    I_C          y\n",
      "14        22  725.0  724.5    107  7.19  2.840  2.750   5.440741\n",
      "127      135  555.0  559.0  65498  6.85  6.770  6.790        NaN\n",
      "468      512  554.0  563.0     23  6.70  6.640  6.670   7.807098\n",
      "499      543  678.5  681.0     15  6.81  6.780  6.800        NaN\n",
      "529      593  687.0  682.0      3  6.68  6.720  3.560        NaN\n",
      "530      594  687.0  682.0      3  1.56  6.720  3.560        NaN\n",
      "531      595  687.0  682.0  65406  6.77  6.780  6.780        NaN\n",
      "673      737  650.0  649.0  65514  6.53  6.450  6.520        NaN\n",
      "859      948  687.5  687.0     14  6.87  0.300  2.370        NaN\n",
      "1065    1173  707.0  703.5    250  7.04  6.275  2.750   7.753474\n",
      "1066    1174  708.0  703.5    250  5.42  7.190  2.750        NaN\n",
      "1067    1175  553.0  703.5     27  7.07  7.070  4.210        NaN\n",
      "1178    1286  715.5  716.5  65438  7.18  7.160  7.180   4.694385\n",
      "1237    1362  702.0  698.5    244  7.00  5.350  2.790   7.806384\n",
      "1326    1451  560.0  682.5     27  6.84  6.820  3.120   7.996870\n",
      "1373    1519  711.0  712.5     14  7.04  7.100  0.745   0.839478\n",
      "1419    1565  697.5  692.5    260  6.93  5.120  0.830        NaN\n",
      "1520    1666  681.5  684.5  65460  6.87  6.800  6.810   4.521973\n",
      "1561    1717  687.5  683.0  65396  6.81  6.830  6.820        NaN\n",
      "1722    1894  729.5  713.5     22  7.10  7.130  0.795   0.780917\n",
      "1950    2137  563.0  694.5     30  6.95  6.970  5.660        NaN\n",
      "2036    2223  709.0  707.0     18  7.06  7.060  3.010        NaN\n",
      "2071    2271  729.0  719.0     14  7.22  7.280  1.120        NaN\n",
      "2214    2414  703.5  701.5  65470  7.02  7.000  6.990   4.299538\n",
      "2364    2579  560.0  682.0     39  6.82  6.800  1.850        NaN\n",
      "2454    2684  564.0  687.0     26  6.86  6.860  0.700        NaN\n",
      "2567    2797  688.5  687.0     17  6.86  6.860  3.600   4.221675\n",
      "2629    2875  555.0  684.5     23  6.83  6.820  1.990   7.794517\n",
      "2670    2916  604.0  675.0     30  6.73  6.720  4.970        NaN\n",
      "2740    2986  691.5    0.0     89  6.89  1.660  0.210   4.196051\n",
      "...      ...    ...    ...    ...   ...    ...    ...        ...\n",
      "3253    3538  658.0  661.5  65463  6.56  6.620  6.600   0.344703\n",
      "3254    3539  658.0  661.5  65463  1.44  6.620  6.600   0.209395\n",
      "3255    3540  658.0  661.5     18  6.50  6.560  3.470   0.209395\n",
      "3303    3597  700.0  704.0     63  6.93  0.335  2.700        NaN\n",
      "3304    3598  690.0  697.0     63  0.32  0.340  0.140        NaN\n",
      "3305    3599  698.5  699.0     64  6.97  0.340  3.350   0.268685\n",
      "3309    3603  696.0  701.0     67  7.01  0.340  3.160   0.286363\n",
      "3310    3604  697.0  693.0     67  0.32  0.340  0.600        NaN\n",
      "3311    3605  694.0  698.0     67  7.01  0.340  3.360   0.278587\n",
      "3312    3606  691.0  703.0     67  0.33  0.340  0.800   0.286621\n",
      "3313    3607  695.0  705.0     68  7.09  0.340  0.030   0.286621\n",
      "3316    3610  708.5  703.0      7  6.94  7.060  0.370        NaN\n",
      "3317    3611  710.0  703.0      7  0.33  1.940  0.370        NaN\n",
      "3318    3612  704.0  703.0      5  7.13  7.050  0.370   0.192079\n",
      "3429    3723  718.5  698.0  65440  7.21  7.060  7.080   0.460215\n",
      "3967    4300  665.0  668.0     31  0.33  0.320  0.700   0.325498\n",
      "4068    4401  667.0  668.0     99  0.37  1.770  3.310   0.323052\n",
      "4301    4651  543.0  612.0    479  0.05  0.060  0.050   0.032366\n",
      "4857    5264  679.0  678.0     10  0.31  0.330  0.020   0.203511\n",
      "5488    5939  715.0  715.5    137  2.89  3.540  2.690   2.858739\n",
      "5565    6016  667.0  666.0     23  7.96  9.210  4.750        NaN\n",
      "6976    7437  646.5  645.5  65491  9.00  6.400  6.370        NaN\n",
      "7281    7742  689.0  681.0     30  0.34  1.380  0.490        NaN\n",
      "10456  10920  643.0  653.0     27  0.33  0.330  0.740        NaN\n",
      "10457  10921  646.0  638.0     27  0.34  0.340  0.590   0.590406\n",
      "11366  11832  622.0  618.0    146  7.90  7.880  8.760  10.814965\n",
      "12348  12814  671.0  675.0     14  2.88  3.110  3.930   3.439684\n",
      "12723  13189  622.0  618.0     10  2.92  2.880  3.450        NaN\n",
      "14216  14682  661.0  657.0    316  2.85  4.650  2.020        NaN\n",
      "15971  16437  599.0  597.5     26  7.96  8.470  7.820        NaN\n",
      "\n",
      "[64 rows x 8 columns]\n",
      "ID :22.0\n",
      "107.0 is abnormal as value of  V_C\n",
      "Has been replaced by 722.5\n",
      "ID :135.0\n",
      "65498.0 is abnormal as value of  V_C\n",
      "Has been replaced by 677.0\n",
      "ID :512.0\n",
      "23.0 is abnormal as value of  V_C\n",
      "Has been replaced by 665.0\n",
      "ID :543.0\n",
      "15.0 is abnormal as value of  V_C\n",
      "Has been replaced by 679.5\n",
      "ID :593.0\n",
      "3.0 is abnormal as value of  V_C\n",
      "Has been replaced by 338.5\n",
      "ID :594.0\n",
      "3.0 is abnormal as value of  V_C\n",
      "Has been replaced by 338.5\n",
      "ID :595.0\n",
      "65406.0 is abnormal as value of  V_C\n",
      "Has been replaced by 338.5\n",
      "ID :737.0\n",
      "65514.0 is abnormal as value of  V_C\n",
      "Has been replaced by 645.0\n",
      "ID :948.0\n",
      "14.0 is abnormal as value of  V_C\n",
      "Has been replaced by 697.0\n",
      "ID :1173.0\n",
      "250.0 is abnormal as value of  V_C\n",
      "Has been replaced by 706.5\n",
      "ID :1174.0\n",
      "250.0 is abnormal as value of  V_C\n",
      "Has been replaced by 706.5\n",
      "ID :1175.0\n",
      "27.0 is abnormal as value of  V_C\n",
      "Has been replaced by 706.5\n",
      "ID :1286.0\n",
      "65438.0 is abnormal as value of  V_C\n",
      "Has been replaced by 716.5\n",
      "ID :1362.0\n",
      "244.0 is abnormal as value of  V_C\n",
      "Has been replaced by 700.5\n",
      "ID :1451.0\n",
      "27.0 is abnormal as value of  V_C\n",
      "Has been replaced by 682.0\n",
      "ID :1519.0\n",
      "14.0 is abnormal as value of  V_C\n",
      "Has been replaced by 703.5\n",
      "ID :1565.0\n",
      "260.0 is abnormal as value of  V_C\n",
      "Has been replaced by 695.5\n",
      "ID :1666.0\n",
      "65460.0 is abnormal as value of  V_C\n",
      "Has been replaced by 684.0\n",
      "ID :1717.0\n",
      "65396.0 is abnormal as value of  V_C\n",
      "Has been replaced by 680.5\n",
      "ID :1894.0\n",
      "22.0 is abnormal as value of  V_C\n",
      "Has been replaced by 717.5\n",
      "ID :2137.0\n",
      "30.0 is abnormal as value of  V_C\n",
      "Has been replaced by 695.5\n",
      "ID :2223.0\n",
      "18.0 is abnormal as value of  V_C\n",
      "Has been replaced by 705.5\n",
      "ID :2271.0\n",
      "14.0 is abnormal as value of  V_C\n",
      "Has been replaced by 726.0\n",
      "ID :2414.0\n",
      "65470.0 is abnormal as value of  V_C\n",
      "Has been replaced by 698.5\n",
      "ID :2579.0\n",
      "39.0 is abnormal as value of  V_C\n",
      "Has been replaced by 683.0\n",
      "ID :2684.0\n",
      "26.0 is abnormal as value of  V_C\n",
      "Has been replaced by 685.5\n",
      "ID :2797.0\n",
      "17.0 is abnormal as value of  V_C\n",
      "Has been replaced by 686.5\n",
      "ID :2875.0\n",
      "23.0 is abnormal as value of  V_C\n",
      "Has been replaced by 683.0\n",
      "ID :2916.0\n",
      "30.0 is abnormal as value of  V_C\n",
      "Has been replaced by 676.0\n",
      "ID :2986.0\n",
      "89.0 is abnormal as value of  V_C\n",
      "Has been replaced by 686.5\n",
      "ID :3149.0\n",
      "5.0 is abnormal as value of  V_C\n",
      "Has been replaced by 668.5\n",
      "ID :3152.0\n",
      "260.0 is abnormal as value of  V_C\n",
      "Has been replaced by 669.5\n",
      "ID :3393.0\n",
      "65470.0 is abnormal as value of  V_C\n",
      "Has been replaced by 655.0\n",
      "ID :3421.0\n",
      "65475.0 is abnormal as value of  V_C\n",
      "Has been replaced by 701.5\n",
      "ID :3538.0\n",
      "65463.0 is abnormal as value of  V_C\n",
      "Has been replaced by 658.0\n",
      "ID :3539.0\n",
      "65463.0 is abnormal as value of  V_C\n",
      "Has been replaced by 658.0\n",
      "ID :3540.0\n",
      "18.0 is abnormal as value of  V_C\n",
      "Has been replaced by 658.0\n",
      "ID :3597.0\n",
      "63.0 is abnormal as value of  V_C\n",
      "Has been replaced by 698.0\n",
      "ID :3598.0\n",
      "63.0 is abnormal as value of  V_C\n",
      "Has been replaced by 698.0\n",
      "ID :3599.0\n",
      "64.0 is abnormal as value of  V_C\n",
      "Has been replaced by 698.0\n",
      "ID :3603.0\n",
      "67.0 is abnormal as value of  V_C\n",
      "Has been replaced by 698.5\n",
      "ID :3604.0\n",
      "67.0 is abnormal as value of  V_C\n",
      "Has been replaced by 698.5\n",
      "ID :3605.0\n",
      "67.0 is abnormal as value of  V_C\n",
      "Has been replaced by 698.5\n",
      "ID :3606.0\n",
      "67.0 is abnormal as value of  V_C\n",
      "Has been replaced by 698.5\n",
      "ID :3607.0\n",
      "68.0 is abnormal as value of  V_C\n",
      "Has been replaced by 698.5\n",
      "ID :3610.0\n",
      "7.0 is abnormal as value of  V_C\n",
      "Has been replaced by 693.0\n",
      "ID :3611.0\n",
      "7.0 is abnormal as value of  V_C\n",
      "Has been replaced by 693.0\n",
      "ID :3612.0\n",
      "5.0 is abnormal as value of  V_C\n",
      "Has been replaced by 693.0\n",
      "ID :3723.0\n",
      "65440.0 is abnormal as value of  V_C\n",
      "Has been replaced by 704.5\n",
      "ID :4300.0\n",
      "31.0 is abnormal as value of  V_C\n",
      "Has been replaced by 663.0\n",
      "ID :4401.0\n",
      "99.0 is abnormal as value of  V_C\n",
      "Has been replaced by 664.5\n",
      "ID :4651.0\n",
      "479.0 is abnormal as value of  V_C\n",
      "Has been replaced by 0.0\n",
      "ID :5264.0\n",
      "10.0 is abnormal as value of  V_C\n",
      "Has been replaced by 674.0\n",
      "ID :5939.0\n",
      "137.0 is abnormal as value of  V_C\n",
      "Has been replaced by 714.5\n",
      "ID :6016.0\n",
      "23.0 is abnormal as value of  V_C\n",
      "Has been replaced by 663.0\n",
      "ID :7437.0\n",
      "65491.0 is abnormal as value of  V_C\n",
      "Has been replaced by 644.0\n",
      "ID :7742.0\n",
      "30.0 is abnormal as value of  V_C\n",
      "Has been replaced by 665.5\n",
      "ID :10920.0\n",
      "27.0 is abnormal as value of  V_C\n",
      "Has been replaced by 628.0\n",
      "ID :10921.0\n",
      "27.0 is abnormal as value of  V_C\n",
      "Has been replaced by 628.0\n",
      "ID :11832.0\n",
      "146.0 is abnormal as value of  V_C\n",
      "Has been replaced by 616.5\n",
      "ID :12814.0\n",
      "14.0 is abnormal as value of  V_C\n",
      "Has been replaced by 671.0\n",
      "ID :13189.0\n",
      "10.0 is abnormal as value of  V_C\n",
      "Has been replaced by 619.0\n",
      "ID :14682.0\n",
      "316.0 is abnormal as value of  V_C\n",
      "Has been replaced by 655.0\n",
      "ID :16437.0\n",
      "26.0 is abnormal as value of  V_C\n",
      "Has been replaced by 594.5\n"
     ]
    }
   ],
   "source": [
    "#计算偏差率的辅助列\n",
    "# for c in ['I_A','I_B','I_C','V_A','V_B','V_C']:\n",
    "for c in ['I_A','I_B','I_C']:\n",
    "    df[c+'_avg_sequence'] = np.nanmean([df[c].shift(i) for i in rolling_mask_eight],axis=0)\n",
    "    df[c+'_exception_ratio'] = np.abs(df[c]-df[c+'_avg_sequence'])/df[c+'_avg_sequence']\n",
    "    df[c+'_cor'] = df[c]\n",
    "    \n",
    "    #out of range\n",
    "    oor_index = df[df[c]>20].index\n",
    "    print(oor_index)\n",
    "    \n",
    "#     outlier_index = df[df[c+'_exception_ratio']>1.6].index\n",
    "#     print(outlier_index)\n",
    "    \n",
    "#     ab_index = pd.Int64Index(set(list(oor_index)+list(outlier_index)))\n",
    "    ab_index = pd.Int64Index(set(list(oor_index)))\n",
    "    print(ab_index)\n",
    "    \n",
    "    ab_data = df.loc[ab_index].sort_values(by='ID', ascending=True)\n",
    "    \n",
    "    print(ab_data[['ID', 'V_A', 'V_B', 'V_C', 'I_A', 'I_B', 'I_C', 'y']])\n",
    "    \n",
    "    # 上下记录均值替代异常值\n",
    "    for idx, line in ab_data.iterrows():\n",
    "        ID = line['ID']\n",
    "        value = line[c]\n",
    "        \n",
    "        index = df[df['ID'] == ID].index\n",
    "            \n",
    "        before_offset = 1\n",
    "        while (idx - before_offset)in ab_index:\n",
    "            before_offset += 1\n",
    "\n",
    "        after_offset = 1\n",
    "        while (idx + after_offset) in ab_index:\n",
    "            after_offset += 1\n",
    "    \n",
    "        print('ID :' + str(ID))\n",
    "        print(value, 'is abnormal as value of ',c)\n",
    "        replace_value = (df.loc[index - before_offset, c].values + df.loc[index + after_offset, c].values) / 2\n",
    "        df.loc[index, c+'_cor'] = replace_value[0]\n",
    "        print('Has been replaced by '+str(replace_value[0]))\n",
    "    \n",
    "    df[c] = df[c+'_cor']\n",
    "    df.drop(columns=[c+'_cor',c+'_exception_ratio',c+'_avg_sequence'],axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "# Corrections for presumed outlier points for I_A failed.....  cv drops continuously    \n",
    "    \n",
    "# for c in ['I_A']:\n",
    "#     df[c+'_avg_sequence'] = np.nanmean([df[c].shift(i) for i in rolling_mask_eight],axis=0)\n",
    "#     df[c+'_exception_ratio'] = np.abs(df[c]-df[c+'_avg_sequence'])/df[c+'_avg_sequence']\n",
    "#     df[c+'_cor'] = df[c]\n",
    "    \n",
    "# #     #out of range\n",
    "# #     oor_index = df[df[c]>20].index\n",
    "# #     print(oor_index)\n",
    "    \n",
    "#     outlier_index = df[df[c+'_exception_ratio']>4].index\n",
    "#     print('outlier_index :\\n',outlier_index)\n",
    "    \n",
    "# #     ab_index = pd.Int64Index(set(list(oor_index)+list(outlier_index)))\n",
    "#     ab_index = pd.Int64Index(set(list(outlier_index)))\n",
    "#     print(ab_index)\n",
    "    \n",
    "#     ab_data = df.loc[ab_index].sort_values(by='ID', ascending=True)\n",
    "    \n",
    "#     print(ab_data[['ID', 'V_A', 'V_B', 'V_C', 'I_A', 'I_B', 'I_C', 'y']])\n",
    "    \n",
    "#     # 上下记录均值替代异常值\n",
    "#     for idx, line in ab_data.iterrows():\n",
    "#         ID = line['ID']\n",
    "#         value = line[c]\n",
    "        \n",
    "#         index = df[df['ID'] == ID].index\n",
    "            \n",
    "#         before_offset = 1\n",
    "#         while (idx - before_offset)in ab_index:\n",
    "#             before_offset += 1\n",
    "\n",
    "#         after_offset = 1\n",
    "#         while (idx + after_offset) in ab_index:\n",
    "#             after_offset += 1\n",
    "    \n",
    "#         print('ID :' + str(ID))\n",
    "#         print(value, 'is abnormal as value of ',c)\n",
    "#         replace_value = (df.loc[index - before_offset, c].values + df.loc[index + after_offset, c].values) / 2\n",
    "#         df.loc[index, c+'_cor'] = replace_value[0]\n",
    "#         print('Has been replaced by '+str(replace_value[0]))\n",
    "    \n",
    "#     df[c] = df[c+'_cor']\n",
    "#     df.drop(columns=[c+'_cor',c+'_exception_ratio',c+'_avg_sequence'],axis=1,inplace=True)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "for c in ['V_A','V_B','V_C']:\n",
    "    df[c+'_avg_sequence'] = np.nanmean([df[c].shift(i) for i in rolling_mask_eight],axis=0)\n",
    "    df[c+'_exception_ratio'] = np.abs(df[c]-df[c+'_avg_sequence'])/df[c+'_avg_sequence']\n",
    "    df[c+'_cor'] = df[c]\n",
    "    \n",
    "    #out of range\n",
    "    oor_index = df[(df[c]>800)|((df[c]<500)&(df[c]!=0))].index\n",
    "    print(oor_index)\n",
    "    \n",
    "#     outlier_index = df[df[c+'_exception_ratio']>1.6].index\n",
    "#     print(outlier_index)\n",
    "    \n",
    "#     ab_index = pd.Int64Index(set(list(oor_index)+list(outlier_index)))\n",
    "    ab_index = pd.Int64Index(set(list(oor_index)))\n",
    "    print(ab_index)\n",
    "    \n",
    "    ab_data = df.loc[ab_index].sort_values(by='ID', ascending=True)\n",
    "    \n",
    "    print(ab_data[['ID', 'V_A', 'V_B', 'V_C', 'I_A', 'I_B', 'I_C', 'y']])\n",
    "    \n",
    "    # 上下记录均值替代异常值\n",
    "    for idx, line in ab_data.iterrows():\n",
    "        ID = line['ID']\n",
    "        value = line[c]\n",
    "        \n",
    "        index = df[df['ID'] == ID].index\n",
    "            \n",
    "        before_offset = 1\n",
    "        while (idx - before_offset)in ab_index:\n",
    "            before_offset += 1\n",
    "\n",
    "        after_offset = 1\n",
    "        while (idx + after_offset) in ab_index:\n",
    "            after_offset += 1\n",
    "    \n",
    "        print('ID :' + str(ID))\n",
    "        print(value, 'is abnormal as value of ',c)\n",
    "        replace_value = (df.loc[index - before_offset, c].values + df.loc[index + after_offset, c].values) / 2\n",
    "        df.loc[index, c+'_cor'] = replace_value[0]\n",
    "        print('Has been replaced by '+str(replace_value[0]))\n",
    "    \n",
    "    df[c] = df[c+'_cor']\n",
    "    df.drop(columns=[c+'_cor',c+'_exception_ratio',c+'_avg_sequence'],axis=1,inplace=True)\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "df['P_A']=df['I_A']*df['V_A']\n",
    "df['P_B']=df['I_B']*df['V_B']\n",
    "df['P_C']=df['I_C']*df['V_C']\n",
    "df['P_avg']=1/3*(df['P_A']+df['P_B']+df['P_C'])\n",
    "\n",
    "\n",
    "# df.drop(columns=['I_A','I_B','I_C','V_A','V_B','V_C','P_A','P_B','P_C','P_avg'],axis=1,inplace=True)\n",
    "# df.drop(columns=['I_A_avg_sequence','I_A_exception_ratio','I_B_avg_sequence','I_B_exception_ratio','I_C_avg_sequence','I_C_exception_ratio','V_B_avg_sequence','V_B_exception_ratio','V_A_avg_sequence','V_A_exception_ratio','V_C_avg_sequence','V_C_exception_ratio',],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.增加前后有效发电量均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = all_data.copy()\n",
    "\n",
    "\n",
    "\n",
    "#前二后二\n",
    "next_one = []\n",
    "prev_one = []\n",
    "next_id = []\n",
    "prev_id = []\n",
    "\n",
    "second_next_one = []\n",
    "second_prev_one = []\n",
    "\n",
    "df_len = df.shape[0]\n",
    "\n",
    "i_y =df.columns.get_loc(\"y\")\n",
    "\n",
    "def get_prev_nn_index(cur_i):\n",
    "    prev_i = cur_i-1\n",
    "    while(prev_i>=0 and pd.isnull(df.iat[prev_i,i_y])):\n",
    "        prev_i-=1\n",
    "    return prev_i\n",
    "\n",
    "def get_next_nn_index(cur_i):\n",
    "    prev_i = cur_i+1\n",
    "    while(prev_i<df_len and pd.isnull(df.iat[prev_i,i_y])):\n",
    "        prev_i+=1\n",
    "    return prev_i\n",
    "\n",
    "for i in range(df_len):\n",
    "    f_pre_i=get_prev_nn_index(i)\n",
    "    if(f_pre_i)<0:\n",
    "        prev_one.append(np.nan)\n",
    "        prev_id.append(0)\n",
    "    else:\n",
    "        prev_one.append(df.iat[f_pre_i,i_y])\n",
    "        prev_id.append(f_pre_i)\n",
    "        \n",
    "    s_pre_i=get_prev_nn_index(f_pre_i)\n",
    "    if (s_pre_i)<0:\n",
    "        second_prev_one.append(np.nan)\n",
    "    else:\n",
    "        second_prev_one.append(df.iat[s_pre_i,i_y])\n",
    "    \n",
    "    f_next_i=get_next_nn_index(i)\n",
    "    if(f_next_i<df_len):\n",
    "        next_one.append(df.iat[f_next_i,i_y])\n",
    "        next_id.append(f_next_i)\n",
    "    else:\n",
    "        next_one.append(np.nan)\n",
    "        next_id.append(df_len)\n",
    "    \n",
    "    s_next_i=get_next_nn_index(f_next_i)\n",
    "    if(s_next_i<df_len):\n",
    "        second_next_one.append(df.iat[s_next_i,i_y])\n",
    "    else:\n",
    "        second_next_one.append(np.nan)\n",
    "        \n",
    "\n",
    "df['next_value'] = next_one\n",
    "df['prev_value'] = prev_one\n",
    "df['avg_value'] = np.nanmean([df['next_value'], df['prev_value']],axis=0)\n",
    "\n",
    "df.drop(['next_value','prev_value'],1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2.增加前后功率均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_avg(df):\n",
    "    array = np.array(df[\"P_avg\"])\n",
    "    newarray=[]\n",
    "    num = 0\n",
    "    for i in np.arange(len(array)):\n",
    "        for j in np.arange(10):\n",
    "            if i<10:\n",
    "                num = (array[j-1]+array[j-2]+array[j-3])/3\n",
    "            if i>=10:\n",
    "                num = (array[i-1]+array[i-2]+array[i-3]+array[i-5]+array[i-6]+array[i-7]+array[i-8]+array[i-9])/9\n",
    "        newarray.append(num)\n",
    "    df[\"old_SoCalledSF_P_avg\"] = newarray\n",
    "    return df\n",
    "\n",
    "df = add_avg(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.训练集测试集数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.去除训练集的重复样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 8409)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拆分数据\n",
    "\n",
    "train_data = df[df['is_train']==1]\n",
    "test_data = df[df['is_train']==0]\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备提交结果\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "df_result['ID'] = list(test_data['ID'])\n",
    "special_missing_ID = test_data[test_data[(test_data == 0) | (test_data == 0.)].count(axis=1) > 13]['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_drop_base=['I_A','I_B','I_C','V_A','V_B','V_C','P_A','P_B','P_C','P_avg']\n",
    "# l_drop =[]\n",
    "# for c in l_drop_base:\n",
    "#     l_drop.append(c+'_cor')\n",
    "# print(l_drop)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('去重前训练集条数:' +str(train_data.shape[0]))\n",
    "# # train_data = train_data.drop_duplicates(train_data.columns.drop(['ID','avg_value','old_SoCalledSF_P_avg']), keep='first')\n",
    "# # train_data = train_data.drop_duplicates(train_data.columns.drop(['ID','avg_value','old_SoCalledSF_P_avg']+l_drop), keep='first')\n",
    "# train_data = train_data.drop_duplicates(train_data.columns.drop(['ID','avg_value','old_SoCalledSF_P_avg']), keep='first')\n",
    "# print('去重后训练集条数:' +str(train_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.使训练集样本分布更合理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def improve_train_test_data(train_data, test_data, poly=False, select=False):\n",
    "#     Y = train_data['y']\n",
    "#     X = train_data.drop(['y','ID','is_train'], axis=1)\n",
    "#     test_data = test_data.drop(['y','ID','is_train'], axis=1)\n",
    "    \n",
    "#     polynm = None\n",
    "#     if poly:\n",
    "#         from sklearn.preprocessing import PolynomialFeatures\n",
    "#         polynm = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "#         X = polynm.fit_transform(X)\n",
    "#         test_data = polynm.transform(test_data)\n",
    "        \n",
    "#     X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=123)\n",
    "    \n",
    "#     sm = None\n",
    "#     if select:\n",
    "#         from sklearn.feature_selection import SelectFromModel\n",
    "#         sm = SelectFromModel(GradientBoostingRegressor(random_state=2))\n",
    "#         X_train = sm.fit_transform(X_train, Y_train)\n",
    "#         X_val = sm.transform(X_val)\n",
    "#         test_data = sm.transform(test_data)\n",
    "        \n",
    "#     train_X = np.concatenate([X_train, X_val])\n",
    "#     train_Y = np.concatenate([Y_train, Y_val])\n",
    "\n",
    "# #     sm = None\n",
    "# #     if select:\n",
    "# #         from sklearn.feature_selection import SelectFromModel\n",
    "# #         sm = SelectFromModel(GradientBoostingRegressor(random_state=2))\n",
    "# #         X = sm.fit_transform(X, Y)\n",
    "# #         test_data = sm.transform(test_data)\n",
    "    \n",
    "# #     train_X = X\n",
    "# #     train_Y = Y\n",
    "#     test_X = test_data\n",
    "        \n",
    "#     return train_X, train_Y, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improve_train_test_data(train_data, test_data, poly=False, select=False):\n",
    "    Y = train_data[['y']]\n",
    "    X = train_data.drop(['y','is_train','I_B','I_C'], axis=1)\n",
    "    test_X = test_data.drop(['y','is_train','I_B','I_C'], axis=1)\n",
    "    \n",
    "    return X, Y, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train, X_test, y_train, y_test, sub_data, sm, polynm = generate_train_data(train_data, test_data, poly=True, select=True)\n",
    "# X_train, X_test, y_train, y_test, sub_data, sm, polynm = generate_train_data(train_data, test_data)\n",
    "\n",
    "# train_X = np.concatenate([X_train, X_test])\n",
    "# train_Y = np.concatenate([y_train, y_test])\n",
    "\n",
    "\n",
    "\n",
    "# test_X = sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train_X, train_Y, test_X = improve_train_test_data(train_data, test_data, poly=True, select=True)\n",
    "train_X, train_Y, test_X = improve_train_test_data(train_data, test_data, poly=False, select=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义打分函数,  SCORE = 1/(1+RMSE)\n",
    "def cal_score(mse):\n",
    "    if isinstance(mse, float):\n",
    "        return 1 / (1 + math.sqrt(mse))\n",
    "    else:\n",
    "        return np.divide(1, 1 + np.sqrt(mse))\n",
    "\n",
    "# def cal_score(mse):\n",
    "#     return np.divide(1, 1 + np.sqrt(mse))\n",
    "\n",
    "# 定义交叉验证函数  \n",
    "def cross_validate(models, X, Y, cv=5):\n",
    "    model_name, mse_avg, score_avg, rmse_r, score_r = [], [], [], [], []\n",
    "    for i, model in enumerate(models):\n",
    "        #获取模型名\n",
    "        name = str(i + 1) + '.' + str(model) \n",
    "#         print(i + 1,'- Model:', str(model).split('(')[0])\n",
    "        print(name)\n",
    "#         model_name.append(str(i + 1) + '.' + str(model).split('(')[0])\n",
    "        model_name.append(name.split('(')[0])\n",
    "        #计算metric\n",
    "        \n",
    "        skf = KFold(5, shuffle=True, random_state=1)\n",
    "        Y_pred = np.zeros(X.shape[0])\n",
    "        for train_idx,val_idx in skf.split(X):\n",
    "            print('train_idx: \\n',str(len(train_idx)),train_idx)\n",
    "            print('val_idx: \\n',str(len(val_idx)),val_idx)\n",
    "            X_train, X_val, Y_train, Y_val = X.iloc[train_idx], X.iloc[val_idx], Y.iloc[train_idx], Y.iloc[val_idx]\n",
    "            model.fit(X_train, Y_train)\n",
    "            Y_pred[val_idx] = model.predict(X_val)\n",
    "            print('Y_pred: \\n',Y_pred)\n",
    "        rmse_c = np.sqrt(mean_squared_error(Y, Y_pred))\n",
    "        score_c = 1/(1+rmse_c)\n",
    "        rmse_r.append(rmse_c)\n",
    "        score_r.append(score_c)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         folds=strat_k_fold.split(X,Y)\n",
    "        #apply shuffling to cross_val_score\n",
    "#         strat_k_fold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=0)\n",
    "        nmse = cross_val_score(model, X, Y, cv=cv, scoring='neg_mean_squared_error')\n",
    "    \n",
    "#         nmse = cross_val_score(model, X, Y, cv=cv, scoring='neg_mean_squared_error')\n",
    "        avg_mse = np.average(-nmse)\n",
    "        mse_avg.append(avg_mse)\n",
    "        #计算分数\n",
    "        scores = cal_score(-nmse)\n",
    "        avg_score = np.average(scores)    \n",
    "        score_avg.append(avg_score)\n",
    "        print('MSE:', -nmse)\n",
    "        print('Score:', scores)\n",
    "        print('Average MSE:', avg_mse, ' - Score:', avg_score, ' - Score_c:', score_c, '\\n')\n",
    "    res = pd.DataFrame()\n",
    "    res['Model'] = model_name\n",
    "    res['Avg MSE'] = mse_avg\n",
    "    res['Avg Score'] = score_avg\n",
    "    res['Score Customize'] = score_r\n",
    "    res['RMSE Customize'] = rmse_r\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基学习器\n",
    "\n",
    "xgbt1 = xgb.XGBRegressor(n_estimators=950, max_depth=3, max_features='sqrt', random_state=321, n_jobs=8)\n",
    "xgbt2 = xgb.XGBRegressor(n_estimators=1000, max_depth=3, max_features='sqrt', random_state=456, n_jobs=8)\n",
    "xgbt3 = xgb.XGBRegressor(n_estimators=1100, max_depth=3, max_features='sqrt', random_state=789, n_jobs=8)\n",
    "# n_estimators=1000  max_depth=5  'sqrt'  GradientBoostingRegressor 最佳参数 ,learning_rate=0.08\n",
    "gbdt1 = GradientBoostingRegressor(n_estimators=800, max_depth=4, max_features='log2', random_state=123,learning_rate=0.08)\n",
    "gbdt2 = GradientBoostingRegressor(n_estimators=900, max_depth=4, max_features='log2', random_state=456,learning_rate=0.08)\n",
    "gbdt3 = GradientBoostingRegressor(n_estimators=1000, max_depth=5, max_features='log2', random_state=789,learning_rate=0.08)\n",
    "# n_estimators=700, max_features='auto', random_state=2, n_jobs=8,max_depth=10\n",
    "forest1 = RandomForestRegressor(n_estimators=800, max_features='sqrt', random_state=7, n_jobs=8)\n",
    "forest2 = RandomForestRegressor(n_estimators=900, max_features='log2', random_state=9, n_jobs=8)\n",
    "forest3 = RandomForestRegressor(n_estimators=900, max_features='sqrt', random_state=11, n_jobs=8) \n",
    "\n",
    "lgb1 = LGBMRegressor(n_estimators=900, max_depth=5, random_state=5, n_jobs=8) \n",
    "lgb2 = LGBMRegressor(n_estimators=850, max_depth=4, random_state=7, n_jobs=8)\n",
    "lgb3 = LGBMRegressor(n_estimators=720, max_depth=4, random_state=9, n_jobs=8)\n",
    "# lgb3 = LGBMRegressor(n_estimators=1000, max_depth=5, random_state=9, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.063976\tvalid's score: 0.798126\n",
      "Early stopping, best iteration is:\n",
      "[876]\tvalid's l2: 0.0631948\tvalid's score: 0.799114\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0154296\tvalid's score: 0.889509\n",
      "Early stopping, best iteration is:\n",
      "[809]\tvalid's l2: 0.0152043\tvalid's score: 0.89023\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid's l2: 0.015193\tvalid's score: 0.890266\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0348576\tvalid's score: 0.842672\n",
      "[1000]\tvalid's l2: 0.0327377\tvalid's score: 0.846786\n",
      "Early stopping, best iteration is:\n",
      "[1240]\tvalid's l2: 0.032321\tvalid's score: 0.847615\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0179828\tvalid's score: 0.881757\n",
      "Early stopping, best iteration is:\n",
      "[591]\tvalid's l2: 0.0177608\tvalid's score: 0.882402\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0586768\tvalid's score: 0.805002\n",
      "[1000]\tvalid's l2: 0.0574485\tvalid's score: 0.806657\n",
      "[1500]\tvalid's l2: 0.057126\tvalid's score: 0.807096\n",
      "Early stopping, best iteration is:\n",
      "[1704]\tvalid's l2: 0.057091\tvalid's score: 0.807143\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0179798\tvalid's score: 0.881765\n",
      "Early stopping, best iteration is:\n",
      "[629]\tvalid's l2: 0.0177844\tvalid's score: 0.882334\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid's l2: 0.0248877\tvalid's score: 0.863738\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0254645\tvalid's score: 0.862384\n",
      "Early stopping, best iteration is:\n",
      "[860]\tvalid's l2: 0.0247487\tvalid's score: 0.864067\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.014179\tvalid's score: 0.893595\n",
      "Early stopping, best iteration is:\n",
      "[752]\tvalid's l2: 0.0139753\tvalid's score: 0.894281\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[321]\tvalid's l2: 0.0214097\tvalid's score: 0.872356\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0620971\tvalid's score: 0.800517\n",
      "[1000]\tvalid's l2: 0.0611689\tvalid's score: 0.801717\n",
      "Early stopping, best iteration is:\n",
      "[1335]\tvalid's l2: 0.0609913\tvalid's score: 0.801948\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0191517\tvalid's score: 0.878434\n",
      "Early stopping, best iteration is:\n",
      "[816]\tvalid's l2: 0.0184904\tvalid's score: 0.880298\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.012936\tvalid's score: 0.897879\n",
      "Early stopping, best iteration is:\n",
      "[446]\tvalid's l2: 0.0128896\tvalid's score: 0.898043\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.036838\tvalid's score: 0.838974\n",
      "Early stopping, best iteration is:\n",
      "[883]\tvalid's l2: 0.0361774\tvalid's score: 0.840192\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0201973\tvalid's score: 0.875567\n",
      "[1000]\tvalid's l2: 0.0195976\tvalid's score: 0.877199\n",
      "Early stopping, best iteration is:\n",
      "[1046]\tvalid's l2: 0.0195309\tvalid's score: 0.877383\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid's l2: 0.0549609\tvalid's score: 0.810086\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid's l2: 0.0146313\tvalid's score: 0.892093\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0334257\tvalid's score: 0.845432\n",
      "[1000]\tvalid's l2: 0.0319909\tvalid's score: 0.848277\n",
      "Early stopping, best iteration is:\n",
      "[1259]\tvalid's l2: 0.0317633\tvalid's score: 0.848736\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0257193\tvalid's score: 0.861792\n",
      "Early stopping, best iteration is:\n",
      "[690]\tvalid's l2: 0.0254763\tvalid's score: 0.862357\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0182199\tvalid's score: 0.881072\n",
      "Early stopping, best iteration is:\n",
      "[521]\tvalid's l2: 0.0181678\tvalid's score: 0.881222\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0654647\tvalid's score: 0.796267\n",
      "[1000]\tvalid's l2: 0.0618783\tvalid's score: 0.800799\n",
      "[1500]\tvalid's l2: 0.0606927\tvalid's score: 0.802337\n",
      "Early stopping, best iteration is:\n",
      "[1886]\tvalid's l2: 0.0604936\tvalid's score: 0.802598\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0185904\tvalid's score: 0.880013\n",
      "Early stopping, best iteration is:\n",
      "[558]\tvalid's l2: 0.0183388\tvalid's score: 0.880731\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0213572\tvalid's score: 0.872493\n",
      "Early stopping, best iteration is:\n",
      "[534]\tvalid's l2: 0.0212646\tvalid's score: 0.872735\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0296048\tvalid's score: 0.853198\n",
      "[1000]\tvalid's l2: 0.0293038\tvalid's score: 0.853837\n",
      "Early stopping, best iteration is:\n",
      "[954]\tvalid's l2: 0.0292615\tvalid's score: 0.853927\n",
      "local cv: 0.8600494113481313\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import lightgbm\n",
    "\n",
    "def my_val(preds, train_data):\n",
    "    label = train_data.get_label()\n",
    "    return 'score', 1/(1+np.sqrt(mean_squared_error(preds, label))), True\n",
    "def my_obj(preds, train_data):\n",
    "    labels = train_deata.get_label()\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'mse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 0\n",
    "}\n",
    "# 同样的条件下，此参数设置达到local cv: 0.8575832021441638\n",
    "\n",
    "# train = train_data.copy()\n",
    "# test = test_X.copy()\n",
    "\n",
    "\n",
    "test_predicts = []\n",
    "val_preds = []\n",
    "\n",
    "# log_test_predicts = []\n",
    "# log_val_predicts = []\n",
    "for idx, seed in enumerate([1,2,3,4,5]):\n",
    "# for idx, seed in enumerate([1]):\n",
    "    kf = KFold(5, shuffle=True, random_state=seed)\n",
    "    \n",
    "    val_preds.append(np.zeros(train_X.shape[0]))\n",
    "    for n_fold, (tra_idx, val_idx) in enumerate(kf.split(train_X)):\n",
    "#         tra = train.iloc[tra_idx]\n",
    "#         val = train.iloc[val_idx]\n",
    "#         tst = test.copy()\n",
    "\n",
    "#         predictor = [c for c in tra.columns.tolist() if c not in['y','I_B','I_C','is_train']]\n",
    "\n",
    "        train_set = lightgbm.Dataset(\n",
    "            train_X.iloc[tra_idx],\n",
    "            train_Y.iloc[tra_idx]['y']\n",
    "        )\n",
    "\n",
    "        validation_set = lightgbm.Dataset(\n",
    "            train_X.iloc[val_idx],\n",
    "            train_Y.iloc[val_idx]['y']\n",
    "        )\n",
    "\n",
    "        model = lightgbm.train(params, train_set, num_boost_round=5000,\n",
    "                              valid_sets= [validation_set],\n",
    "                              valid_names=['valid'],\n",
    "                              early_stopping_rounds=100,\n",
    "                               feval=my_val,\n",
    "                              verbose_eval=500)\n",
    "\n",
    "        val_preds[idx][val_idx] = model.predict(train_X.iloc[val_idx])\n",
    "        test_predicts.append(model.predict(test_X))\n",
    "\n",
    "print('local cv:',1/(1+np.sqrt(mean_squared_error(train_Y['y'],np.mean(val_preds,axis=0)))))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(train_y, predict_y ):\n",
    "    print('local cv:',1/(1+np.sqrt(mean_squared_error(train_y, predict_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练得到的模型预测Test_X\n",
    "wyh_train = np.mean(val_preds,axis=0)\n",
    "wyh_predict = np.mean(test_predicts,axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrs = [\n",
    "    xgbt1, gbdt1, forest1, lgb1,\n",
    "    xgbt2, gbdt2, forest2, lgb2,\n",
    "    xgbt3, gbdt3, forest3, lgb3\n",
    "]\n",
    "\n",
    "regrs_light = [\n",
    "    lgb3, xgbt3, gbdt3, forest3\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_validate(models=regrs_light, X = train_X, Y = train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "       learning_rate=0.1, max_depth=4, min_child_samples=20,\n",
      "       min_child_weight=0.001, min_split_gain=0.0, n_estimators=720,\n",
      "       n_jobs=8, num_leaves=31, objective=None, random_state=9,\n",
      "       reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "       subsample_for_bin=200000, subsample_freq=0)\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   6    7   16 ... 8983 8988 8989]\n",
      "Y_pred: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8996 8997 8999]\n",
      "val_idx: \n",
      " 1800 [   3    4    5 ... 8991 8993 8998]\n",
      "Y_pred: \n",
      " [0.         0.         0.         ... 0.         9.27790014 0.        ]\n",
      "train_idx: \n",
      " 7200 [   0    2    3 ... 8995 8996 8998]\n",
      "val_idx: \n",
      " 1800 [   1   12   13 ... 8994 8997 8999]\n",
      "Y_pred: \n",
      " [0.         1.62641891 0.         ... 9.4915286  9.27790014 0.73598312]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   8    9   10 ... 8979 8992 8996]\n",
      "Y_pred: \n",
      " [0.         1.62641891 0.         ... 9.4915286  9.27790014 0.73598312]\n",
      "train_idx: \n",
      " 7200 [   1    3    4 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   0    2   15 ... 8984 8987 8995]\n",
      "Y_pred: \n",
      " [1.50900872 1.62641891 2.01819079 ... 9.4915286  9.27790014 0.73598312]\n",
      "MSE: [0.37538616 0.02778308 0.03319292 0.02278931 0.07679547]\n",
      "Score: [0.62008288 0.85713116 0.84588826 0.86883895 0.7830118 ]\n",
      "Average MSE: 0.1071893894184095  - Score: 0.794990609947485  - Score_c: 0.8525024378262527 \n",
      "\n",
      "2.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, max_features='sqrt', min_child_weight=1, missing=None,\n",
      "       n_estimators=1100, n_jobs=8, nthread=None, objective='reg:linear',\n",
      "       random_state=789, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=None, silent=True, subsample=1)\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   6    7   16 ... 8983 8988 8989]\n",
      "Y_pred: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8996 8997 8999]\n",
      "val_idx: \n",
      " 1800 [   3    4    5 ... 8991 8993 8998]\n",
      "Y_pred: \n",
      " [0.         0.         0.         ... 0.         9.31527424 0.        ]\n",
      "train_idx: \n",
      " 7200 [   0    2    3 ... 8995 8996 8998]\n",
      "val_idx: \n",
      " 1800 [   1   12   13 ... 8994 8997 8999]\n",
      "Y_pred: \n",
      " [0.         1.70967531 0.         ... 9.59996605 9.31527424 1.30488288]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   8    9   10 ... 8979 8992 8996]\n",
      "Y_pred: \n",
      " [0.         1.70967531 0.         ... 9.59996605 9.31527424 1.30488288]\n",
      "train_idx: \n",
      " 7200 [   1    3    4 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   0    2   15 ... 8984 8987 8995]\n",
      "Y_pred: \n",
      " [1.51005518 1.70967531 1.98962235 ... 9.59996605 9.31527424 1.30488288]\n",
      "MSE: [0.38284219 0.02078627 0.0403467  0.01842254 0.07746435]\n",
      "Score: [0.61776351 0.8739926  0.83273315 0.88049123 0.78227418]\n",
      "Average MSE: 0.10797241075535258  - Score: 0.7974509322748025  - Score_c: 0.8550292505184109 \n",
      "\n",
      "3.GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.08, loss='ls', max_depth=5,\n",
      "             max_features='log2', max_leaf_nodes=None,\n",
      "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "             min_samples_leaf=1, min_samples_split=2,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "             presort='auto', random_state=789, subsample=1.0, verbose=0,\n",
      "             warm_start=False)\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   6    7   16 ... 8983 8988 8989]\n",
      "Y_pred: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8996 8997 8999]\n",
      "val_idx: \n",
      " 1800 [   3    4    5 ... 8991 8993 8998]\n",
      "Y_pred: \n",
      " [0.         0.         0.         ... 0.         9.28067315 0.        ]\n",
      "train_idx: \n",
      " 7200 [   0    2    3 ... 8995 8996 8998]\n",
      "val_idx: \n",
      " 1800 [   1   12   13 ... 8994 8997 8999]\n",
      "Y_pred: \n",
      " [0.         1.75560552 0.         ... 9.6775337  9.28067315 0.69535098]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   8    9   10 ... 8979 8992 8996]\n",
      "Y_pred: \n",
      " [0.         1.75560552 0.         ... 9.6775337  9.28067315 0.69535098]\n",
      "train_idx: \n",
      " 7200 [   1    3    4 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   0    2   15 ... 8984 8987 8995]\n",
      "Y_pred: \n",
      " [1.46468864 1.75560552 1.93401382 ... 9.6775337  9.28067315 0.69535098]\n",
      "MSE: [0.37064972 0.03277303 0.0363797  0.02247151 0.0763999 ]\n",
      "Score: [0.62157741 0.84671622 0.83981768 0.86963705 0.7834502 ]\n",
      "Average MSE: 0.10773477419486803  - Score: 0.7922397096483527  - Score_c: 0.8496336571848296 \n",
      "\n",
      "4.RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=900, n_jobs=8,\n",
      "           oob_score=False, random_state=11, verbose=0, warm_start=False)\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   6    7   16 ... 8983 8988 8989]\n",
      "Y_pred: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8996 8997 8999]\n",
      "val_idx: \n",
      " 1800 [   3    4    5 ... 8991 8993 8998]\n",
      "Y_pred: \n",
      " [0.         0.         0.         ... 0.         9.29858904 0.        ]\n",
      "train_idx: \n",
      " 7200 [   0    2    3 ... 8995 8996 8998]\n",
      "val_idx: \n",
      " 1800 [   1   12   13 ... 8994 8997 8999]\n",
      "Y_pred: \n",
      " [0.         1.73858312 0.         ... 9.65691673 9.29858904 1.16616524]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   8    9   10 ... 8979 8992 8996]\n",
      "Y_pred: \n",
      " [0.         1.73858312 0.         ... 9.65691673 9.29858904 1.16616524]\n",
      "train_idx: \n",
      " 7200 [   1    3    4 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   0    2   15 ... 8984 8987 8995]\n",
      "Y_pred: \n",
      " [1.63200669 1.73858312 2.05342294 ... 9.65691673 9.29858904 1.16616524]\n",
      "MSE: [0.31891313 0.02630594 0.02524492 0.01885264 0.08155755]\n",
      "Score: [0.63909037 0.86044372 0.86289727 0.87927169 0.77785731]\n",
      "Average MSE: 0.09417483679584183  - Score: 0.8039120693915851  - Score_c: 0.8383084536071052 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg MSE</th>\n",
       "      <th>Avg Score</th>\n",
       "      <th>Score Customize</th>\n",
       "      <th>RMSE Customize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.LGBMRegressor</td>\n",
       "      <td>0.107189</td>\n",
       "      <td>0.794991</td>\n",
       "      <td>0.852502</td>\n",
       "      <td>0.173017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.XGBRegressor</td>\n",
       "      <td>0.107972</td>\n",
       "      <td>0.797451</td>\n",
       "      <td>0.855029</td>\n",
       "      <td>0.169551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.GradientBoostingRegressor</td>\n",
       "      <td>0.107735</td>\n",
       "      <td>0.792240</td>\n",
       "      <td>0.849634</td>\n",
       "      <td>0.176978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.RandomForestRegressor</td>\n",
       "      <td>0.094175</td>\n",
       "      <td>0.803912</td>\n",
       "      <td>0.838308</td>\n",
       "      <td>0.192878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model   Avg MSE  Avg Score  Score Customize  \\\n",
       "0              1.LGBMRegressor  0.107189   0.794991         0.852502   \n",
       "1               2.XGBRegressor  0.107972   0.797451         0.855029   \n",
       "2  3.GradientBoostingRegressor  0.107735   0.792240         0.849634   \n",
       "3      4.RandomForestRegressor  0.094175   0.803912         0.838308   \n",
       "\n",
       "   RMSE Customize  \n",
       "0        0.173017  \n",
       "1        0.169551  \n",
       "2        0.176978  \n",
       "3        0.192878  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(models=regrs_light, X = train_X, Y = train_Y['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stacker(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "    \n",
    "    # Train_X: 原始训练集输入矩阵, Train_Y: 原始训练集输出矩阵, Test_X: 原始测试集输入矩阵\n",
    "    def fit_predict(self, Train_X, Train_Y, Test_X):\n",
    "        Train_X = np.array(Train_X)\n",
    "        Train_Y = np.array(Train_Y)\n",
    "        Test_X = np.array(Test_X)\n",
    "\n",
    "        folds = list(KFold(n_splits=self.n_splits, shuffle=True, random_state=2018).split(Train_X, Train_Y))       \n",
    "        \n",
    "        # 以基学习器预测结果为特征的 stacker训练数据 与 stacker预测数据\n",
    "        # 原始训练集预测结果容器\n",
    "        S_train = np.zeros((Train_X.shape[0], len(self.base_models)))\n",
    "        # 原始测试集预测结果容器\n",
    "        S_predict = np.zeros((Test_X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for n_model, regr in enumerate(self.base_models):\n",
    "            print(n_model + 1, 'Base model:', str(regr).split('(')[0])\n",
    "            S_predict_i = np.zeros((Test_X.shape[0], self.n_splits))\n",
    "            \n",
    "            for n_fold, (train_idx, test_idx) in enumerate(folds):\n",
    "                # 将X分为训练集与测试集\n",
    "                X_train_fold, Y_train_fold, X_test_fold, Y_test_fold = Train_X[train_idx], Train_Y[train_idx], Train_X[test_idx], Train_Y[test_idx]\n",
    "                print ('Fit fold', (n_fold+1), '...')\n",
    "                regr.fit(X_train_fold, Y_train_fold)\n",
    "                Y_pred = regr.predict(X_test_fold)\n",
    "                # 每折训练得到的模型根据原始训练集中的测试折的输入矩阵预测\n",
    "                S_train[test_idx, n_model] = Y_pred\n",
    "                # 每折训练得到的模型根据原始测试集输入矩阵预测\n",
    "                S_predict_i[:, n_fold] = regr.predict(Test_X)\n",
    "            \n",
    "            S_predict[:, n_model] = S_predict_i.mean(axis=1)\n",
    "            print_score(Train_Y, S_train[:, n_model])\n",
    "\n",
    "#         nmse_score = cross_val_score(self.stacker, S_train, Train_Y, cv=5, scoring='neg_mean_squared_error')\n",
    "#         print('CV MSE:', -nmse_score)\n",
    "#         print('Stacker AVG MSE:', -nmse_score.mean(), 'Stacker AVG Score:', np.mean(np.divide(1, 1 + np.sqrt(-nmse_score))))\n",
    "\n",
    "        \n",
    "#         self.stacker.fit(S_train, Train_Y)\n",
    "#         res = self.stacker.predict(S_predict)\n",
    "#         return res, S_train, S_predict\n",
    "        return S_train, S_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Base model: LGBMRegressor\n",
      "Fit fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local cv: 0.854932821327786\n",
      "2 Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "local cv: 0.8529556708561585\n",
      "3 Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "local cv: 0.852263312773313\n",
      "4 Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local cv: 0.8400896261900718\n",
      "S_train:\n",
      " [[1.51458284 1.46422434 1.38642627 1.62616332]\n",
      " [1.76178157 1.65899742 1.72956805 1.79318713]\n",
      " [2.05671363 2.06178665 1.99327769 2.05501543]\n",
      " ...\n",
      " [9.47677748 9.54118633 9.76339747 9.65609279]\n",
      " [9.12316301 8.9697237  9.22935241 9.28050491]\n",
      " [1.07680082 0.9183073  0.9758944  1.13638522]] \n",
      " S_predict:\n",
      " [[0.37830614 0.38616354 0.36197187 0.39141048]\n",
      " [1.32273643 1.28386273 1.32835608 1.41062701]\n",
      " [2.14369897 2.16965151 2.11693592 2.19742862]\n",
      " ...\n",
      " [9.94688695 9.91362667 9.92960239 9.91491533]\n",
      " [9.87927858 9.87366829 9.87521383 9.78414177]\n",
      " [9.0404387  9.10828667 9.09617501 9.11478794]]\n"
     ]
    }
   ],
   "source": [
    "# Stack with 4 models\n",
    "\n",
    "stacking_model = SVR(C=100, gamma=0.01, epsilon=0.01)\n",
    "stacker = Stacker(5, stacking_model, regrs_light)\n",
    "S_train, S_predict = stacker.fit_predict(train_X, train_Y, test_X)\n",
    "\n",
    "print('S_train:\\n',S_train,'\\n','S_predict:\\n',S_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(S_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8409, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wyh_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8409,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wyh_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LGBM</th>\n",
       "      <th>XGBM</th>\n",
       "      <th>GBM</th>\n",
       "      <th>RF</th>\n",
       "      <th>WYH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.514583</td>\n",
       "      <td>1.464224</td>\n",
       "      <td>1.386426</td>\n",
       "      <td>1.626163</td>\n",
       "      <td>1.497505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.761782</td>\n",
       "      <td>1.658997</td>\n",
       "      <td>1.729568</td>\n",
       "      <td>1.793187</td>\n",
       "      <td>1.727111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.056714</td>\n",
       "      <td>2.061787</td>\n",
       "      <td>1.993278</td>\n",
       "      <td>2.055015</td>\n",
       "      <td>1.989387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.338706</td>\n",
       "      <td>2.370183</td>\n",
       "      <td>2.407707</td>\n",
       "      <td>2.411520</td>\n",
       "      <td>2.344840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.471365</td>\n",
       "      <td>2.406468</td>\n",
       "      <td>2.510286</td>\n",
       "      <td>2.603078</td>\n",
       "      <td>2.493056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LGBM      XGBM       GBM        RF       WYH\n",
       "0  1.514583  1.464224  1.386426  1.626163  1.497505\n",
       "1  1.761782  1.658997  1.729568  1.793187  1.727111\n",
       "2  2.056714  2.061787  1.993278  2.055015  1.989387\n",
       "3  2.338706  2.370183  2.407707  2.411520  2.344840\n",
       "4  2.471365  2.406468  2.510286  2.603078  2.493056"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_train=pd.DataFrame()\n",
    "stack_train['LGBM']=S_train[:,0]\n",
    "stack_train['XGBM']=S_train[:,1]\n",
    "stack_train['GBM']=S_train[:,2]\n",
    "stack_train['RF']=S_train[:,3]\n",
    "stack_train['WYH']=wyh_train\n",
    "stack_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LGBM</th>\n",
       "      <th>XGBM</th>\n",
       "      <th>GBM</th>\n",
       "      <th>RF</th>\n",
       "      <th>WYH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.378306</td>\n",
       "      <td>0.386164</td>\n",
       "      <td>0.361972</td>\n",
       "      <td>0.391410</td>\n",
       "      <td>0.395371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.322736</td>\n",
       "      <td>1.283863</td>\n",
       "      <td>1.328356</td>\n",
       "      <td>1.410627</td>\n",
       "      <td>1.357521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.143699</td>\n",
       "      <td>2.169652</td>\n",
       "      <td>2.116936</td>\n",
       "      <td>2.197429</td>\n",
       "      <td>2.199140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.467968</td>\n",
       "      <td>3.442956</td>\n",
       "      <td>3.386227</td>\n",
       "      <td>3.404918</td>\n",
       "      <td>3.418993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.667671</td>\n",
       "      <td>3.643572</td>\n",
       "      <td>3.639023</td>\n",
       "      <td>3.645877</td>\n",
       "      <td>3.658541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LGBM      XGBM       GBM        RF       WYH\n",
       "0  0.378306  0.386164  0.361972  0.391410  0.395371\n",
       "1  1.322736  1.283863  1.328356  1.410627  1.357521\n",
       "2  2.143699  2.169652  2.116936  2.197429  2.199140\n",
       "3  3.467968  3.442956  3.386227  3.404918  3.418993\n",
       "4  3.667671  3.643572  3.639023  3.645877  3.658541"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_predict=pd.DataFrame()\n",
    "stack_predict['LGBM']=S_predict[:,0]\n",
    "stack_predict['XGBM']=S_predict[:,1]\n",
    "stack_predict['GBM']=S_predict[:,2]\n",
    "stack_predict['RF']=S_predict[:,3]\n",
    "stack_predict['WYH']=wyh_predict\n",
    "stack_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local cv: 0.8600494113481313\n"
     ]
    }
   ],
   "source": [
    "print_score(stack_train['WYH'],train_Y['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=0.01, gamma=0.01,\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   6    7   16 ... 8983 8988 8989]\n",
      "Y_pred: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8996 8997 8999]\n",
      "val_idx: \n",
      " 1800 [   3    4    5 ... 8991 8993 8998]\n",
      "Y_pred: \n",
      " [0.         0.         0.         ... 0.         9.10764998 0.        ]\n",
      "train_idx: \n",
      " 7200 [   0    2    3 ... 8995 8996 8998]\n",
      "val_idx: \n",
      " 1800 [   1   12   13 ... 8994 8997 8999]\n",
      "Y_pred: \n",
      " [0.         1.69952932 0.         ... 9.66191344 9.10764998 0.82309192]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   8    9   10 ... 8979 8992 8996]\n",
      "Y_pred: \n",
      " [0.         1.69952932 0.         ... 9.66191344 9.10764998 0.82309192]\n",
      "train_idx: \n",
      " 7200 [   1    3    4 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   0    2   15 ... 8984 8987 8995]\n",
      "Y_pred: \n",
      " [1.42875074 1.69952932 1.99774653 ... 9.66191344 9.10764998 0.82309192]\n",
      "MSE: [0.03112617 0.0113917  0.01430331 0.01098032 0.06799768]\n",
      "Score: [0.85003214 0.90356119 0.89317897 0.90515182 0.79317007]\n",
      "Average MSE: 0.027159837772760924  - Score: 0.8690188382388481  - Score_c: 0.8644037904947467 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg MSE</th>\n",
       "      <th>Avg Score</th>\n",
       "      <th>Score Customize</th>\n",
       "      <th>RMSE Customize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.SVR</td>\n",
       "      <td>0.02716</td>\n",
       "      <td>0.869019</td>\n",
       "      <td>0.864404</td>\n",
       "      <td>0.156867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model  Avg MSE  Avg Score  Score Customize  RMSE Customize\n",
       "0  1.SVR  0.02716   0.869019         0.864404        0.156867"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = SVR(C=100, gamma=0.01, epsilon=0.01)\n",
    "cross_validate(models = [svr], X=stack_train, Y=train_Y['y'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001)\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   6    7   16 ... 8983 8988 8989]\n",
      "Y_pred: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8996 8997 8999]\n",
      "val_idx: \n",
      " 1800 [   3    4    5 ... 8991 8993 8998]\n",
      "Y_pred: \n",
      " [0.        0.        0.        ... 0.        9.0419822 0.       ]\n",
      "train_idx: \n",
      " 7200 [   0    2    3 ... 8995 8996 8998]\n",
      "val_idx: \n",
      " 1800 [   1   12   13 ... 8994 8997 8999]\n",
      "Y_pred: \n",
      " [0.         1.70642627 0.         ... 9.61867046 9.0419822  0.81581319]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   8    9   10 ... 8979 8992 8996]\n",
      "Y_pred: \n",
      " [0.         1.70642627 0.         ... 9.61867046 9.0419822  0.81581319]\n",
      "train_idx: \n",
      " 7200 [   1    3    4 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   0    2   15 ... 8984 8987 8995]\n",
      "Y_pred: \n",
      " [1.45048454 1.70642627 2.00868349 ... 9.61867046 9.0419822  0.81581319]\n",
      "MSE: [0.02426274 0.01155207 0.01460766 0.01160801 0.06960523]\n",
      "Score: [0.86522778 0.9029504  0.89217035 0.90273852 0.79124689]\n",
      "Average MSE: 0.0263271423407971  - Score: 0.8708667894452802  - Score_c: 0.8625914369038868 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg MSE</th>\n",
       "      <th>Avg Score</th>\n",
       "      <th>Score Customize</th>\n",
       "      <th>RMSE Customize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Ridge</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.870867</td>\n",
       "      <td>0.862591</td>\n",
       "      <td>0.159297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model   Avg MSE  Avg Score  Score Customize  RMSE Customize\n",
       "0  1.Ridge  0.026327   0.870867         0.862591        0.159297"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "clf = Ridge(alpha=1.0)\n",
    "cross_validate(models = [clf], X=stack_train, Y=train_Y['y'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False)\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   6    7   16 ... 8983 8988 8989]\n",
      "Y_pred: \n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8996 8997 8999]\n",
      "val_idx: \n",
      " 1800 [   3    4    5 ... 8991 8993 8998]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_pred: \n",
      " [0.         0.         0.         ... 0.         9.05926214 0.        ]\n",
      "train_idx: \n",
      " 7200 [   0    2    3 ... 8995 8996 8998]\n",
      "val_idx: \n",
      " 1800 [   1   12   13 ... 8994 8997 8999]\n",
      "Y_pred: \n",
      " [0.         1.77012095 0.         ... 9.47726423 9.05926214 1.07143057]\n",
      "train_idx: \n",
      " 7200 [   0    1    2 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   8    9   10 ... 8979 8992 8996]\n",
      "Y_pred: \n",
      " [0.         1.77012095 0.         ... 9.47726423 9.05926214 1.07143057]\n",
      "train_idx: \n",
      " 7200 [   1    3    4 ... 8997 8998 8999]\n",
      "val_idx: \n",
      " 1800 [   0    2   15 ... 8984 8987 8995]\n",
      "Y_pred: \n",
      " [1.5260529  1.77012095 2.08184308 ... 9.47726423 9.05926214 1.07143057]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: [0.01951557 0.01423042 0.01736294 0.0141595  0.07337156]\n",
      "Score: [0.87742532 0.89342245 0.88357292 0.89366007 0.7868614 ]\n",
      "Average MSE: 0.027727997451235525  - Score: 0.8669884325530403  - Score_c: 0.8572552316087202 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Avg MSE</th>\n",
       "      <th>Avg Score</th>\n",
       "      <th>Score Customize</th>\n",
       "      <th>RMSE Customize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Lasso</td>\n",
       "      <td>0.027728</td>\n",
       "      <td>0.866988</td>\n",
       "      <td>0.857255</td>\n",
       "      <td>0.166514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model   Avg MSE  Avg Score  Score Customize  RMSE Customize\n",
       "0  1.Lasso  0.027728   0.866988         0.857255        0.166514"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "cross_validate(models = [clf], X=stack_train, Y=train_Y['y'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Base model: LGBMRegressor\n",
      "Fit fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local cv: 0.854932821327786\n",
      "2 Base model: XGBRegressor\n",
      "Fit fold 1 ...\n",
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "local cv: 0.8529556708561585\n",
      "3 Base model: GradientBoostingRegressor\n",
      "Fit fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 2 ...\n",
      "Fit fold 3 ...\n",
      "Fit fold 4 ...\n",
      "Fit fold 5 ...\n",
      "local cv: 0.852263312773313\n",
      "4 Base model: RandomForestRegressor\n",
      "Fit fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit fold 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel_launcher.py:29: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local cv: 0.8400896261900718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Alex\\Anaconda3\\envs\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE: [0.03052725 0.01233836 0.01587385 0.01124648 0.06949714]\n",
      "Stacker AVG MSE: 0.027896614998521207 Stacker AVG Score: 0.8669786347699947\n"
     ]
    }
   ],
   "source": [
    "# Stack with 4 models\n",
    "\n",
    "stacking_model = SVR(C=100, gamma=0.01, epsilon=0.01)\n",
    "stacker = Stacker(5, stacking_model, regrs_light)\n",
    "pred_stack, S_train_data, S_predict_data = stacker.fit_predict(train_X, train_Y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stack with 12 models\n",
    "\n",
    "# stacking_model = SVR(C=100, gamma=0.01, epsilon=0.01)\n",
    "# stacker = Stacker(5, stacking_model, regrs)\n",
    "# pred_stack, S_train_data, S_predict_data = stacker.fit_predict(train_X, train_Y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_result['score'] = pred_stack\n",
    "\n",
    "# index = df_result[df_result['ID'].isin(special_missing_ID)].index\n",
    "# df_result.loc[index, 'score'] = 0.379993053\n",
    "\n",
    "# df_result.to_csv('../result/081703_08785.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
