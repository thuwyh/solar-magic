{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rep_cols = {'ID':'ID', \n",
    " '板温':'board_t', \n",
    " '现场温度':'env_t', \n",
    " '光照强度':'light_strength', \n",
    " '转换效率':'efficiency', \n",
    " '转换效率A':'efficiency_A', \n",
    " '转换效率B':'efficiency_B', \n",
    " '转换效率C':'efficiency_C', \n",
    " '电压A':'V_A',\n",
    " '电压B':'V_B', \n",
    " '电压C':'V_C', \n",
    " '电流A':'I_A', \n",
    " '电流B':'I_B', \n",
    " '电流C':'I_C', \n",
    " '功率A':'P_A', \n",
    " '功率B':'P_B', \n",
    " '功率C':'P_C', \n",
    " '平均功率':'P_avg', \n",
    " '风速':'wind_speed',\n",
    " '风向':'wind_direction', \n",
    " '发电量':'y'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_val(preds, train_data):\n",
    "    label = train_data.get_label()\n",
    "    return 'score', 1/(1+np.sqrt(mean_squared_error(preds, label))), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_obj(preds, train_data):\n",
    "    labels = train_deata.get_label()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/public.train.csv')\n",
    "test = pd.read_csv('../data/public.test.csv')\n",
    "\n",
    "train_len = train.shape[0]\n",
    "\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.rename(index=str, columns=rep_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>light_strength</th>\n",
       "      <th>P_A</th>\n",
       "      <th>P_B</th>\n",
       "      <th>P_C</th>\n",
       "      <th>y</th>\n",
       "      <th>P_avg</th>\n",
       "      <th>board_t</th>\n",
       "      <th>env_t</th>\n",
       "      <th>V_A</th>\n",
       "      <th>...</th>\n",
       "      <th>V_C</th>\n",
       "      <th>I_A</th>\n",
       "      <th>I_B</th>\n",
       "      <th>I_C</th>\n",
       "      <th>efficiency</th>\n",
       "      <th>efficiency_A</th>\n",
       "      <th>efficiency_B</th>\n",
       "      <th>efficiency_C</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>976.86</td>\n",
       "      <td>155.98</td>\n",
       "      <td>1087.50</td>\n",
       "      <td>1.437752</td>\n",
       "      <td>740.11</td>\n",
       "      <td>-19.14</td>\n",
       "      <td>-17.4</td>\n",
       "      <td>729</td>\n",
       "      <td>...</td>\n",
       "      <td>725</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.50</td>\n",
       "      <td>80.55</td>\n",
       "      <td>106.32</td>\n",
       "      <td>16.98</td>\n",
       "      <td>118.36</td>\n",
       "      <td>272</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>1128.40</td>\n",
       "      <td>172.08</td>\n",
       "      <td>1132.56</td>\n",
       "      <td>1.692575</td>\n",
       "      <td>811.01</td>\n",
       "      <td>-18.73</td>\n",
       "      <td>-17.3</td>\n",
       "      <td>728</td>\n",
       "      <td>...</td>\n",
       "      <td>726</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.56</td>\n",
       "      <td>99.90</td>\n",
       "      <td>139.00</td>\n",
       "      <td>21.20</td>\n",
       "      <td>139.51</td>\n",
       "      <td>275</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>41</td>\n",
       "      <td>1279.25</td>\n",
       "      <td>166.06</td>\n",
       "      <td>1310.40</td>\n",
       "      <td>1.975787</td>\n",
       "      <td>918.57</td>\n",
       "      <td>-17.54</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>731</td>\n",
       "      <td>...</td>\n",
       "      <td>720</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.82</td>\n",
       "      <td>82.48</td>\n",
       "      <td>114.86</td>\n",
       "      <td>14.91</td>\n",
       "      <td>117.66</td>\n",
       "      <td>283</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>1474.60</td>\n",
       "      <td>225.37</td>\n",
       "      <td>1517.34</td>\n",
       "      <td>2.370656</td>\n",
       "      <td>1072.44</td>\n",
       "      <td>-15.43</td>\n",
       "      <td>-16.6</td>\n",
       "      <td>730</td>\n",
       "      <td>...</td>\n",
       "      <td>726</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.09</td>\n",
       "      <td>73.98</td>\n",
       "      <td>101.72</td>\n",
       "      <td>15.55</td>\n",
       "      <td>104.67</td>\n",
       "      <td>280</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>65</td>\n",
       "      <td>1548.51</td>\n",
       "      <td>233.28</td>\n",
       "      <td>1674.40</td>\n",
       "      <td>2.532091</td>\n",
       "      <td>1152.06</td>\n",
       "      <td>-14.60</td>\n",
       "      <td>-16.3</td>\n",
       "      <td>727</td>\n",
       "      <td>...</td>\n",
       "      <td>728</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.30</td>\n",
       "      <td>64.62</td>\n",
       "      <td>86.86</td>\n",
       "      <td>13.09</td>\n",
       "      <td>93.92</td>\n",
       "      <td>280</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  light_strength      P_A     P_B      P_C         y    P_avg  board_t  \\\n",
       "0  10              34   976.86  155.98  1087.50  1.437752   740.11   -19.14   \n",
       "1  11              30  1128.40  172.08  1132.56  1.692575   811.01   -18.73   \n",
       "2  12              41  1279.25  166.06  1310.40  1.975787   918.57   -17.54   \n",
       "3  14              53  1474.60  225.37  1517.34  2.370656  1072.44   -15.43   \n",
       "4  15              65  1548.51  233.28  1674.40  2.532091  1152.06   -14.60   \n",
       "\n",
       "   env_t  V_A     ...      V_C   I_A   I_B   I_C  efficiency  efficiency_A  \\\n",
       "0  -17.4  729     ...      725  1.34  0.22  1.50       80.55        106.32   \n",
       "1  -17.3  728     ...      726  1.55  0.24  1.56       99.90        139.00   \n",
       "2  -17.0  731     ...      720  1.75  0.23  1.82       82.48        114.86   \n",
       "3  -16.6  730     ...      726  2.02  0.31  2.09       73.98        101.72   \n",
       "4  -16.3  727     ...      728  2.13  0.32  2.30       64.62         86.86   \n",
       "\n",
       "   efficiency_B  efficiency_C  wind_direction  wind_speed  \n",
       "0         16.98        118.36             272         0.6  \n",
       "1         21.20        139.51             275         0.8  \n",
       "2         14.91        117.66             283         1.1  \n",
       "3         15.55        104.67             280         0.9  \n",
       "4         13.09         93.92             280         1.1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#异常值处理\n",
    "# 改用均值\n",
    "cols = [c for c in df.columns.tolist() if c!='y' and c!='ID']\n",
    "for c in cols:\n",
    "    df[c+'_is_out_of_upper'] = (df[c]>df[c].quantile(0.99)).astype(np.int32)\n",
    "    df[c+'_is_out_of_lower'] = (df[c]<df[c].quantile(0.01)).astype(np.int32)\n",
    "#     df.loc[(df[c]>df[c].quantile(0.99))|(df[c]<df[c].quantile(0.01)),c]=np.nan\n",
    "#     df[c].fillna(df[c].mean(),inplace=True)\n",
    "    df[c] = np.clip(df[c],df[c].quantile(.01),df[c].quantile(0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = ['P_A','P_avg','I_A','P_C','I_C','P_B','I_B']\n",
    "target_plus = [c+'_is_out_of_upper' for c in target]+[c+'_is_out_of_lower' for c in target]+target\n",
    "for c in target:\n",
    "    df['log_'+c] = np.log1p(df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 估算功率\n",
    "df['predict_p_1'] = df['P_A']+df['P_B']+df['P_C']\n",
    "df['predict_p_2'] = (df['P_A']*df['efficiency_A'] \\\n",
    "                   +df['P_B']*df['efficiency_B'] \\\n",
    "                   +df['P_C']*df['efficiency_C'])/36000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we are processing P_A\n",
      "Training until validation scores don't improve for 20 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wyh/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[751]\tvalid's l1: 19.7346\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 20.6882\n",
      "[2000]\tvalid's l1: 20.1342\n",
      "Early stopping, best iteration is:\n",
      "[2223]\tvalid's l1: 20.0669\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 20.9161\n",
      "Early stopping, best iteration is:\n",
      "[1308]\tvalid's l1: 20.6166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wyh/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now, we are processing P_avg\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 9.98123\n",
      "Early stopping, best iteration is:\n",
      "[1256]\tvalid's l1: 9.88543\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 9.93393\n",
      "Early stopping, best iteration is:\n",
      "[1572]\tvalid's l1: 9.71995\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 9.6463\n",
      "Early stopping, best iteration is:\n",
      "[1430]\tvalid's l1: 9.50549\n",
      "Now, we are processing I_A\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 0.03622\n",
      "Early stopping, best iteration is:\n",
      "[1116]\tvalid's l1: 0.0360427\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 0.0372562\n",
      "Early stopping, best iteration is:\n",
      "[988]\tvalid's l1: 0.0372478\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 0.0355553\n",
      "Early stopping, best iteration is:\n",
      "[1038]\tvalid's l1: 0.035478\n",
      "Now, we are processing P_C\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 20.9856\n",
      "Early stopping, best iteration is:\n",
      "[1948]\tvalid's l1: 20.4718\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 20.2846\n",
      "Early stopping, best iteration is:\n",
      "[1304]\tvalid's l1: 20.0961\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 18.9535\n",
      "Early stopping, best iteration is:\n",
      "[1451]\tvalid's l1: 18.6187\n",
      "Now, we are processing I_C\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 0.0351321\n",
      "Early stopping, best iteration is:\n",
      "[1098]\tvalid's l1: 0.0350017\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 0.0353729\n",
      "Early stopping, best iteration is:\n",
      "[1217]\tvalid's l1: 0.0351105\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 0.0352782\n",
      "Early stopping, best iteration is:\n",
      "[1525]\tvalid's l1: 0.0346918\n",
      "Now, we are processing P_B\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 21.4159\n",
      "[2000]\tvalid's l1: 20.8265\n",
      "Early stopping, best iteration is:\n",
      "[2154]\tvalid's l1: 20.7884\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 20.6594\n",
      "Early stopping, best iteration is:\n",
      "[1137]\tvalid's l1: 20.5522\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 22.0995\n",
      "[2000]\tvalid's l1: 21.5559\n",
      "[3000]\tvalid's l1: 21.3138\n",
      "[4000]\tvalid's l1: 21.1187\n",
      "Early stopping, best iteration is:\n",
      "[4071]\tvalid's l1: 21.1092\n",
      "Now, we are processing I_B\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 0.0361006\n",
      "[2000]\tvalid's l1: 0.0349518\n",
      "Early stopping, best iteration is:\n",
      "[2506]\tvalid's l1: 0.0346315\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 0.0346798\n",
      "Early stopping, best iteration is:\n",
      "[1423]\tvalid's l1: 0.0341732\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[1000]\tvalid's l1: 0.0353894\n",
      "Early stopping, best iteration is:\n",
      "[1755]\tvalid's l1: 0.0345007\n"
     ]
    }
   ],
   "source": [
    "# 第一阶，用其他值预测某些特征\n",
    "\n",
    "params_layer1 = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l1',\n",
    "    'metric': 'mae',\n",
    "    'num_leaves': 48,\n",
    "    'learning_rate': 0.2,\n",
    "#     'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 0\n",
    "}\n",
    "kf_layer1 = KFold(3, shuffle=True, random_state=1991)\n",
    "\n",
    "layer1_result = df[['ID']]\n",
    "\n",
    "for t in target:\n",
    "    print('Now, we are processing',t)\n",
    "    # 特征中去掉t\n",
    "    predictor_t = [c for c in target_plus if c not in['ID','y',t,t+'_is_out_of_upper',t+'_is_out_of_lower']]\n",
    "    \n",
    "    # 初始化结果\n",
    "    val_preds = np.zeros(df.shape[0])\n",
    "    \n",
    "    for n_fold, (tra_idx, val_idx) in enumerate(kf_layer1.split(df)):\n",
    "        tra = df.iloc[tra_idx]\n",
    "        # 删掉有问题的数据\n",
    "        tra.drop(tra[(tra[t+'_is_out_of_upper']==1)|(tra[t+'_is_out_of_lower']==1)].index, inplace=True)\n",
    "        \n",
    "        val = df.iloc[val_idx]\n",
    "        # 删掉有问题的数据\n",
    "        val_c = val.drop(val[(val[t+'_is_out_of_upper']==1)|(val[t+'_is_out_of_lower']==1)].index)\n",
    "\n",
    "        train_set = lightgbm.Dataset(\n",
    "            tra[predictor_t],\n",
    "            tra[t]\n",
    "        )\n",
    "\n",
    "        validation_set = lightgbm.Dataset(\n",
    "            val_c[predictor_t],\n",
    "            val_c[t]\n",
    "        )\n",
    "\n",
    "        model = lightgbm.train(params_layer1, train_set, \n",
    "                               num_boost_round=8000,\n",
    "                              valid_sets= [validation_set],\n",
    "                              valid_names=['valid'],\n",
    "                              early_stopping_rounds=20,\n",
    "                              verbose_eval=1000)\n",
    "\n",
    "        val_preds[val_idx] = model.predict(val[predictor_t])\n",
    "        \n",
    "    # 将结果保存起来\n",
    "    layer1_result['predicted_'+t] = val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>predicted_P_A</th>\n",
       "      <th>predicted_P_avg</th>\n",
       "      <th>predicted_I_A</th>\n",
       "      <th>predicted_P_C</th>\n",
       "      <th>predicted_I_C</th>\n",
       "      <th>predicted_P_B</th>\n",
       "      <th>predicted_I_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>852.802597</td>\n",
       "      <td>756.483336</td>\n",
       "      <td>1.462350</td>\n",
       "      <td>1097.639430</td>\n",
       "      <td>1.423265</td>\n",
       "      <td>157.043170</td>\n",
       "      <td>0.219164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1115.429979</td>\n",
       "      <td>809.889903</td>\n",
       "      <td>1.547411</td>\n",
       "      <td>1152.026598</td>\n",
       "      <td>1.550395</td>\n",
       "      <td>163.939634</td>\n",
       "      <td>0.225199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1285.242300</td>\n",
       "      <td>928.907016</td>\n",
       "      <td>1.759097</td>\n",
       "      <td>1329.374632</td>\n",
       "      <td>1.792227</td>\n",
       "      <td>162.750528</td>\n",
       "      <td>0.244601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1489.419024</td>\n",
       "      <td>1091.271283</td>\n",
       "      <td>2.056612</td>\n",
       "      <td>1498.716542</td>\n",
       "      <td>2.113968</td>\n",
       "      <td>214.498214</td>\n",
       "      <td>0.313826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1511.216897</td>\n",
       "      <td>1117.096194</td>\n",
       "      <td>2.058041</td>\n",
       "      <td>1658.668627</td>\n",
       "      <td>2.338914</td>\n",
       "      <td>240.708355</td>\n",
       "      <td>0.304332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  predicted_P_A  predicted_P_avg  predicted_I_A  predicted_P_C  \\\n",
       "0  10     852.802597       756.483336       1.462350    1097.639430   \n",
       "1  11    1115.429979       809.889903       1.547411    1152.026598   \n",
       "2  12    1285.242300       928.907016       1.759097    1329.374632   \n",
       "3  14    1489.419024      1091.271283       2.056612    1498.716542   \n",
       "4  15    1511.216897      1117.096194       2.058041    1658.668627   \n",
       "\n",
       "   predicted_I_C  predicted_P_B  predicted_I_B  \n",
       "0       1.423265     157.043170       0.219164  \n",
       "1       1.550395     163.939634       0.225199  \n",
       "2       1.792227     162.750528       0.244601  \n",
       "3       2.113968     214.498214       0.313826  \n",
       "4       2.338914     240.708355       0.304332  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1_result.to_pickle('../feature/predicted_value-2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1_result = pd.read_pickle('../feature/predicted_value.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(layer1_result, on='ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in target:\n",
    "    df['diff_'+t] = df[t]-df['predicted_'+t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df.iloc[0:train_len]\n",
    "test = df.iloc[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression_l2',\n",
    "    'metric': 'mse',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.08,\n",
    "    'feature_fraction': 0.6,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 1,\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = [c for c in train.columns.tolist() if c not in['ID','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0615459\tvalid's score: 0.801228\n",
      "Early stopping, best iteration is:\n",
      "[508]\tvalid's l2: 0.0614762\tvalid's score: 0.801318\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0218491\tvalid's score: 0.871221\n",
      "[1000]\tvalid's l2: 0.0186993\tvalid's score: 0.879705\n",
      "[1500]\tvalid's l2: 0.0181318\tvalid's score: 0.881326\n",
      "Early stopping, best iteration is:\n",
      "[1641]\tvalid's l2: 0.0180839\tvalid's score: 0.881464\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid's l2: 0.0125641\tvalid's score: 0.899208\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0499562\tvalid's score: 0.817321\n",
      "[1000]\tvalid's l2: 0.0474069\tvalid's score: 0.821199\n",
      "[1500]\tvalid's l2: 0.0469237\tvalid's score: 0.82195\n",
      "Early stopping, best iteration is:\n",
      "[1414]\tvalid's l2: 0.0468792\tvalid's score: 0.82202\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0162355\tvalid's score: 0.886982\n",
      "Early stopping, best iteration is:\n",
      "[811]\tvalid's l2: 0.0158043\tvalid's score: 0.888324\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0699104\tvalid's score: 0.790885\n",
      "[1000]\tvalid's l2: 0.0678041\tvalid's score: 0.793404\n",
      "[1500]\tvalid's l2: 0.0665323\tvalid's score: 0.794951\n",
      "[2000]\tvalid's l2: 0.0662452\tvalid's score: 0.795304\n",
      "Early stopping, best iteration is:\n",
      "[2080]\tvalid's l2: 0.0661955\tvalid's score: 0.795365\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0176277\tvalid's score: 0.882792\n",
      "[1000]\tvalid's l2: 0.0163847\tvalid's score: 0.886523\n",
      "[1500]\tvalid's l2: 0.0161291\tvalid's score: 0.887311\n",
      "Early stopping, best iteration is:\n",
      "[1649]\tvalid's l2: 0.0160666\tvalid's score: 0.887505\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid's l2: 0.0228009\tvalid's score: 0.86881\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid's l2: 0.0448296\tvalid's score: 0.825266\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0184254\tvalid's score: 0.880483\n",
      "[1000]\tvalid's l2: 0.0169804\tvalid's score: 0.884714\n",
      "Early stopping, best iteration is:\n",
      "[1149]\tvalid's l2: 0.0167433\tvalid's score: 0.885429\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0446638\tvalid's score: 0.825533\n",
      "Early stopping, best iteration is:\n",
      "[816]\tvalid's l2: 0.0439101\tvalid's score: 0.826756\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0553378\tvalid's score: 0.809559\n",
      "Early stopping, best iteration is:\n",
      "[576]\tvalid's l2: 0.0551757\tvalid's score: 0.809785\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0143212\tvalid's score: 0.893119\n",
      "Early stopping, best iteration is:\n",
      "[585]\tvalid's l2: 0.0141454\tvalid's score: 0.893708\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid's l2: 0.011512\tvalid's score: 0.903102\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0332647\tvalid's score: 0.845747\n",
      "[1000]\tvalid's l2: 0.0313865\tvalid's score: 0.8495\n",
      "Early stopping, best iteration is:\n",
      "[1107]\tvalid's l2: 0.0311953\tvalid's score: 0.849891\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0196275\tvalid's score: 0.877117\n",
      "Early stopping, best iteration is:\n",
      "[815]\tvalid's l2: 0.0189765\tvalid's score: 0.878924\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid's l2: 0.0567988\tvalid's score: 0.807542\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0461414\tvalid's score: 0.823177\n",
      "[1000]\tvalid's l2: 0.0452398\tvalid's score: 0.824609\n",
      "Early stopping, best iteration is:\n",
      "[965]\tvalid's l2: 0.0452072\tvalid's score: 0.824661\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.039078\tvalid's score: 0.834946\n",
      "[1000]\tvalid's l2: 0.0365046\tvalid's score: 0.839587\n",
      "[1500]\tvalid's l2: 0.0351682\tvalid's score: 0.842083\n",
      "[2000]\tvalid's l2: 0.0348684\tvalid's score: 0.842651\n",
      "Early stopping, best iteration is:\n",
      "[2396]\tvalid's l2: 0.0347515\tvalid's score: 0.842874\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0205375\tvalid's score: 0.874654\n",
      "Early stopping, best iteration is:\n",
      "[768]\tvalid's l2: 0.0201093\tvalid's score: 0.875805\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.014862\tvalid's score: 0.891337\n",
      "Early stopping, best iteration is:\n",
      "[452]\tvalid's l2: 0.0147806\tvalid's score: 0.891603\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.10492\tvalid's score: 0.755336\n",
      "[1000]\tvalid's l2: 0.0967473\tvalid's score: 0.762752\n",
      "[1500]\tvalid's l2: 0.0941255\tvalid's score: 0.765229\n",
      "[2000]\tvalid's l2: 0.0933742\tvalid's score: 0.765948\n",
      "[2500]\tvalid's l2: 0.0930498\tvalid's score: 0.76626\n",
      "[3000]\tvalid's l2: 0.0929548\tvalid's score: 0.766351\n",
      "Early stopping, best iteration is:\n",
      "[3048]\tvalid's l2: 0.0929387\tvalid's score: 0.766367\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid's l2: 0.0191096\tvalid's score: 0.878551\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\tvalid's l2: 0.0194026\tvalid's score: 0.877737\n",
      "Early stopping, best iteration is:\n",
      "[413]\tvalid's l2: 0.0191988\tvalid's score: 0.878303\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid's l2: 0.0226749\tvalid's score: 0.869125\n"
     ]
    }
   ],
   "source": [
    "test_predicts = []\n",
    "val_preds = []\n",
    "\n",
    "# log_test_predicts = []\n",
    "# log_val_predicts = []\n",
    "for idx, seed in enumerate([1,2,3,4,5]):\n",
    "    kf = KFold(5, shuffle=True, random_state=seed)\n",
    "    \n",
    "    val_preds.append(np.zeros(train.shape[0]))\n",
    "    for n_fold, (tra_idx, val_idx) in enumerate(kf.split(train)):\n",
    "        tra = train.iloc[tra_idx]\n",
    "        val = train.iloc[val_idx]\n",
    "\n",
    "        train_set = lightgbm.Dataset(\n",
    "            tra[predictor],\n",
    "            tra['y']\n",
    "        )\n",
    "\n",
    "        validation_set = lightgbm.Dataset(\n",
    "            val[predictor],\n",
    "            val['y']\n",
    "        )\n",
    "\n",
    "        model = lightgbm.train(params, train_set, num_boost_round=5000,\n",
    "                              valid_sets= [validation_set],\n",
    "                              valid_names=['valid'],\n",
    "                              early_stopping_rounds=100,\n",
    "                               feval=my_val,\n",
    "                              verbose_eval=500)\n",
    "\n",
    "        val_preds[idx][val_idx] = model.predict(val[predictor])\n",
    "        test_predicts.append(model.predict(test[predictor]))\n",
    "        \n",
    "#         train_set = lightgbm.Dataset(\n",
    "#             tra[predictor],\n",
    "#             np.log1p(tra['y'])\n",
    "#         )\n",
    "\n",
    "#         validation_set = lightgbm.Dataset(\n",
    "#             val[predictor],\n",
    "#             np.log1p(val['y'])\n",
    "#         )\n",
    "\n",
    "#         model = lightgbm.train(params, train_set, num_boost_round=5000,\n",
    "#                               valid_sets= [validation_set],\n",
    "#                               valid_names=['valid'],\n",
    "#                               early_stopping_rounds=100,\n",
    "#                                feval=my_val,\n",
    "#                               verbose_eval=500)\n",
    "\n",
    "#         val_preds[idx][val_idx] = np.expm1(model.predict(val[predictor]))\n",
    "#         test_predicts.append(np.expm1(model.predict(test[predictor])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local cv: 0.852399722262\n"
     ]
    }
   ],
   "source": [
    "print('local cv:',1/(1+np.sqrt(mean_squared_error(train['y'],np.mean(val_preds,axis=0)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_A               147386.301654\n",
       "predict_p_1       122642.480351\n",
       "log_P_A           115407.717628\n",
       "log_I_A            26107.769807\n",
       "P_C                15860.467511\n",
       "log_P_avg           9580.742280\n",
       "I_A                 6655.241084\n",
       "P_avg               1597.620548\n",
       "I_C                 1429.933066\n",
       "log_I_C              674.539319\n",
       "P_B                  595.530535\n",
       "I_B                  537.526659\n",
       "light_strength       453.098265\n",
       "log_P_B              291.201493\n",
       "board_t              220.515220\n",
       "wind_direction       195.516600\n",
       "log_I_B              174.403615\n",
       "predict_p_2          132.874186\n",
       "V_B                  125.851948\n",
       "V_A                  121.839249\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(model.feature_importance(importance_type='gain'),\n",
    "          index=model.feature_name()).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wyh/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test['ans'] = np.mean(test_predicts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['ID','ans']].to_csv('../result/0730-8524-bagging.csv',header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1131ea080>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1131eaac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['ans'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8409.000000\n",
       "mean        5.696277\n",
       "std         3.457993\n",
       "min        -0.276554\n",
       "25%         2.523626\n",
       "50%         5.720650\n",
       "75%         8.889917\n",
       "max        12.215004\n",
       "Name: ans, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['ans'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x107abb908>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nApLUsP8PdtTXiw0lxJEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107e19470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['y'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9000.000000\n",
       "mean        5.695245\n",
       "std         3.463744\n",
       "min        -0.125144\n",
       "25%         2.512812\n",
       "50%         5.769032\n",
       "75%         8.896220\n",
       "max        12.288756\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['y'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
